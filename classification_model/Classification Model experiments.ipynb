{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "6e6ddfd3",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import re"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "f4135694",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>submission_title</th>\n",
       "      <th>comment</th>\n",
       "      <th>comment_id</th>\n",
       "      <th>url</th>\n",
       "      <th>subreddit_id</th>\n",
       "      <th>label1</th>\n",
       "      <th>label2</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Shashi Tharoor Set To Run For Congress Preside...</td>\n",
       "      <td>Extremely valid points but I believe he has th...</td>\n",
       "      <td>ip5g6vu</td>\n",
       "      <td>/r/india/comments/xif8wm/shashi_tharoor_set_to...</td>\n",
       "      <td>2qh1q</td>\n",
       "      <td>-1</td>\n",
       "      <td>-1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Yogi government puts Kolkata's image as part o...</td>\n",
       "      <td>Even if the ad was designed by the newspaper -...</td>\n",
       "      <td>hcontm8</td>\n",
       "      <td>/r/india/comments/pmn9o3/yogi_government_puts_...</td>\n",
       "      <td>2qh1q</td>\n",
       "      <td>-1</td>\n",
       "      <td>-1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>An attempt to address the list of \"simplified\"...</td>\n",
       "      <td>Diverse population including Muslims. Welcomin...</td>\n",
       "      <td>fbhlv40</td>\n",
       "      <td>/r/india/comments/ebdeup/an_attempt_to_address...</td>\n",
       "      <td>2qh1q</td>\n",
       "      <td>-1</td>\n",
       "      <td>-2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>You guys noticing what's happening in Sri Lanka?</td>\n",
       "      <td>&gt;The blockade was done by your own people.\\n\\n...</td>\n",
       "      <td>i2yrud3</td>\n",
       "      <td>/r/india/comments/tt1ryh/you_guys_noticing_wha...</td>\n",
       "      <td>2qh1q</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Just got abused on the train by a hyper-nation...</td>\n",
       "      <td>Ohoo bahut bura laga ye sunke ki aap Undergarm...</td>\n",
       "      <td>hooi92k</td>\n",
       "      <td>/r/india/comments/rh2kcs/just_got_abused_on_th...</td>\n",
       "      <td>2qh1q</td>\n",
       "      <td>-2</td>\n",
       "      <td>-2</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                    submission_title  \\\n",
       "0  Shashi Tharoor Set To Run For Congress Preside...   \n",
       "1  Yogi government puts Kolkata's image as part o...   \n",
       "2  An attempt to address the list of \"simplified\"...   \n",
       "3   You guys noticing what's happening in Sri Lanka?   \n",
       "4  Just got abused on the train by a hyper-nation...   \n",
       "\n",
       "                                             comment comment_id  \\\n",
       "0  Extremely valid points but I believe he has th...    ip5g6vu   \n",
       "1  Even if the ad was designed by the newspaper -...    hcontm8   \n",
       "2  Diverse population including Muslims. Welcomin...    fbhlv40   \n",
       "3  >The blockade was done by your own people.\\n\\n...    i2yrud3   \n",
       "4  Ohoo bahut bura laga ye sunke ki aap Undergarm...    hooi92k   \n",
       "\n",
       "                                                 url subreddit_id  label1  \\\n",
       "0  /r/india/comments/xif8wm/shashi_tharoor_set_to...        2qh1q      -1   \n",
       "1  /r/india/comments/pmn9o3/yogi_government_puts_...        2qh1q      -1   \n",
       "2  /r/india/comments/ebdeup/an_attempt_to_address...        2qh1q      -1   \n",
       "3  /r/india/comments/tt1ryh/you_guys_noticing_wha...        2qh1q       0   \n",
       "4  /r/india/comments/rh2kcs/just_got_abused_on_th...        2qh1q      -2   \n",
       "\n",
       "   label2  \n",
       "0      -1  \n",
       "1      -1  \n",
       "2      -2  \n",
       "3       0  \n",
       "4      -2  "
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "text_df = pd.read_csv(\"training_subset.csv\")\n",
    "text_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "0f97eec8",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>label1</th>\n",
       "      <th>label2</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>119.000000</td>\n",
       "      <td>119.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>-0.058824</td>\n",
       "      <td>-0.201681</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>1.043902</td>\n",
       "      <td>0.916698</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>-2.000000</td>\n",
       "      <td>-2.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>-1.000000</td>\n",
       "      <td>-1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>2.000000</td>\n",
       "      <td>2.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "           label1      label2\n",
       "count  119.000000  119.000000\n",
       "mean    -0.058824   -0.201681\n",
       "std      1.043902    0.916698\n",
       "min     -2.000000   -2.000000\n",
       "25%     -1.000000   -1.000000\n",
       "50%      0.000000    0.000000\n",
       "75%      1.000000    0.000000\n",
       "max      2.000000    2.000000"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "text_df.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "e5124002",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>submission_title</th>\n",
       "      <th>comment</th>\n",
       "      <th>comment_id</th>\n",
       "      <th>url</th>\n",
       "      <th>subreddit_id</th>\n",
       "      <th>label1</th>\n",
       "      <th>label2</th>\n",
       "      <th>avg_score</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Shashi Tharoor Set To Run For Congress Preside...</td>\n",
       "      <td>Extremely valid points but I believe he has th...</td>\n",
       "      <td>ip5g6vu</td>\n",
       "      <td>/r/india/comments/xif8wm/shashi_tharoor_set_to...</td>\n",
       "      <td>2qh1q</td>\n",
       "      <td>-1</td>\n",
       "      <td>-1</td>\n",
       "      <td>-1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Yogi government puts Kolkata's image as part o...</td>\n",
       "      <td>Even if the ad was designed by the newspaper -...</td>\n",
       "      <td>hcontm8</td>\n",
       "      <td>/r/india/comments/pmn9o3/yogi_government_puts_...</td>\n",
       "      <td>2qh1q</td>\n",
       "      <td>-1</td>\n",
       "      <td>-1</td>\n",
       "      <td>-1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>An attempt to address the list of \"simplified\"...</td>\n",
       "      <td>Diverse population including Muslims. Welcomin...</td>\n",
       "      <td>fbhlv40</td>\n",
       "      <td>/r/india/comments/ebdeup/an_attempt_to_address...</td>\n",
       "      <td>2qh1q</td>\n",
       "      <td>-1</td>\n",
       "      <td>-2</td>\n",
       "      <td>-1.5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>You guys noticing what's happening in Sri Lanka?</td>\n",
       "      <td>&gt;The blockade was done by your own people.\\n\\n...</td>\n",
       "      <td>i2yrud3</td>\n",
       "      <td>/r/india/comments/tt1ryh/you_guys_noticing_wha...</td>\n",
       "      <td>2qh1q</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Just got abused on the train by a hyper-nation...</td>\n",
       "      <td>Ohoo bahut bura laga ye sunke ki aap Undergarm...</td>\n",
       "      <td>hooi92k</td>\n",
       "      <td>/r/india/comments/rh2kcs/just_got_abused_on_th...</td>\n",
       "      <td>2qh1q</td>\n",
       "      <td>-2</td>\n",
       "      <td>-2</td>\n",
       "      <td>-2.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                    submission_title  \\\n",
       "0  Shashi Tharoor Set To Run For Congress Preside...   \n",
       "1  Yogi government puts Kolkata's image as part o...   \n",
       "2  An attempt to address the list of \"simplified\"...   \n",
       "3   You guys noticing what's happening in Sri Lanka?   \n",
       "4  Just got abused on the train by a hyper-nation...   \n",
       "\n",
       "                                             comment comment_id  \\\n",
       "0  Extremely valid points but I believe he has th...    ip5g6vu   \n",
       "1  Even if the ad was designed by the newspaper -...    hcontm8   \n",
       "2  Diverse population including Muslims. Welcomin...    fbhlv40   \n",
       "3  >The blockade was done by your own people.\\n\\n...    i2yrud3   \n",
       "4  Ohoo bahut bura laga ye sunke ki aap Undergarm...    hooi92k   \n",
       "\n",
       "                                                 url subreddit_id  label1  \\\n",
       "0  /r/india/comments/xif8wm/shashi_tharoor_set_to...        2qh1q      -1   \n",
       "1  /r/india/comments/pmn9o3/yogi_government_puts_...        2qh1q      -1   \n",
       "2  /r/india/comments/ebdeup/an_attempt_to_address...        2qh1q      -1   \n",
       "3  /r/india/comments/tt1ryh/you_guys_noticing_wha...        2qh1q       0   \n",
       "4  /r/india/comments/rh2kcs/just_got_abused_on_th...        2qh1q      -2   \n",
       "\n",
       "   label2  avg_score  \n",
       "0      -1       -1.0  \n",
       "1      -1       -1.0  \n",
       "2      -2       -1.5  \n",
       "3       0        0.0  \n",
       "4      -2       -2.0  "
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "text_df['avg_score'] = text_df.apply(lambda x: np.mean(x[5:]), axis=1)\n",
    "text_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "69d4dcf1",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>label1</th>\n",
       "      <th>label2</th>\n",
       "      <th>avg_score</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>119.000000</td>\n",
       "      <td>119.000000</td>\n",
       "      <td>119.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>-0.058824</td>\n",
       "      <td>-0.201681</td>\n",
       "      <td>-0.130252</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>1.043902</td>\n",
       "      <td>0.916698</td>\n",
       "      <td>0.914715</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>-2.000000</td>\n",
       "      <td>-2.000000</td>\n",
       "      <td>-2.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>-1.000000</td>\n",
       "      <td>-1.000000</td>\n",
       "      <td>-0.500000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.500000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>2.000000</td>\n",
       "      <td>2.000000</td>\n",
       "      <td>2.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "           label1      label2   avg_score\n",
       "count  119.000000  119.000000  119.000000\n",
       "mean    -0.058824   -0.201681   -0.130252\n",
       "std      1.043902    0.916698    0.914715\n",
       "min     -2.000000   -2.000000   -2.000000\n",
       "25%     -1.000000   -1.000000   -0.500000\n",
       "50%      0.000000    0.000000    0.000000\n",
       "75%      1.000000    0.000000    0.500000\n",
       "max      2.000000    2.000000    2.000000"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "text_df.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7a725e8b",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "844a0a3e",
   "metadata": {},
   "source": [
    "## Text Cleaning\n",
    " - Remove all quotes of previous comments (starts with \">\" and ends with newline)\n",
    " - Remove special characters other than ,.'\"?!\n",
    " - Remove links"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "cc537de8",
   "metadata": {},
   "outputs": [],
   "source": [
    "def clean_quotations(text):\n",
    "    temp = re.sub(r'>.*?\\n', '', text)\n",
    "    return temp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "e371e9e3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# clean_punc = re.compile('[^a-zA-Z0-9\\s]')\n",
    "# print(clean_punc.sub('', reviews[0][\"text\"][0].lower()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "6d3f7728",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\">The blockade was done by your own people.\\n\\nWhat a joke. \\n\\n>The simple truth is that your communist party aligned with China and created propaganda against India.\\n\\nThey didn't create any propaganda. India helped their civil war. They are puppet of India. Majority of them have no courage to talk anything about India. \\n\\nPeople in India die due to Koshi that's why India wants to construct another larger dam so that only Nepali would die.\\n\\nAnd another simple explanation, when India initiated a road in Lipulekh Kalapani area (which according to Sugauli treaty) is part of Nepal. India never talked about it with Nepal. Because India dissolved the treaty without Nepal's agreement. \\n\\nWhen every argument ends, we have common culture is your ultimate sword.\""
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "text_df['comment'][3]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "1a5311f9",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"\\nWhat a joke. \\n\\n\\nThey didn't create any propaganda. India helped their civil war. They are puppet of India. Majority of them have no courage to talk anything about India. \\n\\nPeople in India die due to Koshi that's why India wants to construct another larger dam so that only Nepali would die.\\n\\nAnd another simple explanation, when India initiated a road in Lipulekh Kalapani area (which according to Sugauli treaty) is part of Nepal. India never talked about it with Nepal. Because India dissolved the treaty without Nepal's agreement. \\n\\nWhen every argument ends, we have common culture is your ultimate sword.\""
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "clean_quotations(text_df['comment'][3])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "4a69bab7",
   "metadata": {},
   "outputs": [],
   "source": [
    "def clean_url(text):\n",
    "    temp = re.sub(r'(http(s)?:\\/\\/.)?(www\\.)?[-a-zA-Z0-9@:%._\\+~#=]{2,256}\\.[a-z]{2,6}\\b([-a-zA-Z0-9@:%_\\+\\.~#?&\\/=]*)', '', text)\n",
    "    return temp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "a0e216fd",
   "metadata": {},
   "outputs": [],
   "source": [
    "def clean_text(text):\n",
    "    temp = clean_quotations(text)\n",
    "    temp = clean_url(temp)\n",
    "    temp = re.sub(r'[^a-zA-Z0-9\\s\\.,?!\\'\\\"]', ' ', temp)\n",
    "    temp = re.sub(r'\\s+', ' ', temp)  # replace multiple spaces with single space\n",
    "    return temp.strip()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "23ecb563",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"What a joke. They didn't create any propaganda. India helped their civil war. They are puppet of India. Majority of them have no courage to talk anything about India. People in India die due to Koshi that's why India wants to construct another larger dam so that only Nepali would die. And another simple explanation, when India initiated a road in Lipulekh Kalapani area which according to Sugauli treaty is part of Nepal. India never talked about it with Nepal. Because India dissolved the treaty without Nepal's agreement. When every argument ends, we have common culture is your ultimate sword.\""
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "clean_text(text_df['comment'][3])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "c5d8e37a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Attempt at more elaborate translation, for those who might be interested:\n",
      "\n",
      "> They are plastering one movie's posters all over the place.\n",
      "> \n",
      "> The whole of BJP cadre is involved in plastering such posters.\n",
      "> \n",
      "> This is why you came in poltics? To plaster... what will you tell you children at home when they ask what do you do for living? - *I plaster movie's posters.*\n",
      "> \n",
      "> They are saying that Kashmir Files should be tax free, why not just upload it on Youtube? It'll be all free free.\n",
      "> \n",
      "> Why are you getting it tax free? Just ask Vivek Agnihotri to put it all on Youtube, it will all be free for everybody to watch.\n",
      "> \n",
      "> I read something in the newspaper yesterday - there's a Haryana BJP MLA who said that he will get a free screening of the movie held in some park - immediately, Vivek posted on twitter addressing Manohar Lal Khattar about this free screening and asking him to tell that MLA to pay for that screening. \n",
      "> \n",
      "> Listen, some guys are earning crores out of Kashmiri Pandits' tragedy, and you guys are plastering posters on the walls for them. Open your eyes! What has become of you people? \n",
      "> \n",
      "> After eight years of ruling a country, if that country's Prime Minister has to bend his knees in front of Vivek Agnihotri, it means that PM hasn't done any work in all those years.\n",
      "\n",
      "**Edit**: Full video here - https://youtube.com/watch?v=6zLEV34OZKA\n"
     ]
    }
   ],
   "source": [
    "print(text_df['comment'][14])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "fbf1965e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Attempt at more elaborate translation, for those who might be interested Edit Full video here'"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "clean_text(text_df['comment'][14])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "fdff8368",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>clean_title</th>\n",
       "      <th>clean_comment</th>\n",
       "      <th>url</th>\n",
       "      <th>avg_score</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Shashi Tharoor Set To Run For Congress Preside...</td>\n",
       "      <td>Extremely valid points but I believe he has th...</td>\n",
       "      <td>/r/india/comments/xif8wm/shashi_tharoor_set_to...</td>\n",
       "      <td>-1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Yogi government puts Kolkata's image as part o...</td>\n",
       "      <td>Even if the ad was designed by the newspaper t...</td>\n",
       "      <td>/r/india/comments/pmn9o3/yogi_government_puts_...</td>\n",
       "      <td>-1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>An attempt to address the list of \"simplified\"...</td>\n",
       "      <td>Diverse population including Muslims. Welcomin...</td>\n",
       "      <td>/r/india/comments/ebdeup/an_attempt_to_address...</td>\n",
       "      <td>-1.5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>You guys noticing what's happening in Sri Lanka?</td>\n",
       "      <td>What a joke. They didn't create any propaganda...</td>\n",
       "      <td>/r/india/comments/tt1ryh/you_guys_noticing_wha...</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Just got abused on the train by a hyper nation...</td>\n",
       "      <td>Ohoo bahut bura laga ye sunke ki aap Undergarm...</td>\n",
       "      <td>/r/india/comments/rh2kcs/just_got_abused_on_th...</td>\n",
       "      <td>-2.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                         clean_title  \\\n",
       "0  Shashi Tharoor Set To Run For Congress Preside...   \n",
       "1  Yogi government puts Kolkata's image as part o...   \n",
       "2  An attempt to address the list of \"simplified\"...   \n",
       "3   You guys noticing what's happening in Sri Lanka?   \n",
       "4  Just got abused on the train by a hyper nation...   \n",
       "\n",
       "                                       clean_comment  \\\n",
       "0  Extremely valid points but I believe he has th...   \n",
       "1  Even if the ad was designed by the newspaper t...   \n",
       "2  Diverse population including Muslims. Welcomin...   \n",
       "3  What a joke. They didn't create any propaganda...   \n",
       "4  Ohoo bahut bura laga ye sunke ki aap Undergarm...   \n",
       "\n",
       "                                                 url  avg_score  \n",
       "0  /r/india/comments/xif8wm/shashi_tharoor_set_to...       -1.0  \n",
       "1  /r/india/comments/pmn9o3/yogi_government_puts_...       -1.0  \n",
       "2  /r/india/comments/ebdeup/an_attempt_to_address...       -1.5  \n",
       "3  /r/india/comments/tt1ryh/you_guys_noticing_wha...        0.0  \n",
       "4  /r/india/comments/rh2kcs/just_got_abused_on_th...       -2.0  "
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "clean_df = pd.DataFrame()\n",
    "clean_df['clean_title'] = text_df.apply(lambda x: clean_text(x['submission_title']), axis=1)\n",
    "clean_df['clean_comment'] = text_df.apply(lambda x: clean_text(x['comment']), axis=1)\n",
    "clean_df[['url', 'avg_score']] = text_df[['url', 'avg_score']]\n",
    "clean_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "0220480f",
   "metadata": {},
   "outputs": [],
   "source": [
    "clean_df.to_csv(\"cleaned_subset.csv\", index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "d2b59db3",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>clean_title</th>\n",
       "      <th>clean_comment</th>\n",
       "      <th>url</th>\n",
       "      <th>avg_score</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Shashi Tharoor Set To Run For Congress Preside...</td>\n",
       "      <td>Extremely valid points but I believe he has th...</td>\n",
       "      <td>/r/india/comments/xif8wm/shashi_tharoor_set_to...</td>\n",
       "      <td>-1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Yogi government puts Kolkata's image as part o...</td>\n",
       "      <td>Even if the ad was designed by the newspaper t...</td>\n",
       "      <td>/r/india/comments/pmn9o3/yogi_government_puts_...</td>\n",
       "      <td>-1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>An attempt to address the list of \"simplified\"...</td>\n",
       "      <td>Diverse population including Muslims. Welcomin...</td>\n",
       "      <td>/r/india/comments/ebdeup/an_attempt_to_address...</td>\n",
       "      <td>-1.5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>You guys noticing what's happening in Sri Lanka?</td>\n",
       "      <td>What a joke. They didn't create any propaganda...</td>\n",
       "      <td>/r/india/comments/tt1ryh/you_guys_noticing_wha...</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Just got abused on the train by a hyper nation...</td>\n",
       "      <td>Ohoo bahut bura laga ye sunke ki aap Undergarm...</td>\n",
       "      <td>/r/india/comments/rh2kcs/just_got_abused_on_th...</td>\n",
       "      <td>-2.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                         clean_title  \\\n",
       "0  Shashi Tharoor Set To Run For Congress Preside...   \n",
       "1  Yogi government puts Kolkata's image as part o...   \n",
       "2  An attempt to address the list of \"simplified\"...   \n",
       "3   You guys noticing what's happening in Sri Lanka?   \n",
       "4  Just got abused on the train by a hyper nation...   \n",
       "\n",
       "                                       clean_comment  \\\n",
       "0  Extremely valid points but I believe he has th...   \n",
       "1  Even if the ad was designed by the newspaper t...   \n",
       "2  Diverse population including Muslims. Welcomin...   \n",
       "3  What a joke. They didn't create any propaganda...   \n",
       "4  Ohoo bahut bura laga ye sunke ki aap Undergarm...   \n",
       "\n",
       "                                                 url  avg_score  \n",
       "0  /r/india/comments/xif8wm/shashi_tharoor_set_to...       -1.0  \n",
       "1  /r/india/comments/pmn9o3/yogi_government_puts_...       -1.0  \n",
       "2  /r/india/comments/ebdeup/an_attempt_to_address...       -1.5  \n",
       "3  /r/india/comments/tt1ryh/you_guys_noticing_wha...        0.0  \n",
       "4  /r/india/comments/rh2kcs/just_got_abused_on_th...       -2.0  "
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "clean_df = pd.read_csv(\"cleaned_subset.csv\")\n",
    "clean_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e502510e",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "c434e4fd",
   "metadata": {},
   "source": [
    "## Rule-based classifier"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8595fa9f",
   "metadata": {},
   "source": [
    "### Knowledge Base"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "cd259e0a",
   "metadata": {},
   "outputs": [],
   "source": [
    "right = \"\"\"authority, hierarchy, order, duty, tradition, reaction, nationalism, conservatives, right-libertarians, \n",
    "neoconservatives, imperialists, monarchists, fascists, reactionaries, traditionalists, traditional, death penalty, \n",
    "religion, tradition, Bhajpa, BJP, Shiv Sena, MNS, Sanatan, dharm, Hindutva, Islamophobia, Khalistan, Narendra, Modi, Amit, Shah, \n",
    "mandir, ram, Bharatiya, Janata, libtard, Democratic Alliance, NDA, AIADMK, Janta Dal\"\"\".lower()\n",
    "left = \"\"\"freedom, equality, fraternity, rights, progress, reform, internationalism, anarchists, communists, socialists, \n",
    "democratic socialists, social democrats, left-libertarians, progressives, social, liberals, progressive, Congress, \n",
    "INC, Aam, aadmi, party, AAP, CPI, CPI(M), Welfare, Protectionism, Commies, Rahul, gandhi, indira, yatra, arvind, kejriwal, \n",
    "libby, libbies, sjw, bhakts\"\"\".lower()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8bdc3a93",
   "metadata": {},
   "source": [
    "### Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "de5ffd70",
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package punkt to\n",
      "[nltk_data]     C:\\Users\\tejas\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package punkt is already up-to-date!\n",
      "[nltk_data] Downloading package stopwords to\n",
      "[nltk_data]     C:\\Users\\tejas\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package stopwords is already up-to-date!\n",
      "[nltk_data] Downloading package wordnet to\n",
      "[nltk_data]     C:\\Users\\tejas\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package wordnet is already up-to-date!\n"
     ]
    }
   ],
   "source": [
    "import re\n",
    "import nltk\n",
    "nltk.download('punkt')\n",
    "from nltk.tokenize import word_tokenize\n",
    "from nltk import pos_tag\n",
    "nltk.download('stopwords')\n",
    "from nltk.corpus import stopwords\n",
    "nltk.download('wordnet')\n",
    "from nltk.corpus import wordnet"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "7a73476a",
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>submission_title</th>\n",
       "      <th>comment</th>\n",
       "      <th>comment_id</th>\n",
       "      <th>url</th>\n",
       "      <th>subreddit_id</th>\n",
       "      <th>label1</th>\n",
       "      <th>label2</th>\n",
       "      <th>avg_score</th>\n",
       "      <th>cleaned_comment</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Shashi Tharoor Set To Run For Congress Preside...</td>\n",
       "      <td>Extremely valid points but I believe he has th...</td>\n",
       "      <td>ip5g6vu</td>\n",
       "      <td>/r/india/comments/xif8wm/shashi_tharoor_set_to...</td>\n",
       "      <td>2qh1q</td>\n",
       "      <td>-1</td>\n",
       "      <td>-1</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>extremely valid points but i believe he has th...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Yogi government puts Kolkata's image as part o...</td>\n",
       "      <td>Even if the ad was designed by the newspaper -...</td>\n",
       "      <td>hcontm8</td>\n",
       "      <td>/r/india/comments/pmn9o3/yogi_government_puts_...</td>\n",
       "      <td>2qh1q</td>\n",
       "      <td>-1</td>\n",
       "      <td>-1</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>even if the ad was designed by the newspaper t...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>An attempt to address the list of \"simplified\"...</td>\n",
       "      <td>Diverse population including Muslims. Welcomin...</td>\n",
       "      <td>fbhlv40</td>\n",
       "      <td>/r/india/comments/ebdeup/an_attempt_to_address...</td>\n",
       "      <td>2qh1q</td>\n",
       "      <td>-1</td>\n",
       "      <td>-2</td>\n",
       "      <td>-1.5</td>\n",
       "      <td>diverse population including muslims welcoming...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>You guys noticing what's happening in Sri Lanka?</td>\n",
       "      <td>&gt;The blockade was done by your own people.\\r\\n...</td>\n",
       "      <td>i2yrud3</td>\n",
       "      <td>/r/india/comments/tt1ryh/you_guys_noticing_wha...</td>\n",
       "      <td>2qh1q</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>what a joke they didn t create any propaganda...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Just got abused on the train by a hyper-nation...</td>\n",
       "      <td>Ohoo bahut bura laga ye sunke ki aap Undergarm...</td>\n",
       "      <td>hooi92k</td>\n",
       "      <td>/r/india/comments/rh2kcs/just_got_abused_on_th...</td>\n",
       "      <td>2qh1q</td>\n",
       "      <td>-2</td>\n",
       "      <td>-2</td>\n",
       "      <td>-2.0</td>\n",
       "      <td>ohoo bahut bura laga ye sunke ki aap undergarm...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                    submission_title  \\\n",
       "0  Shashi Tharoor Set To Run For Congress Preside...   \n",
       "1  Yogi government puts Kolkata's image as part o...   \n",
       "2  An attempt to address the list of \"simplified\"...   \n",
       "3   You guys noticing what's happening in Sri Lanka?   \n",
       "4  Just got abused on the train by a hyper-nation...   \n",
       "\n",
       "                                             comment comment_id  \\\n",
       "0  Extremely valid points but I believe he has th...    ip5g6vu   \n",
       "1  Even if the ad was designed by the newspaper -...    hcontm8   \n",
       "2  Diverse population including Muslims. Welcomin...    fbhlv40   \n",
       "3  >The blockade was done by your own people.\\r\\n...    i2yrud3   \n",
       "4  Ohoo bahut bura laga ye sunke ki aap Undergarm...    hooi92k   \n",
       "\n",
       "                                                 url subreddit_id  label1  \\\n",
       "0  /r/india/comments/xif8wm/shashi_tharoor_set_to...        2qh1q      -1   \n",
       "1  /r/india/comments/pmn9o3/yogi_government_puts_...        2qh1q      -1   \n",
       "2  /r/india/comments/ebdeup/an_attempt_to_address...        2qh1q      -1   \n",
       "3  /r/india/comments/tt1ryh/you_guys_noticing_wha...        2qh1q       0   \n",
       "4  /r/india/comments/rh2kcs/just_got_abused_on_th...        2qh1q      -2   \n",
       "\n",
       "   label2  avg_score                                    cleaned_comment  \n",
       "0      -1       -1.0  extremely valid points but i believe he has th...  \n",
       "1      -1       -1.0  even if the ad was designed by the newspaper t...  \n",
       "2      -2       -1.5  diverse population including muslims welcoming...  \n",
       "3       0        0.0   what a joke they didn t create any propaganda...  \n",
       "4      -2       -2.0  ohoo bahut bura laga ye sunke ki aap undergarm...  "
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Define a function to clean the text\n",
    "def clean(text):\n",
    "    res_txt = []\n",
    "    for line in text.split('\\n'):\n",
    "        if not line.startswith(\">\"): \n",
    "            res_txt.append(line.lower())\n",
    "    text = \"\\n\".join(res_txt)\n",
    "    \n",
    "    text = re.sub('[^A-Za-z]+', ' ', text)\n",
    "    text = re.sub(r'(http(s)?:\\/\\/.)?(www\\.)?[-a-zA-Z0-9@:%._\\+~#=]{2,256}\\.[a-z]{2,6}\\b([-a-zA-Z0-9@:%_\\+\\.~#?&\\/=]*)', ' ', text)\n",
    "    \n",
    "    return text\n",
    "\n",
    "text_df['cleaned_comment'] = text_df['comment'].apply(clean)\n",
    "text_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "5e5a36b1",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>submission_title</th>\n",
       "      <th>comment</th>\n",
       "      <th>comment_id</th>\n",
       "      <th>url</th>\n",
       "      <th>subreddit_id</th>\n",
       "      <th>label1</th>\n",
       "      <th>label2</th>\n",
       "      <th>avg_score</th>\n",
       "      <th>cleaned_comment</th>\n",
       "      <th>POS_tagged</th>\n",
       "      <th>lemmatized_comment</th>\n",
       "      <th>wordCount_comment</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Shashi Tharoor Set To Run For Congress Preside...</td>\n",
       "      <td>Extremely valid points but I believe he has th...</td>\n",
       "      <td>ip5g6vu</td>\n",
       "      <td>/r/india/comments/xif8wm/shashi_tharoor_set_to...</td>\n",
       "      <td>2qh1q</td>\n",
       "      <td>-1</td>\n",
       "      <td>-1</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>extremely valid points but i believe he has th...</td>\n",
       "      <td>[(extremely, r), (valid, a), (points, n), (bel...</td>\n",
       "      <td>extremely valid point believe charisma win u...</td>\n",
       "      <td>{'party': 1}</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Yogi government puts Kolkata's image as part o...</td>\n",
       "      <td>Even if the ad was designed by the newspaper -...</td>\n",
       "      <td>hcontm8</td>\n",
       "      <td>/r/india/comments/pmn9o3/yogi_government_puts_...</td>\n",
       "      <td>2qh1q</td>\n",
       "      <td>-1</td>\n",
       "      <td>-1</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>even if the ad was designed by the newspaper t...</td>\n",
       "      <td>[(even, r), (ad, n), (designed, v), (newspaper...</td>\n",
       "      <td>even ad design newspaper never ever happen i...</td>\n",
       "      <td>{'ad': 1}</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>An attempt to address the list of \"simplified\"...</td>\n",
       "      <td>Diverse population including Muslims. Welcomin...</td>\n",
       "      <td>fbhlv40</td>\n",
       "      <td>/r/india/comments/ebdeup/an_attempt_to_address...</td>\n",
       "      <td>2qh1q</td>\n",
       "      <td>-1</td>\n",
       "      <td>-2</td>\n",
       "      <td>-1.5</td>\n",
       "      <td>diverse population including muslims welcoming...</td>\n",
       "      <td>[(diverse, a), (population, n), (including, v)...</td>\n",
       "      <td>diverse population include muslim welcome mi...</td>\n",
       "      <td>{'right': 1}</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>You guys noticing what's happening in Sri Lanka?</td>\n",
       "      <td>&gt;The blockade was done by your own people.\\r\\n...</td>\n",
       "      <td>i2yrud3</td>\n",
       "      <td>/r/india/comments/tt1ryh/you_guys_noticing_wha...</td>\n",
       "      <td>2qh1q</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>what a joke they didn t create any propaganda...</td>\n",
       "      <td>[(joke, n), (create, v), (propaganda, n), (ind...</td>\n",
       "      <td>joke create propaganda india help civil war ...</td>\n",
       "      <td>{'part': 1, 'end': 1}</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Just got abused on the train by a hyper-nation...</td>\n",
       "      <td>Ohoo bahut bura laga ye sunke ki aap Undergarm...</td>\n",
       "      <td>hooi92k</td>\n",
       "      <td>/r/india/comments/rh2kcs/just_got_abused_on_th...</td>\n",
       "      <td>2qh1q</td>\n",
       "      <td>-2</td>\n",
       "      <td>-2</td>\n",
       "      <td>-2.0</td>\n",
       "      <td>ohoo bahut bura laga ye sunke ki aap undergarm...</td>\n",
       "      <td>[(ohoo, a), (bahut, n), (bura, n), (laga, n), ...</td>\n",
       "      <td>ohoo bahut bura laga ye sunke ki aap underga...</td>\n",
       "      <td>{'aap': 1, 'pe': 1, 'phobia': 1}</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                    submission_title  \\\n",
       "0  Shashi Tharoor Set To Run For Congress Preside...   \n",
       "1  Yogi government puts Kolkata's image as part o...   \n",
       "2  An attempt to address the list of \"simplified\"...   \n",
       "3   You guys noticing what's happening in Sri Lanka?   \n",
       "4  Just got abused on the train by a hyper-nation...   \n",
       "\n",
       "                                             comment comment_id  \\\n",
       "0  Extremely valid points but I believe he has th...    ip5g6vu   \n",
       "1  Even if the ad was designed by the newspaper -...    hcontm8   \n",
       "2  Diverse population including Muslims. Welcomin...    fbhlv40   \n",
       "3  >The blockade was done by your own people.\\r\\n...    i2yrud3   \n",
       "4  Ohoo bahut bura laga ye sunke ki aap Undergarm...    hooi92k   \n",
       "\n",
       "                                                 url subreddit_id  label1  \\\n",
       "0  /r/india/comments/xif8wm/shashi_tharoor_set_to...        2qh1q      -1   \n",
       "1  /r/india/comments/pmn9o3/yogi_government_puts_...        2qh1q      -1   \n",
       "2  /r/india/comments/ebdeup/an_attempt_to_address...        2qh1q      -1   \n",
       "3  /r/india/comments/tt1ryh/you_guys_noticing_wha...        2qh1q       0   \n",
       "4  /r/india/comments/rh2kcs/just_got_abused_on_th...        2qh1q      -2   \n",
       "\n",
       "   label2  avg_score                                    cleaned_comment  \\\n",
       "0      -1       -1.0  extremely valid points but i believe he has th...   \n",
       "1      -1       -1.0  even if the ad was designed by the newspaper t...   \n",
       "2      -2       -1.5  diverse population including muslims welcoming...   \n",
       "3       0        0.0   what a joke they didn t create any propaganda...   \n",
       "4      -2       -2.0  ohoo bahut bura laga ye sunke ki aap undergarm...   \n",
       "\n",
       "                                          POS_tagged  \\\n",
       "0  [(extremely, r), (valid, a), (points, n), (bel...   \n",
       "1  [(even, r), (ad, n), (designed, v), (newspaper...   \n",
       "2  [(diverse, a), (population, n), (including, v)...   \n",
       "3  [(joke, n), (create, v), (propaganda, n), (ind...   \n",
       "4  [(ohoo, a), (bahut, n), (bura, n), (laga, n), ...   \n",
       "\n",
       "                                  lemmatized_comment  \\\n",
       "0    extremely valid point believe charisma win u...   \n",
       "1    even ad design newspaper never ever happen i...   \n",
       "2    diverse population include muslim welcome mi...   \n",
       "3    joke create propaganda india help civil war ...   \n",
       "4    ohoo bahut bura laga ye sunke ki aap underga...   \n",
       "\n",
       "                  wordCount_comment  \n",
       "0                      {'party': 1}  \n",
       "1                         {'ad': 1}  \n",
       "2                      {'right': 1}  \n",
       "3             {'part': 1, 'end': 1}  \n",
       "4  {'aap': 1, 'pe': 1, 'phobia': 1}  "
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# POS tagger dictionary\n",
    "pos_dict = {'J':wordnet.ADJ, 'V':wordnet.VERB, 'N':wordnet.NOUN, 'R':wordnet.ADV}\n",
    "def token_stop_pos(text):\n",
    "    tags = pos_tag(word_tokenize(text))\n",
    "    newlist = []\n",
    "    for word, tag in tags:\n",
    "        if word.lower() not in set(stopwords.words('english')):\n",
    "            newlist.append(tuple([word, pos_dict.get(tag[0])]))\n",
    "    return newlist\n",
    "\n",
    "text_df['POS_tagged'] = text_df['cleaned_comment'].apply(token_stop_pos)\n",
    "right = token_stop_pos(right)\n",
    "left = token_stop_pos(left)\n",
    "text_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "ee3bdffc",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>submission_title</th>\n",
       "      <th>comment</th>\n",
       "      <th>comment_id</th>\n",
       "      <th>url</th>\n",
       "      <th>subreddit_id</th>\n",
       "      <th>label1</th>\n",
       "      <th>label2</th>\n",
       "      <th>avg_score</th>\n",
       "      <th>cleaned_comment</th>\n",
       "      <th>POS_tagged</th>\n",
       "      <th>lemmatized_comment</th>\n",
       "      <th>wordCount_comment</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Shashi Tharoor Set To Run For Congress Preside...</td>\n",
       "      <td>Extremely valid points but I believe he has th...</td>\n",
       "      <td>ip5g6vu</td>\n",
       "      <td>/r/india/comments/xif8wm/shashi_tharoor_set_to...</td>\n",
       "      <td>2qh1q</td>\n",
       "      <td>-1</td>\n",
       "      <td>-1</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>extremely valid points but i believe he has th...</td>\n",
       "      <td>[(extremely, r), (valid, a), (points, n), (bel...</td>\n",
       "      <td>extremely valid point believe charisma win u...</td>\n",
       "      <td>{'party': 1}</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Yogi government puts Kolkata's image as part o...</td>\n",
       "      <td>Even if the ad was designed by the newspaper -...</td>\n",
       "      <td>hcontm8</td>\n",
       "      <td>/r/india/comments/pmn9o3/yogi_government_puts_...</td>\n",
       "      <td>2qh1q</td>\n",
       "      <td>-1</td>\n",
       "      <td>-1</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>even if the ad was designed by the newspaper t...</td>\n",
       "      <td>[(even, r), (ad, n), (designed, v), (newspaper...</td>\n",
       "      <td>even ad design newspaper never ever happen i...</td>\n",
       "      <td>{'ad': 1}</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>An attempt to address the list of \"simplified\"...</td>\n",
       "      <td>Diverse population including Muslims. Welcomin...</td>\n",
       "      <td>fbhlv40</td>\n",
       "      <td>/r/india/comments/ebdeup/an_attempt_to_address...</td>\n",
       "      <td>2qh1q</td>\n",
       "      <td>-1</td>\n",
       "      <td>-2</td>\n",
       "      <td>-1.5</td>\n",
       "      <td>diverse population including muslims welcoming...</td>\n",
       "      <td>[(diverse, a), (population, n), (including, v)...</td>\n",
       "      <td>diverse population include muslim welcome mi...</td>\n",
       "      <td>{'right': 1}</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>You guys noticing what's happening in Sri Lanka?</td>\n",
       "      <td>&gt;The blockade was done by your own people.\\r\\n...</td>\n",
       "      <td>i2yrud3</td>\n",
       "      <td>/r/india/comments/tt1ryh/you_guys_noticing_wha...</td>\n",
       "      <td>2qh1q</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>what a joke they didn t create any propaganda...</td>\n",
       "      <td>[(joke, n), (create, v), (propaganda, n), (ind...</td>\n",
       "      <td>joke create propaganda india help civil war ...</td>\n",
       "      <td>{'part': 1, 'end': 1}</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Just got abused on the train by a hyper-nation...</td>\n",
       "      <td>Ohoo bahut bura laga ye sunke ki aap Undergarm...</td>\n",
       "      <td>hooi92k</td>\n",
       "      <td>/r/india/comments/rh2kcs/just_got_abused_on_th...</td>\n",
       "      <td>2qh1q</td>\n",
       "      <td>-2</td>\n",
       "      <td>-2</td>\n",
       "      <td>-2.0</td>\n",
       "      <td>ohoo bahut bura laga ye sunke ki aap undergarm...</td>\n",
       "      <td>[(ohoo, a), (bahut, n), (bura, n), (laga, n), ...</td>\n",
       "      <td>ohoo bahut bura laga ye sunke ki aap underga...</td>\n",
       "      <td>{'aap': 1, 'pe': 1, 'phobia': 1}</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                    submission_title  \\\n",
       "0  Shashi Tharoor Set To Run For Congress Preside...   \n",
       "1  Yogi government puts Kolkata's image as part o...   \n",
       "2  An attempt to address the list of \"simplified\"...   \n",
       "3   You guys noticing what's happening in Sri Lanka?   \n",
       "4  Just got abused on the train by a hyper-nation...   \n",
       "\n",
       "                                             comment comment_id  \\\n",
       "0  Extremely valid points but I believe he has th...    ip5g6vu   \n",
       "1  Even if the ad was designed by the newspaper -...    hcontm8   \n",
       "2  Diverse population including Muslims. Welcomin...    fbhlv40   \n",
       "3  >The blockade was done by your own people.\\r\\n...    i2yrud3   \n",
       "4  Ohoo bahut bura laga ye sunke ki aap Undergarm...    hooi92k   \n",
       "\n",
       "                                                 url subreddit_id  label1  \\\n",
       "0  /r/india/comments/xif8wm/shashi_tharoor_set_to...        2qh1q      -1   \n",
       "1  /r/india/comments/pmn9o3/yogi_government_puts_...        2qh1q      -1   \n",
       "2  /r/india/comments/ebdeup/an_attempt_to_address...        2qh1q      -1   \n",
       "3  /r/india/comments/tt1ryh/you_guys_noticing_wha...        2qh1q       0   \n",
       "4  /r/india/comments/rh2kcs/just_got_abused_on_th...        2qh1q      -2   \n",
       "\n",
       "   label2  avg_score                                    cleaned_comment  \\\n",
       "0      -1       -1.0  extremely valid points but i believe he has th...   \n",
       "1      -1       -1.0  even if the ad was designed by the newspaper t...   \n",
       "2      -2       -1.5  diverse population including muslims welcoming...   \n",
       "3       0        0.0   what a joke they didn t create any propaganda...   \n",
       "4      -2       -2.0  ohoo bahut bura laga ye sunke ki aap undergarm...   \n",
       "\n",
       "                                          POS_tagged  \\\n",
       "0  [(extremely, r), (valid, a), (points, n), (bel...   \n",
       "1  [(even, r), (ad, n), (designed, v), (newspaper...   \n",
       "2  [(diverse, a), (population, n), (including, v)...   \n",
       "3  [(joke, n), (create, v), (propaganda, n), (ind...   \n",
       "4  [(ohoo, a), (bahut, n), (bura, n), (laga, n), ...   \n",
       "\n",
       "                                  lemmatized_comment  \\\n",
       "0    extremely valid point believe charisma win u...   \n",
       "1    even ad design newspaper never ever happen i...   \n",
       "2    diverse population include muslim welcome mi...   \n",
       "3    joke create propaganda india help civil war ...   \n",
       "4    ohoo bahut bura laga ye sunke ki aap underga...   \n",
       "\n",
       "                  wordCount_comment  \n",
       "0                      {'party': 1}  \n",
       "1                         {'ad': 1}  \n",
       "2                      {'right': 1}  \n",
       "3             {'part': 1, 'end': 1}  \n",
       "4  {'aap': 1, 'pe': 1, 'phobia': 1}  "
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Lemmatization\n",
    "from nltk.stem import WordNetLemmatizer\n",
    "wordnet_lemmatizer = WordNetLemmatizer()\n",
    "def lemmatize(pos_data):\n",
    "    lemma_rew = \" \"\n",
    "    for word, pos in pos_data:\n",
    "        if not pos:\n",
    "            lemma = word\n",
    "            lemma_rew = lemma_rew + \" \" + lemma\n",
    "        else:\n",
    "            lemma = wordnet_lemmatizer.lemmatize(word, pos=pos)\n",
    "            lemma_rew = lemma_rew + \" \" + lemma\n",
    "    return lemma_rew\n",
    "\n",
    "text_df['lemmatized_comment'] = text_df['POS_tagged'].apply(lemmatize)\n",
    "right = lemmatize(right).split(' , ')\n",
    "left = lemmatize(left).split(' , ')\n",
    "text_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fc8413ed",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "id": "ec7ac580",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>submission_title</th>\n",
       "      <th>comment</th>\n",
       "      <th>comment_id</th>\n",
       "      <th>url</th>\n",
       "      <th>subreddit_id</th>\n",
       "      <th>label1</th>\n",
       "      <th>label2</th>\n",
       "      <th>avg_score</th>\n",
       "      <th>cleaned_comment</th>\n",
       "      <th>POS_tagged</th>\n",
       "      <th>lemmatized_comment</th>\n",
       "      <th>wordCount_comment</th>\n",
       "      <th>sentiment</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Shashi Tharoor Set To Run For Congress Preside...</td>\n",
       "      <td>Extremely valid points but I believe he has th...</td>\n",
       "      <td>ip5g6vu</td>\n",
       "      <td>/r/india/comments/xif8wm/shashi_tharoor_set_to...</td>\n",
       "      <td>2qh1q</td>\n",
       "      <td>-1</td>\n",
       "      <td>-1</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>extremely valid points but i believe he has th...</td>\n",
       "      <td>[(extremely, r), (valid, a), (points, n), (bel...</td>\n",
       "      <td>extremely valid point believe charisma win u...</td>\n",
       "      <td>{'extremely': 1, 'valid': 1, 'point': 1, 'beli...</td>\n",
       "      <td>-1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Yogi government puts Kolkata's image as part o...</td>\n",
       "      <td>Even if the ad was designed by the newspaper -...</td>\n",
       "      <td>hcontm8</td>\n",
       "      <td>/r/india/comments/pmn9o3/yogi_government_puts_...</td>\n",
       "      <td>2qh1q</td>\n",
       "      <td>-1</td>\n",
       "      <td>-1</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>even if the ad was designed by the newspaper t...</td>\n",
       "      <td>[(even, r), (ad, n), (designed, v), (newspaper...</td>\n",
       "      <td>even ad design newspaper never ever happen i...</td>\n",
       "      <td>{'even': 1, 'ad': 1, 'design': 1, 'newspaper':...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>An attempt to address the list of \"simplified\"...</td>\n",
       "      <td>Diverse population including Muslims. Welcomin...</td>\n",
       "      <td>fbhlv40</td>\n",
       "      <td>/r/india/comments/ebdeup/an_attempt_to_address...</td>\n",
       "      <td>2qh1q</td>\n",
       "      <td>-1</td>\n",
       "      <td>-2</td>\n",
       "      <td>-1.5</td>\n",
       "      <td>diverse population including muslims welcoming...</td>\n",
       "      <td>[(diverse, a), (population, n), (including, v)...</td>\n",
       "      <td>diverse population include muslim welcome mi...</td>\n",
       "      <td>{'diverse': 2, 'population': 2, 'include': 1, ...</td>\n",
       "      <td>-1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>You guys noticing what's happening in Sri Lanka?</td>\n",
       "      <td>&gt;The blockade was done by your own people.\\r\\n...</td>\n",
       "      <td>i2yrud3</td>\n",
       "      <td>/r/india/comments/tt1ryh/you_guys_noticing_wha...</td>\n",
       "      <td>2qh1q</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>what a joke they didn t create any propaganda...</td>\n",
       "      <td>[(joke, n), (create, v), (propaganda, n), (ind...</td>\n",
       "      <td>joke create propaganda india help civil war ...</td>\n",
       "      <td>{'joke': 1, 'create': 1, 'propaganda': 1, 'ind...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Just got abused on the train by a hyper-nation...</td>\n",
       "      <td>Ohoo bahut bura laga ye sunke ki aap Undergarm...</td>\n",
       "      <td>hooi92k</td>\n",
       "      <td>/r/india/comments/rh2kcs/just_got_abused_on_th...</td>\n",
       "      <td>2qh1q</td>\n",
       "      <td>-2</td>\n",
       "      <td>-2</td>\n",
       "      <td>-2.0</td>\n",
       "      <td>ohoo bahut bura laga ye sunke ki aap undergarm...</td>\n",
       "      <td>[(ohoo, a), (bahut, n), (bura, n), (laga, n), ...</td>\n",
       "      <td>ohoo bahut bura laga ye sunke ki aap underga...</td>\n",
       "      <td>{'ohoo': 1, 'bahut': 2, 'bura': 1, 'laga': 1, ...</td>\n",
       "      <td>-1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                    submission_title  \\\n",
       "0  Shashi Tharoor Set To Run For Congress Preside...   \n",
       "1  Yogi government puts Kolkata's image as part o...   \n",
       "2  An attempt to address the list of \"simplified\"...   \n",
       "3   You guys noticing what's happening in Sri Lanka?   \n",
       "4  Just got abused on the train by a hyper-nation...   \n",
       "\n",
       "                                             comment comment_id  \\\n",
       "0  Extremely valid points but I believe he has th...    ip5g6vu   \n",
       "1  Even if the ad was designed by the newspaper -...    hcontm8   \n",
       "2  Diverse population including Muslims. Welcomin...    fbhlv40   \n",
       "3  >The blockade was done by your own people.\\r\\n...    i2yrud3   \n",
       "4  Ohoo bahut bura laga ye sunke ki aap Undergarm...    hooi92k   \n",
       "\n",
       "                                                 url subreddit_id  label1  \\\n",
       "0  /r/india/comments/xif8wm/shashi_tharoor_set_to...        2qh1q      -1   \n",
       "1  /r/india/comments/pmn9o3/yogi_government_puts_...        2qh1q      -1   \n",
       "2  /r/india/comments/ebdeup/an_attempt_to_address...        2qh1q      -1   \n",
       "3  /r/india/comments/tt1ryh/you_guys_noticing_wha...        2qh1q       0   \n",
       "4  /r/india/comments/rh2kcs/just_got_abused_on_th...        2qh1q      -2   \n",
       "\n",
       "   label2  avg_score                                    cleaned_comment  \\\n",
       "0      -1       -1.0  extremely valid points but i believe he has th...   \n",
       "1      -1       -1.0  even if the ad was designed by the newspaper t...   \n",
       "2      -2       -1.5  diverse population including muslims welcoming...   \n",
       "3       0        0.0   what a joke they didn t create any propaganda...   \n",
       "4      -2       -2.0  ohoo bahut bura laga ye sunke ki aap undergarm...   \n",
       "\n",
       "                                          POS_tagged  \\\n",
       "0  [(extremely, r), (valid, a), (points, n), (bel...   \n",
       "1  [(even, r), (ad, n), (designed, v), (newspaper...   \n",
       "2  [(diverse, a), (population, n), (including, v)...   \n",
       "3  [(joke, n), (create, v), (propaganda, n), (ind...   \n",
       "4  [(ohoo, a), (bahut, n), (bura, n), (laga, n), ...   \n",
       "\n",
       "                                  lemmatized_comment  \\\n",
       "0    extremely valid point believe charisma win u...   \n",
       "1    even ad design newspaper never ever happen i...   \n",
       "2    diverse population include muslim welcome mi...   \n",
       "3    joke create propaganda india help civil war ...   \n",
       "4    ohoo bahut bura laga ye sunke ki aap underga...   \n",
       "\n",
       "                                   wordCount_comment  sentiment  \n",
       "0  {'extremely': 1, 'valid': 1, 'point': 1, 'beli...         -1  \n",
       "1  {'even': 1, 'ad': 1, 'design': 1, 'newspaper':...          0  \n",
       "2  {'diverse': 2, 'population': 2, 'include': 1, ...         -1  \n",
       "3  {'joke': 1, 'create': 1, 'propaganda': 1, 'ind...          0  \n",
       "4  {'ohoo': 1, 'bahut': 2, 'bura': 1, 'laga': 1, ...         -1  "
      ]
     },
     "execution_count": 62,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Word frequency for comment\n",
    "from nltk import FreqDist\n",
    "def word_count(lemmatized_text):\n",
    "    words = lemmatized_text.split()\n",
    "    temp=zip(*[words[i:] for i in range(0,2)])\n",
    "    words.extend([' '.join(t) for t in temp])\n",
    "    fdist = FreqDist(words)\n",
    "    return fdist\n",
    "\n",
    "# Calculate sentiment of word frequency comment\n",
    "def sentiment_count(freq_dist):\n",
    "    total = 0\n",
    "    for term, freq in freq_dist.items():\n",
    "        if term in left: total -= freq\n",
    "        if term in right: total += freq\n",
    "            \n",
    "    return total\n",
    "\n",
    "left = list(map(str.strip, left))\n",
    "right = list(map(str.strip, right))\n",
    "text_df['wordCount_comment'] = text_df['lemmatized_comment'].apply(word_count)\n",
    "text_df['sentiment'] = text_df['wordCount_comment'].apply(sentiment_count)\n",
    "text_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "id": "0f86d35a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "47"
      ]
     },
     "execution_count": 63,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "score = 0\n",
    "for index, row in text_df.iterrows():\n",
    "    if (row['sentiment'] < 0 and row['avg_score'] < 0) or (row['sentiment'] > 0 and row['avg_score'] > 0) or (row['sentiment']==0 and row['avg_score']==0):\n",
    "        score+=1\n",
    "        \n",
    "score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2c880ba3",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "24a146cb",
   "metadata": {},
   "source": [
    "## BERT-based classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "985802f8",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from torch import nn\n",
    "from transformers import BertTokenizer, BertModel"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "981e520d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "device(type='cuda')"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "device"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "6e3a582d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "|===========================================================================|\n",
      "|                  PyTorch CUDA memory summary, device ID 0                 |\n",
      "|---------------------------------------------------------------------------|\n",
      "|            CUDA OOMs: 0            |        cudaMalloc retries: 0         |\n",
      "|===========================================================================|\n",
      "|        Metric         | Cur Usage  | Peak Usage | Tot Alloc  | Tot Freed  |\n",
      "|---------------------------------------------------------------------------|\n",
      "| Allocated memory      |       0 B  |       0 B  |       0 B  |       0 B  |\n",
      "|       from large pool |       0 B  |       0 B  |       0 B  |       0 B  |\n",
      "|       from small pool |       0 B  |       0 B  |       0 B  |       0 B  |\n",
      "|---------------------------------------------------------------------------|\n",
      "| Active memory         |       0 B  |       0 B  |       0 B  |       0 B  |\n",
      "|       from large pool |       0 B  |       0 B  |       0 B  |       0 B  |\n",
      "|       from small pool |       0 B  |       0 B  |       0 B  |       0 B  |\n",
      "|---------------------------------------------------------------------------|\n",
      "| GPU reserved memory   |       0 B  |       0 B  |       0 B  |       0 B  |\n",
      "|       from large pool |       0 B  |       0 B  |       0 B  |       0 B  |\n",
      "|       from small pool |       0 B  |       0 B  |       0 B  |       0 B  |\n",
      "|---------------------------------------------------------------------------|\n",
      "| Non-releasable memory |       0 B  |       0 B  |       0 B  |       0 B  |\n",
      "|       from large pool |       0 B  |       0 B  |       0 B  |       0 B  |\n",
      "|       from small pool |       0 B  |       0 B  |       0 B  |       0 B  |\n",
      "|---------------------------------------------------------------------------|\n",
      "| Allocations           |       0    |       0    |       0    |       0    |\n",
      "|       from large pool |       0    |       0    |       0    |       0    |\n",
      "|       from small pool |       0    |       0    |       0    |       0    |\n",
      "|---------------------------------------------------------------------------|\n",
      "| Active allocs         |       0    |       0    |       0    |       0    |\n",
      "|       from large pool |       0    |       0    |       0    |       0    |\n",
      "|       from small pool |       0    |       0    |       0    |       0    |\n",
      "|---------------------------------------------------------------------------|\n",
      "| GPU reserved segments |       0    |       0    |       0    |       0    |\n",
      "|       from large pool |       0    |       0    |       0    |       0    |\n",
      "|       from small pool |       0    |       0    |       0    |       0    |\n",
      "|---------------------------------------------------------------------------|\n",
      "| Non-releasable allocs |       0    |       0    |       0    |       0    |\n",
      "|       from large pool |       0    |       0    |       0    |       0    |\n",
      "|       from small pool |       0    |       0    |       0    |       0    |\n",
      "|---------------------------------------------------------------------------|\n",
      "| Oversize allocations  |       0    |       0    |       0    |       0    |\n",
      "|---------------------------------------------------------------------------|\n",
      "| Oversize GPU segments |       0    |       0    |       0    |       0    |\n",
      "|===========================================================================|\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(torch.cuda.memory_summary(device=None, abbreviated=False))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "ace181e4",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>clean_title</th>\n",
       "      <th>clean_comment</th>\n",
       "      <th>url</th>\n",
       "      <th>avg_score</th>\n",
       "      <th>target</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Shashi Tharoor Set To Run For Congress Preside...</td>\n",
       "      <td>Extremely valid points but I believe he has th...</td>\n",
       "      <td>/r/india/comments/xif8wm/shashi_tharoor_set_to...</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-0.50</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Yogi government puts Kolkata's image as part o...</td>\n",
       "      <td>Even if the ad was designed by the newspaper t...</td>\n",
       "      <td>/r/india/comments/pmn9o3/yogi_government_puts_...</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-0.50</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>An attempt to address the list of \"simplified\"...</td>\n",
       "      <td>Diverse population including Muslims. Welcomin...</td>\n",
       "      <td>/r/india/comments/ebdeup/an_attempt_to_address...</td>\n",
       "      <td>-1.5</td>\n",
       "      <td>-0.75</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>You guys noticing what's happening in Sri Lanka?</td>\n",
       "      <td>What a joke. They didn't create any propaganda...</td>\n",
       "      <td>/r/india/comments/tt1ryh/you_guys_noticing_wha...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Just got abused on the train by a hyper nation...</td>\n",
       "      <td>Ohoo bahut bura laga ye sunke ki aap Undergarm...</td>\n",
       "      <td>/r/india/comments/rh2kcs/just_got_abused_on_th...</td>\n",
       "      <td>-2.0</td>\n",
       "      <td>-1.00</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                         clean_title  \\\n",
       "0  Shashi Tharoor Set To Run For Congress Preside...   \n",
       "1  Yogi government puts Kolkata's image as part o...   \n",
       "2  An attempt to address the list of \"simplified\"...   \n",
       "3   You guys noticing what's happening in Sri Lanka?   \n",
       "4  Just got abused on the train by a hyper nation...   \n",
       "\n",
       "                                       clean_comment  \\\n",
       "0  Extremely valid points but I believe he has th...   \n",
       "1  Even if the ad was designed by the newspaper t...   \n",
       "2  Diverse population including Muslims. Welcomin...   \n",
       "3  What a joke. They didn't create any propaganda...   \n",
       "4  Ohoo bahut bura laga ye sunke ki aap Undergarm...   \n",
       "\n",
       "                                                 url  avg_score  target  \n",
       "0  /r/india/comments/xif8wm/shashi_tharoor_set_to...       -1.0   -0.50  \n",
       "1  /r/india/comments/pmn9o3/yogi_government_puts_...       -1.0   -0.50  \n",
       "2  /r/india/comments/ebdeup/an_attempt_to_address...       -1.5   -0.75  \n",
       "3  /r/india/comments/tt1ryh/you_guys_noticing_wha...        0.0    0.00  \n",
       "4  /r/india/comments/rh2kcs/just_got_abused_on_th...       -2.0   -1.00  "
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "clean_df['target'] = clean_df['avg_score']/2\n",
    "clean_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "3d3df4ef",
   "metadata": {},
   "outputs": [],
   "source": [
    "tokenizer = BertTokenizer.from_pretrained(\"google/muril-base-cased\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "89a8b9f6",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'input_ids': tensor([[   104,  96009,   1691,  38666,   6810,   1363,    148,   8994,   1157,\n",
       "           1207,   1108,  19794,   4394,   1192,   1113,   6952,   1750,  16762,\n",
       "          10743,   1341,   1121,   7783,   1108,   1936,  31551,  24418,  51325,\n",
       "           4382,  60648,    121,   7154,    119,    148,   1678,   5526,   1725,\n",
       "          44165,   6127,   2959, 183153, 159371,   1207,    172,  12521,   1109,\n",
       "          49676,   2219,   2733,   9610,   1113,   9989,   1147,    121,    105,\n",
       "              0,      0,      0,      0,      0,      0,      0,      0,      0,\n",
       "              0,      0,      0,      0,      0,      0,      0,      0,      0,\n",
       "              0,      0,      0,      0,      0,      0,      0,      0,      0,\n",
       "              0,      0,      0,      0,      0,      0,      0,      0,      0,\n",
       "              0,      0,      0,      0,      0,      0,      0,      0,      0,\n",
       "              0,      0,      0,      0,      0,      0,      0,      0,      0,\n",
       "              0,      0,      0,      0,      0,      0,      0,      0,      0,\n",
       "              0,      0,      0,      0,      0,      0,      0,      0,      0,\n",
       "              0,      0,      0,      0,      0,      0,      0,      0,      0,\n",
       "              0,      0,      0,      0,      0,      0,      0,      0,      0,\n",
       "              0,      0,      0,      0,      0,      0,      0,      0,      0,\n",
       "              0,      0,      0,      0,      0,      0,      0,      0,      0,\n",
       "              0,      0,      0,      0,      0,      0,      0,      0,      0,\n",
       "              0,      0,      0,      0,      0,      0,      0,      0,      0,\n",
       "              0,      0,      0,      0,      0,      0,      0,      0,      0,\n",
       "              0,      0,      0,      0,      0,      0,      0,      0,      0,\n",
       "              0,      0,      0,      0,      0,      0,      0,      0,      0,\n",
       "              0,      0,      0,      0,      0,      0,      0,      0,      0,\n",
       "              0,      0,      0,      0,      0,      0,      0,      0,      0,\n",
       "              0,      0,      0,      0,      0,      0,      0,      0,      0,\n",
       "              0,      0,      0,      0,      0,      0,      0,      0,      0,\n",
       "              0,      0,      0,      0,      0,      0,      0,      0,      0,\n",
       "              0,      0,      0,      0,      0,      0,      0,      0,      0,\n",
       "              0,      0,      0,      0,      0,      0,      0,      0,      0,\n",
       "              0,      0,      0,      0,      0,      0,      0,      0,      0,\n",
       "              0,      0,      0,      0,      0,      0,      0,      0,      0,\n",
       "              0,      0,      0,      0,      0,      0,      0,      0,      0,\n",
       "              0,      0,      0,      0,      0,      0,      0,      0,      0,\n",
       "              0,      0,      0,      0,      0,      0,      0,      0,      0,\n",
       "              0,      0,      0,      0,      0,      0,      0,      0,      0,\n",
       "              0,      0,      0,      0,      0,      0,      0,      0,      0,\n",
       "              0,      0,      0,      0,      0,      0,      0,      0,      0,\n",
       "              0,      0,      0,      0,      0,      0,      0,      0,      0,\n",
       "              0,      0,      0,      0,      0,      0,      0,      0,      0,\n",
       "              0,      0,      0,      0,      0,      0,      0,      0,      0,\n",
       "              0,      0,      0,      0,      0,      0,      0,      0,      0,\n",
       "              0,      0,      0,      0,      0,      0,      0,      0,      0,\n",
       "              0,      0,      0,      0,      0,      0,      0,      0,      0,\n",
       "              0,      0,      0,      0,      0,      0,      0,      0,      0,\n",
       "              0,      0,      0,      0,      0,      0,      0,      0,      0,\n",
       "              0,      0,      0,      0,      0,      0,      0,      0,      0,\n",
       "              0,      0,      0,      0,      0,      0,      0,      0,      0,\n",
       "              0,      0,      0,      0,      0,      0,      0,      0,      0,\n",
       "              0,      0,      0,      0,      0,      0,      0,      0,      0,\n",
       "              0,      0,      0,      0,      0,      0,      0,      0,      0,\n",
       "              0,      0,      0,      0,      0,      0,      0,      0,      0,\n",
       "              0,      0,      0,      0,      0,      0,      0,      0,      0,\n",
       "              0,      0,      0,      0,      0,      0,      0,      0,      0,\n",
       "              0,      0,      0,      0,      0,      0,      0,      0,      0,\n",
       "              0,      0,      0,      0,      0,      0,      0,      0,      0,\n",
       "              0,      0,      0,      0,      0,      0,      0,      0]]), 'token_type_ids': tensor([[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "         0, 0, 0, 0, 0, 0, 0, 0]]), 'attention_mask': tensor([[1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
       "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
       "         1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "         0, 0, 0, 0, 0, 0, 0, 0]])}"
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tokenizer(clean_df['clean_comment'][0], padding='max_length', max_length = 512, truncation=True, return_tensors=\"pt\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "43853d53",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "bb7845bd",
   "metadata": {},
   "outputs": [],
   "source": [
    "class MuRILbase(nn.Module):\n",
    "\n",
    "    def __init__(self, dropout=0.2):\n",
    "\n",
    "        super(MuRILbase, self).__init__()\n",
    "\n",
    "        self.bert = BertModel.from_pretrained('google/muril-base-cased')\n",
    "        self.dropout = nn.Dropout(dropout)\n",
    "        self.l1 = nn.Linear(768, 200)\n",
    "        self.l2 = nn.Linear(200, 1)\n",
    "        self.relu = nn.ReLU()\n",
    "        self.tanh = nn.Tanh()\n",
    "        \n",
    "        modules = [self.bert.embeddings, *self.bert.encoder.layer[:-3]]  # freeze all but last few\n",
    "        for module in modules:\n",
    "            for param in module.parameters():\n",
    "                param.requires_grad = False\n",
    "\n",
    "    def forward(self, input_id, mask):\n",
    "\n",
    "        _, pooled_output = self.bert(input_ids= input_id, attention_mask=mask,return_dict=False)\n",
    "        x = self.dropout(pooled_output)\n",
    "        x = self.l1(x)\n",
    "        x = self.relu(x)\n",
    "        x = self.l2(x)\n",
    "        x = self.tanh(x)\n",
    "\n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "4f401798",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of the model checkpoint at google/muril-base-cased were not used when initializing BertModel: ['cls.predictions.transform.LayerNorm.bias', 'cls.predictions.transform.LayerNorm.weight', 'cls.predictions.transform.dense.bias', 'cls.predictions.decoder.bias', 'cls.predictions.transform.dense.weight', 'cls.seq_relationship.weight', 'cls.seq_relationship.bias', 'cls.predictions.bias', 'cls.predictions.decoder.weight']\n",
      "- This IS expected if you are initializing BertModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing BertModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "MuRILbase(\n",
       "  (bert): BertModel(\n",
       "    (embeddings): BertEmbeddings(\n",
       "      (word_embeddings): Embedding(197285, 768, padding_idx=0)\n",
       "      (position_embeddings): Embedding(512, 768)\n",
       "      (token_type_embeddings): Embedding(2, 768)\n",
       "      (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "      (dropout): Dropout(p=0.1, inplace=False)\n",
       "    )\n",
       "    (encoder): BertEncoder(\n",
       "      (layer): ModuleList(\n",
       "        (0): BertLayer(\n",
       "          (attention): BertAttention(\n",
       "            (self): BertSelfAttention(\n",
       "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (output): BertSelfOutput(\n",
       "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (intermediate): BertIntermediate(\n",
       "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "            (intermediate_act_fn): GELUActivation()\n",
       "          )\n",
       "          (output): BertOutput(\n",
       "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (1): BertLayer(\n",
       "          (attention): BertAttention(\n",
       "            (self): BertSelfAttention(\n",
       "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (output): BertSelfOutput(\n",
       "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (intermediate): BertIntermediate(\n",
       "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "            (intermediate_act_fn): GELUActivation()\n",
       "          )\n",
       "          (output): BertOutput(\n",
       "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (2): BertLayer(\n",
       "          (attention): BertAttention(\n",
       "            (self): BertSelfAttention(\n",
       "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (output): BertSelfOutput(\n",
       "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (intermediate): BertIntermediate(\n",
       "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "            (intermediate_act_fn): GELUActivation()\n",
       "          )\n",
       "          (output): BertOutput(\n",
       "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (3): BertLayer(\n",
       "          (attention): BertAttention(\n",
       "            (self): BertSelfAttention(\n",
       "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (output): BertSelfOutput(\n",
       "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (intermediate): BertIntermediate(\n",
       "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "            (intermediate_act_fn): GELUActivation()\n",
       "          )\n",
       "          (output): BertOutput(\n",
       "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (4): BertLayer(\n",
       "          (attention): BertAttention(\n",
       "            (self): BertSelfAttention(\n",
       "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (output): BertSelfOutput(\n",
       "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (intermediate): BertIntermediate(\n",
       "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "            (intermediate_act_fn): GELUActivation()\n",
       "          )\n",
       "          (output): BertOutput(\n",
       "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (5): BertLayer(\n",
       "          (attention): BertAttention(\n",
       "            (self): BertSelfAttention(\n",
       "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (output): BertSelfOutput(\n",
       "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (intermediate): BertIntermediate(\n",
       "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "            (intermediate_act_fn): GELUActivation()\n",
       "          )\n",
       "          (output): BertOutput(\n",
       "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (6): BertLayer(\n",
       "          (attention): BertAttention(\n",
       "            (self): BertSelfAttention(\n",
       "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (output): BertSelfOutput(\n",
       "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (intermediate): BertIntermediate(\n",
       "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "            (intermediate_act_fn): GELUActivation()\n",
       "          )\n",
       "          (output): BertOutput(\n",
       "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (7): BertLayer(\n",
       "          (attention): BertAttention(\n",
       "            (self): BertSelfAttention(\n",
       "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (output): BertSelfOutput(\n",
       "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (intermediate): BertIntermediate(\n",
       "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "            (intermediate_act_fn): GELUActivation()\n",
       "          )\n",
       "          (output): BertOutput(\n",
       "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (8): BertLayer(\n",
       "          (attention): BertAttention(\n",
       "            (self): BertSelfAttention(\n",
       "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (output): BertSelfOutput(\n",
       "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (intermediate): BertIntermediate(\n",
       "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "            (intermediate_act_fn): GELUActivation()\n",
       "          )\n",
       "          (output): BertOutput(\n",
       "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (9): BertLayer(\n",
       "          (attention): BertAttention(\n",
       "            (self): BertSelfAttention(\n",
       "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (output): BertSelfOutput(\n",
       "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (intermediate): BertIntermediate(\n",
       "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "            (intermediate_act_fn): GELUActivation()\n",
       "          )\n",
       "          (output): BertOutput(\n",
       "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (10): BertLayer(\n",
       "          (attention): BertAttention(\n",
       "            (self): BertSelfAttention(\n",
       "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (output): BertSelfOutput(\n",
       "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (intermediate): BertIntermediate(\n",
       "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "            (intermediate_act_fn): GELUActivation()\n",
       "          )\n",
       "          (output): BertOutput(\n",
       "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (11): BertLayer(\n",
       "          (attention): BertAttention(\n",
       "            (self): BertSelfAttention(\n",
       "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (output): BertSelfOutput(\n",
       "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (intermediate): BertIntermediate(\n",
       "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "            (intermediate_act_fn): GELUActivation()\n",
       "          )\n",
       "          (output): BertOutput(\n",
       "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "      )\n",
       "    )\n",
       "    (pooler): BertPooler(\n",
       "      (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "      (activation): Tanh()\n",
       "    )\n",
       "  )\n",
       "  (dropout): Dropout(p=0.2, inplace=False)\n",
       "  (l1): Linear(in_features=768, out_features=200, bias=True)\n",
       "  (l2): Linear(in_features=200, out_features=1, bias=True)\n",
       "  (relu): ReLU()\n",
       "  (tanh): Tanh()\n",
       ")"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model = MuRILbase()\n",
    "model.to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "eb14ee59",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[-0.0133],\n",
      "        [-0.0146],\n",
      "        [-0.0140]], device='cuda:0')\n",
      "tensor([-0.0133, -0.0146, -0.0140], device='cuda:0')\n",
      "tensor([-0.5000, -0.5000, -0.7500], device='cuda:0')\n",
      "0.3380824625492096\n",
      "0.33807727694511414\n"
     ]
    }
   ],
   "source": [
    "# testing with a few inputs\n",
    "criterion = nn.MSELoss()\n",
    "\n",
    "temp_batch = list(clean_df['clean_comment'][0:3])\n",
    "temp_targets = torch.tensor(list(clean_df['target'][0:3])).to(device)\n",
    "temp = tokenizer(temp_batch, padding='max_length', max_length = 512, truncation=True, return_tensors=\"pt\")\n",
    "input_ids = temp['input_ids'].to(device)\n",
    "attention_mask = temp['attention_mask'].to(device)\n",
    "with torch.no_grad():\n",
    "    preds = model(input_ids, attention_mask)\n",
    "#     loss = criterion(preds, temp_targets)\n",
    "    print(preds)\n",
    "    print(preds.squeeze(1))\n",
    "    print(temp_targets)\n",
    "#     print(loss.item())\n",
    "    loss = criterion(preds.squeeze(1), temp_targets)\n",
    "    print(loss.item())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9ca9db02",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "c5b49ae4",
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_loop(model, train_df, num_epochs, batch_size, lr=0.001):\n",
    "    criterion = nn.MSELoss().to(device)\n",
    "    optimizer = torch.optim.Adam(model.parameters(), lr=lr)\n",
    "    losses = []\n",
    "    \n",
    "    inputs = train_df.copy()\n",
    "    for _ in range(num_epochs):\n",
    "        inputs = inputs.sample(frac=1).reset_index(drop=True)  # shuffle order\n",
    "        for i in range(int(np.ceil(len(inputs)/batch_size))):\n",
    "            model.zero_grad()\n",
    "            \n",
    "            # getting inputs\n",
    "            batch = list(inputs['clean_comment'][i:i+batch_size])\n",
    "            targets = torch.tensor(list(inputs['target'][i:i+batch_size])).to(device)\n",
    "            temp = tokenizer(batch, padding='max_length', max_length = 512, truncation=True, return_tensors=\"pt\")\n",
    "            input_ids, attention_mask = temp['input_ids'].to(device), temp['attention_mask'].to(device)\n",
    "            \n",
    "            # training model\n",
    "            preds = model(input_ids, attention_mask).squeeze(1)\n",
    "            batch_loss = criterion(preds, targets)\n",
    "            batch_loss.backward()\n",
    "            optimizer.step()\n",
    "            \n",
    "            losses.append(batch_loss.item())\n",
    "            \n",
    "            # excplicitly delete variables in cuda\n",
    "            del batch, targets, temp, input_ids, attention_mask, preds, batch_loss\n",
    "    return model, losses"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "39428f62",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of the model checkpoint at google/muril-base-cased were not used when initializing BertModel: ['cls.predictions.transform.LayerNorm.weight', 'cls.seq_relationship.bias', 'cls.predictions.decoder.bias', 'cls.predictions.transform.LayerNorm.bias', 'cls.predictions.bias', 'cls.predictions.transform.dense.weight', 'cls.seq_relationship.weight', 'cls.predictions.transform.dense.bias', 'cls.predictions.decoder.weight']\n",
      "- This IS expected if you are initializing BertModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing BertModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n"
     ]
    }
   ],
   "source": [
    "model = MuRILbase().to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "1f404159",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "|===========================================================================|\n",
      "|                  PyTorch CUDA memory summary, device ID 0                 |\n",
      "|---------------------------------------------------------------------------|\n",
      "|            CUDA OOMs: 0            |        cudaMalloc retries: 0         |\n",
      "|===========================================================================|\n",
      "|        Metric         | Cur Usage  | Peak Usage | Tot Alloc  | Tot Freed  |\n",
      "|---------------------------------------------------------------------------|\n",
      "| Allocated memory      |     906 MB |    2080 MB |  602567 MB |  601661 MB |\n",
      "|       from large pool |     905 MB |    2077 MB |  602101 MB |  601195 MB |\n",
      "|       from small pool |       1 MB |       4 MB |     466 MB |     465 MB |\n",
      "|---------------------------------------------------------------------------|\n",
      "| Active memory         |     906 MB |    2080 MB |  602567 MB |  601661 MB |\n",
      "|       from large pool |     905 MB |    2077 MB |  602101 MB |  601195 MB |\n",
      "|       from small pool |       1 MB |       4 MB |     466 MB |     465 MB |\n",
      "|---------------------------------------------------------------------------|\n",
      "| GPU reserved memory   |     998 MB |    2910 MB |    2910 MB |    1912 MB |\n",
      "|       from large pool |     994 MB |    2904 MB |    2904 MB |    1910 MB |\n",
      "|       from small pool |       4 MB |       6 MB |       6 MB |       2 MB |\n",
      "|---------------------------------------------------------------------------|\n",
      "| Non-releasable memory |   93370 KB |  168966 KB |  270720 MB |  270629 MB |\n",
      "|       from large pool |   90368 KB |  166912 KB |  270094 MB |  270006 MB |\n",
      "|       from small pool |    3002 KB |    3002 KB |     625 MB |     622 MB |\n",
      "|---------------------------------------------------------------------------|\n",
      "| Allocations           |     205    |     464    |   70201    |   69996    |\n",
      "|       from large pool |      75    |     171    |   44386    |   44311    |\n",
      "|       from small pool |     130    |     295    |   25815    |   25685    |\n",
      "|---------------------------------------------------------------------------|\n",
      "| Active allocs         |     205    |     464    |   70201    |   69996    |\n",
      "|       from large pool |      75    |     171    |   44386    |   44311    |\n",
      "|       from small pool |     130    |     295    |   25815    |   25685    |\n",
      "|---------------------------------------------------------------------------|\n",
      "| GPU reserved segments |      22    |      70    |      70    |      48    |\n",
      "|       from large pool |      20    |      67    |      67    |      47    |\n",
      "|       from small pool |       2    |       3    |       3    |       1    |\n",
      "|---------------------------------------------------------------------------|\n",
      "| Non-releasable allocs |      30    |      50    |   34931    |   34901    |\n",
      "|       from large pool |      24    |      43    |   24920    |   24896    |\n",
      "|       from small pool |       6    |      11    |   10011    |   10005    |\n",
      "|---------------------------------------------------------------------------|\n",
      "| Oversize allocations  |       0    |       0    |       0    |       0    |\n",
      "|---------------------------------------------------------------------------|\n",
      "| Oversize GPU segments |       0    |       0    |       0    |       0    |\n",
      "|===========================================================================|\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# torch.cuda.empty_cache()\n",
    "print(torch.cuda.memory_summary(device=None, abbreviated=False))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "e41b528a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Wall time: 16.9 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "model, losses = train_loop(model, clean_df, num_epochs=5, batch_size=16)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "74c2ec5c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[<matplotlib.lines.Line2D at 0x27ab2e46850>]"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.plot([i*5/len(losses) for i in range(len(losses))], losses)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "18ab6ea3",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
