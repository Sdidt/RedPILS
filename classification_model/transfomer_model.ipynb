{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/abhishekvaidyanathan/Desktop/RedPILS/redpils/lib/python3.9/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n",
      "[nltk_data] Error loading vader_lexicon: <urlopen error [SSL:\n",
      "[nltk_data]     CERTIFICATE_VERIFY_FAILED] certificate verify failed:\n",
      "[nltk_data]     unable to get local issuer certificate (_ssl.c:1129)>\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "device(type='cpu')"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import re\n",
    "import json\n",
    "import xgboost as xg\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import mean_squared_error, r2_score, confusion_matrix, classification_report\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn import linear_model\n",
    "from sklearn.decomposition import PCA, TruncatedSVD\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from collections import Counter\n",
    "from textblob import TextBlob\n",
    "import torch\n",
    "from torch import nn\n",
    "from transformers import AutoModelForSequenceClassification, AutoTokenizer, AutoModel\n",
    "import nltk\n",
    "from nltk.sentiment import SentimentIntensityAnalyzer\n",
    "nltk.download('vader_lexicon')\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "device"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# start here\n",
    "train_df = pd.read_csv('train_full.csv')\n",
    "eval_df = pd.read_csv('eval_full.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>clean_title</th>\n",
       "      <th>clean_comment</th>\n",
       "      <th>comment_id</th>\n",
       "      <th>url</th>\n",
       "      <th>target</th>\n",
       "      <th>true_label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>BJP Gujarat 2022 Manifesto.</td>\n",
       "      <td>There are two types of parties those that prom...</td>\n",
       "      <td>iy20u35</td>\n",
       "      <td>/r/IndiaSpeaks/comments/z5u6kf/bjp_gujarat_202...</td>\n",
       "      <td>0.00</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Rajasthan BJP MLA Sanjay Sharma posted this on...</td>\n",
       "      <td>If fundamentals are sound then, faith can help...</td>\n",
       "      <td>hnc96s6</td>\n",
       "      <td>/r/IndiaSpeaks/comments/r9df3s/rajasthan_bjp_m...</td>\n",
       "      <td>0.75</td>\n",
       "      <td>2.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>The new Indian If Trump's supporters blame Ant...</td>\n",
       "      <td>Contrary to popular belief, until Modi, India ...</td>\n",
       "      <td>giqnuc2</td>\n",
       "      <td>/r/india/comments/ku5i9f/the_new_indian_if_tru...</td>\n",
       "      <td>-0.50</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Kejriwal says that Mukesh Ambani's Antilia is ...</td>\n",
       "      <td>Bro inhone bahut land hijack kiya hai kisse pa...</td>\n",
       "      <td>iq3l8o5</td>\n",
       "      <td>/r/IndiaSpeaks/comments/xpb83d/kejriwal_says_t...</td>\n",
       "      <td>-0.25</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>The picture pretty much sums up the ideology o...</td>\n",
       "      <td>The 1.9 million denied citizenship in Assam al...</td>\n",
       "      <td>fbtqycg</td>\n",
       "      <td>/r/india/comments/ee11sp/the_picture_pretty_mu...</td>\n",
       "      <td>-1.00</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                         clean_title  \\\n",
       "0                        BJP Gujarat 2022 Manifesto.   \n",
       "1  Rajasthan BJP MLA Sanjay Sharma posted this on...   \n",
       "2  The new Indian If Trump's supporters blame Ant...   \n",
       "3  Kejriwal says that Mukesh Ambani's Antilia is ...   \n",
       "4  The picture pretty much sums up the ideology o...   \n",
       "\n",
       "                                       clean_comment comment_id  \\\n",
       "0  There are two types of parties those that prom...    iy20u35   \n",
       "1  If fundamentals are sound then, faith can help...    hnc96s6   \n",
       "2  Contrary to popular belief, until Modi, India ...    giqnuc2   \n",
       "3  Bro inhone bahut land hijack kiya hai kisse pa...    iq3l8o5   \n",
       "4  The 1.9 million denied citizenship in Assam al...    fbtqycg   \n",
       "\n",
       "                                                 url  target  true_label  \n",
       "0  /r/IndiaSpeaks/comments/z5u6kf/bjp_gujarat_202...    0.00         1.0  \n",
       "1  /r/IndiaSpeaks/comments/r9df3s/rajasthan_bjp_m...    0.75         2.0  \n",
       "2  /r/india/comments/ku5i9f/the_new_indian_if_tru...   -0.50         0.0  \n",
       "3  /r/IndiaSpeaks/comments/xpb83d/kejriwal_says_t...   -0.25         0.0  \n",
       "4  /r/india/comments/ee11sp/the_picture_pretty_mu...   -1.00         0.0  "
      ]
     },
     "execution_count": 53,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_df['true_label'] = train_df.apply(lambda x: np.sign(x['target'])+1, axis=1)\n",
    "train_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>clean_title</th>\n",
       "      <th>clean_comment</th>\n",
       "      <th>comment_id</th>\n",
       "      <th>url</th>\n",
       "      <th>target</th>\n",
       "      <th>true_label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>ResignModi trending in India on 1 with 200k tw...</td>\n",
       "      <td>People tend to look down on \"social media acti...</td>\n",
       "      <td>gwe056n</td>\n",
       "      <td>/r/india/comments/n11sqc/resignmodi_trending_i...</td>\n",
       "      <td>-0.5</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Put 'The Kashmir Files' on YouTube, everyone w...</td>\n",
       "      <td>I remember it was made to release twice, and t...</td>\n",
       "      <td>i1y3pv3</td>\n",
       "      <td>/r/india/comments/tmcun4/put_the_kashmir_files...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Kejriwal says 'The Kashmir Files' is a jhoothi...</td>\n",
       "      <td>Bhai delhi m hindu bht h but ye aur caste k lo...</td>\n",
       "      <td>i21haf8</td>\n",
       "      <td>/r/IndiaSpeaks/comments/tmhqqg/kejriwal_says_t...</td>\n",
       "      <td>0.5</td>\n",
       "      <td>2.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Government of India has Blacklisted Karl Rock ...</td>\n",
       "      <td>mahatma gandhi's shadows are fading. retards w...</td>\n",
       "      <td>h4lazw7</td>\n",
       "      <td>/r/india/comments/ogrc0d/government_of_india_h...</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Kejriwal says 'The Kashmir Files' is a jhoothi...</td>\n",
       "      <td>Isn't this kejru the same guy who kept tweetin...</td>\n",
       "      <td>i1yrkwx</td>\n",
       "      <td>/r/IndiaSpeaks/comments/tmhqqg/kejriwal_says_t...</td>\n",
       "      <td>0.5</td>\n",
       "      <td>2.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                         clean_title  \\\n",
       "0  ResignModi trending in India on 1 with 200k tw...   \n",
       "1  Put 'The Kashmir Files' on YouTube, everyone w...   \n",
       "2  Kejriwal says 'The Kashmir Files' is a jhoothi...   \n",
       "3  Government of India has Blacklisted Karl Rock ...   \n",
       "4  Kejriwal says 'The Kashmir Files' is a jhoothi...   \n",
       "\n",
       "                                       clean_comment comment_id  \\\n",
       "0  People tend to look down on \"social media acti...    gwe056n   \n",
       "1  I remember it was made to release twice, and t...    i1y3pv3   \n",
       "2  Bhai delhi m hindu bht h but ye aur caste k lo...    i21haf8   \n",
       "3  mahatma gandhi's shadows are fading. retards w...    h4lazw7   \n",
       "4  Isn't this kejru the same guy who kept tweetin...    i1yrkwx   \n",
       "\n",
       "                                                 url  target  true_label  \n",
       "0  /r/india/comments/n11sqc/resignmodi_trending_i...    -0.5         0.0  \n",
       "1  /r/india/comments/tmcun4/put_the_kashmir_files...     0.0         1.0  \n",
       "2  /r/IndiaSpeaks/comments/tmhqqg/kejriwal_says_t...     0.5         2.0  \n",
       "3  /r/india/comments/ogrc0d/government_of_india_h...    -1.0         0.0  \n",
       "4  /r/IndiaSpeaks/comments/tmhqqg/kejriwal_says_t...     0.5         2.0  "
      ]
     },
     "execution_count": 55,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "eval_df['true_label'] = eval_df.apply(lambda x: np.sign(x['target'])+1, axis=1)\n",
    "eval_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(62, 60)"
      ]
     },
     "execution_count": 56,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "right = \"\"\"right wing, RW, authority, hierarchy, order, duty, tradition, reaction, nationalism, conservative, right-libertarian, \\\n",
    "neoconservative, imperialist, monarchist, fascist, reactionaries, traditionalist, traditional, death penalty, \\\n",
    "religion, Bhajpa, BJP, Shiv Sena, RSS, MNS, Sanatan, dharm, Hindutva, Islamophobia, Narendra, Modi, Amit, Shah, \\\n",
    "mandir, ram, valmiki, ramayan, Bharatiya, Janata, Democratic Alliance, NDA, AIADMK, Janta Dal, bhakt, CAA, NRC, hindu majority, \\\n",
    "hindu unity, hindu pride, nationalist, sangh, sanghi, yogi, brahmin, brahman, smriti irani, hindu rashtra, jai shri ram, \\\n",
    "pm cares, pmcares, adani, hindu\"\"\".lower()\n",
    "left = \"\"\"left wing, LW, leftists, freedom, equality, fraternity, rights, progress, reform, internationalism, anarchist, communist, socialist, \\\n",
    "democratic socialist, social democrat, left-libertarian, progressive, social, liberal, western, Congress, UPA, RG, mamata, \\\n",
    "Aam, aadmi, AAP, CPI, Welfare, Protectionism, Commies, Rahul, gandhi, indira, yatra, arvind, kejriwal, inclusivity, \\\n",
    "libby, libbies, sjw, libtard, hinduphobia, LGBTQ, masjid, pappu, christian, muslim, secular, minority, minorities, Shashi, Tharoor, \\\n",
    "gay, lesbian, transgender, trans, reservation, abrahamic, godi\"\"\".lower()\n",
    "\n",
    "right_terms = set(right.split(', '))\n",
    "left_terms = set(left.split(', '))\n",
    "len(right_terms), len(left_terms)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "from tensorflow.keras import layers\n",
    "from keras.preprocessing.text import Tokenizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [],
   "source": [
    "class TransformerBlock(layers.Layer):\n",
    "    def __init__(self, embed_dim, num_heads, ff_dim, rate=0.1):\n",
    "        super().__init__()\n",
    "        self.att = layers.MultiHeadAttention(num_heads=num_heads, key_dim=embed_dim)\n",
    "        self.ffn = keras.Sequential(\n",
    "            [layers.Dense(ff_dim, activation=\"relu\"), layers.Dense(embed_dim),]\n",
    "        )\n",
    "        self.layernorm1 = layers.LayerNormalization(epsilon=1e-6)\n",
    "        self.layernorm2 = layers.LayerNormalization(epsilon=1e-6)\n",
    "        self.dropout1 = layers.Dropout(rate)\n",
    "        self.dropout2 = layers.Dropout(rate)\n",
    "\n",
    "    def call(self, inputs, training):\n",
    "        attn_output = self.att(inputs, inputs)\n",
    "        attn_output = self.dropout1(attn_output, training=training)\n",
    "        out1 = self.layernorm1(inputs + attn_output)\n",
    "        ffn_output = self.ffn(out1)\n",
    "        ffn_output = self.dropout2(ffn_output, training=training)\n",
    "        return self.layernorm2(out1 + ffn_output)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [],
   "source": [
    "class TokenAndPositionEmbedding(layers.Layer):\n",
    "    def __init__(self, maxlen, vocab_size, embed_dim):\n",
    "        super().__init__()\n",
    "        self.token_emb = layers.Embedding(input_dim=vocab_size, output_dim=embed_dim)\n",
    "        self.pos_emb = layers.Embedding(input_dim=maxlen, output_dim=embed_dim)\n",
    "\n",
    "    def call(self, x):\n",
    "        maxlen = tf.shape(x)[-1]\n",
    "        positions = tf.range(start=0, limit=maxlen, delta=1)\n",
    "        positions = self.pos_emb(positions)\n",
    "        x = self.token_emb(x)\n",
    "        return x + positions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_train = np.array(train_df['clean_comment'])\n",
    "y_train = np.array(train_df['true_label'])\n",
    "x_val = np.array(eval_df['clean_comment'])\n",
    "y_val = np.array(eval_df['true_label'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a tokenizer\n",
    "tokenizer = Tokenizer()\n",
    "\n",
    "# Fit the tokenizer on your text\n",
    "# tokenizer.fit_on_texts(x_train)\n",
    "x_train = tokenizer.texts_to_sequences(x_train)\n",
    "x_val = tokenizer.texts_to_sequences(x_val)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1999 Training sequences\n",
      "1000 Validation sequences\n"
     ]
    }
   ],
   "source": [
    "vocab_size = 20000  # Only consider the top 20k words\n",
    "maxlen = 50  # Only consider the first 200 words of each movie review\n",
    "# (x_train, y_train), (x_val, y_val) = keras.datasets.imdb.load_data(num_words=vocab_size)\n",
    "print(len(x_train), \"Training sequences\")\n",
    "print(len(x_val), \"Validation sequences\")\n",
    "x_train = keras.preprocessing.sequence.pad_sequences(x_train, maxlen=maxlen)\n",
    "x_val = keras.preprocessing.sequence.pad_sequences(x_val, maxlen=maxlen)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [],
   "source": [
    "embed_dim = 32  # Embedding size for each token\n",
    "num_heads = 8  # Number of attention heads\n",
    "ff_dim = 32  # Hidden layer size in feed forward network inside transformer\n",
    "\n",
    "inputs = layers.Input(shape=(maxlen,))\n",
    "embedding_layer = TokenAndPositionEmbedding(maxlen, vocab_size, embed_dim)\n",
    "x = embedding_layer(inputs)\n",
    "transformer_block = TransformerBlock(embed_dim, num_heads, ff_dim)\n",
    "x = transformer_block(x)\n",
    "x = layers.GlobalAveragePooling1D()(x)\n",
    "x = layers.Dropout(0.1)(x)\n",
    "x = layers.Dense(20, activation=\"relu\")(x)\n",
    "x = layers.Dropout(0.1)(x)\n",
    "outputs = layers.Dense(3, activation=\"softmax\")(x)\n",
    "outputs = (outputs - 1) * 2\n",
    "\n",
    "model = keras.Model(inputs=inputs, outputs=outputs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/2\n",
      "63/63 [==============================] - 5s 38ms/step - loss: 1.0986 - accuracy: 0.2881 - val_loss: 1.0986 - val_accuracy: 0.3350\n",
      "Epoch 2/2\n",
      "63/63 [==============================] - 2s 34ms/step - loss: 1.0986 - accuracy: 0.2996 - val_loss: 1.0986 - val_accuracy: 0.3350\n"
     ]
    }
   ],
   "source": [
    "model.compile(optimizer=\"adam\", loss=\"sparse_categorical_crossentropy\", metrics=[\"accuracy\"])\n",
    "history = model.fit(\n",
    "    x_train, y_train, batch_size=32, epochs=2, validation_data=(x_val, y_val)\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "redpils",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.6"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
