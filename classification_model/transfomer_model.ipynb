{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/abhishekvaidyanathan/Desktop/RedPILS/redpils/lib/python3.9/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n",
      "[nltk_data] Error loading vader_lexicon: <urlopen error [SSL:\n",
      "[nltk_data]     CERTIFICATE_VERIFY_FAILED] certificate verify failed:\n",
      "[nltk_data]     unable to get local issuer certificate (_ssl.c:1129)>\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "device(type='cpu')"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import re\n",
    "import json\n",
    "import xgboost as xg\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import mean_squared_error, r2_score, confusion_matrix, classification_report\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn import linear_model\n",
    "from sklearn.decomposition import PCA, TruncatedSVD\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from collections import Counter\n",
    "from textblob import TextBlob\n",
    "import torch\n",
    "from torch import nn\n",
    "from transformers import AutoModelForSequenceClassification, AutoTokenizer, AutoModel\n",
    "import nltk\n",
    "from nltk.sentiment import SentimentIntensityAnalyzer\n",
    "nltk.download('vader_lexicon')\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "device"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# start here\n",
    "train_df = pd.read_csv('train_full.csv')\n",
    "eval_df = pd.read_csv('eval_full.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>clean_title</th>\n",
       "      <th>clean_comment</th>\n",
       "      <th>comment_id</th>\n",
       "      <th>url</th>\n",
       "      <th>target</th>\n",
       "      <th>true_label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>BJP Gujarat 2022 Manifesto.</td>\n",
       "      <td>There are two types of parties those that prom...</td>\n",
       "      <td>iy20u35</td>\n",
       "      <td>/r/IndiaSpeaks/comments/z5u6kf/bjp_gujarat_202...</td>\n",
       "      <td>0.00</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Rajasthan BJP MLA Sanjay Sharma posted this on...</td>\n",
       "      <td>If fundamentals are sound then, faith can help...</td>\n",
       "      <td>hnc96s6</td>\n",
       "      <td>/r/IndiaSpeaks/comments/r9df3s/rajasthan_bjp_m...</td>\n",
       "      <td>0.75</td>\n",
       "      <td>2.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>The new Indian If Trump's supporters blame Ant...</td>\n",
       "      <td>Contrary to popular belief, until Modi, India ...</td>\n",
       "      <td>giqnuc2</td>\n",
       "      <td>/r/india/comments/ku5i9f/the_new_indian_if_tru...</td>\n",
       "      <td>-0.50</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Kejriwal says that Mukesh Ambani's Antilia is ...</td>\n",
       "      <td>Bro inhone bahut land hijack kiya hai kisse pa...</td>\n",
       "      <td>iq3l8o5</td>\n",
       "      <td>/r/IndiaSpeaks/comments/xpb83d/kejriwal_says_t...</td>\n",
       "      <td>-0.25</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>The picture pretty much sums up the ideology o...</td>\n",
       "      <td>The 1.9 million denied citizenship in Assam al...</td>\n",
       "      <td>fbtqycg</td>\n",
       "      <td>/r/india/comments/ee11sp/the_picture_pretty_mu...</td>\n",
       "      <td>-1.00</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                         clean_title  \\\n",
       "0                        BJP Gujarat 2022 Manifesto.   \n",
       "1  Rajasthan BJP MLA Sanjay Sharma posted this on...   \n",
       "2  The new Indian If Trump's supporters blame Ant...   \n",
       "3  Kejriwal says that Mukesh Ambani's Antilia is ...   \n",
       "4  The picture pretty much sums up the ideology o...   \n",
       "\n",
       "                                       clean_comment comment_id  \\\n",
       "0  There are two types of parties those that prom...    iy20u35   \n",
       "1  If fundamentals are sound then, faith can help...    hnc96s6   \n",
       "2  Contrary to popular belief, until Modi, India ...    giqnuc2   \n",
       "3  Bro inhone bahut land hijack kiya hai kisse pa...    iq3l8o5   \n",
       "4  The 1.9 million denied citizenship in Assam al...    fbtqycg   \n",
       "\n",
       "                                                 url  target  true_label  \n",
       "0  /r/IndiaSpeaks/comments/z5u6kf/bjp_gujarat_202...    0.00         1.0  \n",
       "1  /r/IndiaSpeaks/comments/r9df3s/rajasthan_bjp_m...    0.75         2.0  \n",
       "2  /r/india/comments/ku5i9f/the_new_indian_if_tru...   -0.50         0.0  \n",
       "3  /r/IndiaSpeaks/comments/xpb83d/kejriwal_says_t...   -0.25         0.0  \n",
       "4  /r/india/comments/ee11sp/the_picture_pretty_mu...   -1.00         0.0  "
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_df['true_label'] = train_df.apply(lambda x: np.sign(x['target'])+1, axis=1)\n",
    "train_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>clean_title</th>\n",
       "      <th>clean_comment</th>\n",
       "      <th>comment_id</th>\n",
       "      <th>url</th>\n",
       "      <th>target</th>\n",
       "      <th>true_label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>ResignModi trending in India on 1 with 200k tw...</td>\n",
       "      <td>People tend to look down on \"social media acti...</td>\n",
       "      <td>gwe056n</td>\n",
       "      <td>/r/india/comments/n11sqc/resignmodi_trending_i...</td>\n",
       "      <td>-0.5</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Put 'The Kashmir Files' on YouTube, everyone w...</td>\n",
       "      <td>I remember it was made to release twice, and t...</td>\n",
       "      <td>i1y3pv3</td>\n",
       "      <td>/r/india/comments/tmcun4/put_the_kashmir_files...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Kejriwal says 'The Kashmir Files' is a jhoothi...</td>\n",
       "      <td>Bhai delhi m hindu bht h but ye aur caste k lo...</td>\n",
       "      <td>i21haf8</td>\n",
       "      <td>/r/IndiaSpeaks/comments/tmhqqg/kejriwal_says_t...</td>\n",
       "      <td>0.5</td>\n",
       "      <td>2.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Government of India has Blacklisted Karl Rock ...</td>\n",
       "      <td>mahatma gandhi's shadows are fading. retards w...</td>\n",
       "      <td>h4lazw7</td>\n",
       "      <td>/r/india/comments/ogrc0d/government_of_india_h...</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Kejriwal says 'The Kashmir Files' is a jhoothi...</td>\n",
       "      <td>Isn't this kejru the same guy who kept tweetin...</td>\n",
       "      <td>i1yrkwx</td>\n",
       "      <td>/r/IndiaSpeaks/comments/tmhqqg/kejriwal_says_t...</td>\n",
       "      <td>0.5</td>\n",
       "      <td>2.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                         clean_title  \\\n",
       "0  ResignModi trending in India on 1 with 200k tw...   \n",
       "1  Put 'The Kashmir Files' on YouTube, everyone w...   \n",
       "2  Kejriwal says 'The Kashmir Files' is a jhoothi...   \n",
       "3  Government of India has Blacklisted Karl Rock ...   \n",
       "4  Kejriwal says 'The Kashmir Files' is a jhoothi...   \n",
       "\n",
       "                                       clean_comment comment_id  \\\n",
       "0  People tend to look down on \"social media acti...    gwe056n   \n",
       "1  I remember it was made to release twice, and t...    i1y3pv3   \n",
       "2  Bhai delhi m hindu bht h but ye aur caste k lo...    i21haf8   \n",
       "3  mahatma gandhi's shadows are fading. retards w...    h4lazw7   \n",
       "4  Isn't this kejru the same guy who kept tweetin...    i1yrkwx   \n",
       "\n",
       "                                                 url  target  true_label  \n",
       "0  /r/india/comments/n11sqc/resignmodi_trending_i...    -0.5         0.0  \n",
       "1  /r/india/comments/tmcun4/put_the_kashmir_files...     0.0         1.0  \n",
       "2  /r/IndiaSpeaks/comments/tmhqqg/kejriwal_says_t...     0.5         2.0  \n",
       "3  /r/india/comments/ogrc0d/government_of_india_h...    -1.0         0.0  \n",
       "4  /r/IndiaSpeaks/comments/tmhqqg/kejriwal_says_t...     0.5         2.0  "
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "eval_df['true_label'] = eval_df.apply(lambda x: np.sign(x['target'])+1, axis=1)\n",
    "eval_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(62, 60)"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "right = \"\"\"right wing, RW, authority, hierarchy, order, duty, tradition, reaction, nationalism, conservative, right-libertarian, \\\n",
    "neoconservative, imperialist, monarchist, fascist, reactionaries, traditionalist, traditional, death penalty, \\\n",
    "religion, Bhajpa, BJP, Shiv Sena, RSS, MNS, Sanatan, dharm, Hindutva, Islamophobia, Narendra, Modi, Amit, Shah, \\\n",
    "mandir, ram, valmiki, ramayan, Bharatiya, Janata, Democratic Alliance, NDA, AIADMK, Janta Dal, bhakt, CAA, NRC, hindu majority, \\\n",
    "hindu unity, hindu pride, nationalist, sangh, sanghi, yogi, brahmin, brahman, smriti irani, hindu rashtra, jai shri ram, \\\n",
    "pm cares, pmcares, adani, hindu\"\"\".lower()\n",
    "left = \"\"\"left wing, LW, leftists, freedom, equality, fraternity, rights, progress, reform, internationalism, anarchist, communist, socialist, \\\n",
    "democratic socialist, social democrat, left-libertarian, progressive, social, liberal, western, Congress, UPA, RG, mamata, \\\n",
    "Aam, aadmi, AAP, CPI, Welfare, Protectionism, Commies, Rahul, gandhi, indira, yatra, arvind, kejriwal, inclusivity, \\\n",
    "libby, libbies, sjw, libtard, hinduphobia, LGBTQ, masjid, pappu, christian, muslim, secular, minority, minorities, Shashi, Tharoor, \\\n",
    "gay, lesbian, transgender, trans, reservation, abrahamic, godi\"\"\".lower()\n",
    "\n",
    "right_terms = set(right.split(', '))\n",
    "left_terms = set(left.split(', '))\n",
    "len(right_terms), len(left_terms)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "list_right_terms = list(right_terms)\n",
    "list_left_terms = list(left_terms)\n",
    "full_terms = left_terms.union(right_terms)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def random_swap(term):\n",
    "    if term in left_terms:\n",
    "        # LW term being swapped\n",
    "        return np.random.choice(list_right_terms)\n",
    "    elif term in right_terms:\n",
    "        # RW term being swapped\n",
    "        return np.random.choice(list_left_terms)\n",
    "    print(f\"Error with: {term}\")\n",
    "\n",
    "def swap_terms(text):\n",
    "    term_match = re.compile('|'.join([r'\\b'+t for t in full_terms]))\n",
    "    \n",
    "    temp = term_match.sub(lambda m: random_swap(m.group()), text.lower())\n",
    "    return temp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>clean_comment</th>\n",
       "      <th>target</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>there are two types of parties those that prom...</td>\n",
       "      <td>0.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>if fundamentals are sound then, faith can help...</td>\n",
       "      <td>0.75</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>if fundamentals are sound then, faith can help...</td>\n",
       "      <td>-0.75</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>contrary to popular belief, until modi, india ...</td>\n",
       "      <td>-0.50</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>bro inhone bahut land hijack kiya hai kisse pa...</td>\n",
       "      <td>-0.25</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2512</th>\n",
       "      <td>if you had spent 5 min looking at the actual s...</td>\n",
       "      <td>0.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2513</th>\n",
       "      <td>he can look at education. that is something he...</td>\n",
       "      <td>0.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2514</th>\n",
       "      <td>it is good a initiative but the plastic in roa...</td>\n",
       "      <td>0.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2515</th>\n",
       "      <td>yup, been reading about it since couple of wee...</td>\n",
       "      <td>0.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2516</th>\n",
       "      <td>first i thought christmas ke chakkar me. then ...</td>\n",
       "      <td>0.00</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>2517 rows Ã— 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                          clean_comment  target\n",
       "0     there are two types of parties those that prom...    0.00\n",
       "1     if fundamentals are sound then, faith can help...    0.75\n",
       "2     if fundamentals are sound then, faith can help...   -0.75\n",
       "3     contrary to popular belief, until modi, india ...   -0.50\n",
       "4     bro inhone bahut land hijack kiya hai kisse pa...   -0.25\n",
       "...                                                 ...     ...\n",
       "2512  if you had spent 5 min looking at the actual s...    0.00\n",
       "2513  he can look at education. that is something he...    0.00\n",
       "2514  it is good a initiative but the plastic in roa...    0.00\n",
       "2515  yup, been reading about it since couple of wee...    0.00\n",
       "2516  first i thought christmas ke chakkar me. then ...    0.00\n",
       "\n",
       "[2517 rows x 2 columns]"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "aug_records = []\n",
    "for i, row in train_df.iterrows():\n",
    "    aug_records.append({'clean_comment':row['clean_comment'].lower(), 'target':row['target']})\n",
    "    # adding in record with swapped terms and opposite score\n",
    "    if(row['target']>0.0):\n",
    "        aug_records.append({'clean_comment':swap_terms(row['clean_comment']), 'target':-row['target']})\n",
    "        # aug_records.append({'clean_comment':swap_terms(row['clean_comment']), 'target':-row['target']})\n",
    "aug_df = pd.DataFrame.from_records(aug_records)\n",
    "aug_df"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# TFIDF Embeddings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1999, 92418) (1000, 92418)\n"
     ]
    }
   ],
   "source": [
    "vectorizer = TfidfVectorizer(ngram_range=(1, 2), analyzer='word')\n",
    "\n",
    "X_train = vectorizer.fit_transform(list(train_df['clean_comment']))\n",
    "X_test = vectorizer.transform(list(eval_df['clean_comment']))\n",
    "y_train, y_test = [np.sign(x)+1 for x in list(train_df['target'])], [np.sign(x)+1 for x in list(eval_df['target'])]\n",
    "\n",
    "print(X_train.shape, X_test.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'order': 0, 'bjp': 1, 'aap': 2, 'congress': 3, 'shashi': 4, 'tharoor': 5, 'hindu': 6, 'modi': 7, 'hindutva': 8, 'rights': 9, 'caa': 10, 'fascist': 11, 'western': 12, 'trans': 13, 'nationalism': 14, 'christian': 15, 'religion': 16, 'freedom': 17, 'social': 18, 'muslim': 19, 'right wing': 20, 'minority': 21, 'amit': 22, 'shah': 23, 'bharatiya': 24, 'janata': 25, 'kejriwal': 26, 'nationalist': 27, 'ram': 28, 'secular': 29, 'upa': 30, 'gandhi': 31, 'nda': 32, 'rw': 33, 'duty': 34, 'cpi': 35, 'hindu rashtra': 36, 'pappu': 37, 'minorities': 38, 'equality': 39, 'reservation': 40, 'commies': 41, 'yogi': 42, 'liberal': 43, 'mandir': 44, 'yatra': 45, 'smriti irani': 46, 'conservative': 47, 'lgbtq': 48, 'nrc': 49, 'progressive': 50, 'adani': 51, 'hierarchy': 52, 'reaction': 53, 'rahul': 54, 'welfare': 55, 'gay': 56, 'brahmin': 57, 'rss': 58, 'progress': 59, 'left wing': 60, 'ramayan': 61, 'indira': 62, 'janta dal': 63, 'islamophobia': 64, 'sangh': 65, 'bhakt': 66, 'leftists': 67, 'aam': 68, 'aadmi': 69, 'sanatan': 70, 'dharm': 71, 'sanghi': 72, 'socialist': 73, 'democratic socialist': 74, 'hindu unity': 75, 'narendra': 76, 'communist': 77, 'valmiki': 78, 'reform': 79, 'abrahamic': 80, 'arvind': 81, 'lw': 82, 'authority': 83, 'mamata': 84, 'aiadmk': 85, 'traditional': 86, 'transgender': 87, 'rg': 88, 'fraternity': 89, 'tradition': 90, 'hinduphobia': 91, 'pm cares': 92, 'masjid': 93, 'godi': 94, 'pmcares': 95, 'sjw': 96}\n"
     ]
    }
   ],
   "source": [
    "count = 0\n",
    "\n",
    "new_voc = {}\n",
    "for i in vectorizer.vocabulary_:\n",
    "    if (i in left_terms) or (i in right_terms):\n",
    "        new_voc[i] = count \n",
    "        count += 1 \n",
    "print(new_voc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1999, 97) (1000, 97)\n"
     ]
    }
   ],
   "source": [
    "vectorizer = TfidfVectorizer(ngram_range=(1, 2), analyzer='word', vocabulary=new_voc)\n",
    "\n",
    "x_train = vectorizer.fit_transform(list(train_df['clean_comment']))\n",
    "x_val = vectorizer.transform(list(eval_df['clean_comment']))\n",
    "y_train, y_val = [np.sign(x)+1 for x in list(train_df['target'])], [np.sign(x)+1 for x in list(eval_df['target'])]\n",
    "x_train = x_train.toarray()\n",
    "x_val = x_val.toarray()\n",
    "\n",
    "\n",
    "print(x_train.shape, x_val.shape)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Transformers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "from tensorflow.keras import layers\n",
    "from keras.preprocessing.text import Tokenizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "class TransformerBlock(layers.Layer):\n",
    "    def __init__(self, embed_dim, num_heads, ff_dim, rate=0.1):\n",
    "        super().__init__()\n",
    "        self.att = layers.MultiHeadAttention(num_heads=num_heads, key_dim=embed_dim)\n",
    "        self.ffn = keras.Sequential(\n",
    "            [layers.Dense(ff_dim, activation=\"relu\"), layers.Dense(embed_dim),]\n",
    "        )\n",
    "        self.layernorm1 = layers.LayerNormalization(epsilon=1e-6)\n",
    "        self.layernorm2 = layers.LayerNormalization(epsilon=1e-6)\n",
    "        self.dropout1 = layers.Dropout(rate)\n",
    "        self.dropout2 = layers.Dropout(rate)\n",
    "\n",
    "    def call(self, inputs, training):\n",
    "        attn_output = self.att(inputs, inputs)\n",
    "        attn_output = self.dropout1(attn_output, training=training)\n",
    "        out1 = self.layernorm1(inputs + attn_output)\n",
    "        ffn_output = self.ffn(out1)\n",
    "        ffn_output = self.dropout2(ffn_output, training=training)\n",
    "        return self.layernorm2(out1 + ffn_output)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "class TokenAndPositionEmbedding(layers.Layer):\n",
    "    def __init__(self, maxlen, vocab_size, embed_dim):\n",
    "        super().__init__()\n",
    "        self.token_emb = layers.Embedding(input_dim=vocab_size, output_dim=embed_dim)\n",
    "        self.pos_emb = layers.Embedding(input_dim=maxlen, output_dim=embed_dim)\n",
    "\n",
    "    def call(self, x):\n",
    "        maxlen = tf.shape(x)[-1]\n",
    "        positions = tf.range(start=0, limit=maxlen, delta=1)\n",
    "        positions = self.pos_emb(positions)\n",
    "        x = self.token_emb(x)\n",
    "        return x + positions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "convert_text_to_seq = 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "if convert_text_to_seq:\n",
    "    x_train = np.array(train_df['clean_comment'])\n",
    "    y_train = np.array(train_df['true_label'])\n",
    "    x_val = np.array(eval_df['clean_comment'])\n",
    "    y_val = np.array(eval_df['true_label'])\n",
    "\n",
    "    x_train_aug = np.array(aug_df['clean_comment'])\n",
    "    y_train_aug= np.array(aug_df['target'])\n",
    "\n",
    "    # Create a tokenizer\n",
    "    tokenizer = Tokenizer()\n",
    "\n",
    "    # Fit the tokenizer on your text\n",
    "    # tokenizer.fit_on_texts(x_train)\n",
    "    x_train = tokenizer.texts_to_sequences(x_train)\n",
    "    x_val = tokenizer.texts_to_sequences(x_val)\n",
    "    x_train_aug = tokenizer.texts_to_sequences(x_train_aug)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1999 Training sequences\n",
      "1000 Validation sequences\n"
     ]
    }
   ],
   "source": [
    "vocab_size = 20000  # Only consider the top 20k words\n",
    "maxlen = 50  # Only consider the first 200 words of each movie review\n",
    "# (x_train, y_train), (x_val, y_val) = keras.datasets.imdb.load_data(num_words=vocab_size)\n",
    "print(len(x_train), \"Training sequences\")\n",
    "print(len(x_val), \"Validation sequences\")\n",
    "x_train = keras.preprocessing.sequence.pad_sequences(x_train, maxlen=maxlen)\n",
    "x_val = keras.preprocessing.sequence.pad_sequences(x_val, maxlen=maxlen)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "embed_dim = 32  # Embedding size for each token\n",
    "num_heads = 8  # Number of attention heads\n",
    "ff_dim = 32  # Hidden layer size in feed forward network inside transformer\n",
    "\n",
    "inputs = layers.Input(shape=(maxlen,))\n",
    "embedding_layer = TokenAndPositionEmbedding(maxlen, vocab_size, embed_dim)\n",
    "x = embedding_layer(inputs)\n",
    "transformer_block = TransformerBlock(embed_dim, num_heads, ff_dim)\n",
    "x = transformer_block(x)\n",
    "x = layers.GlobalAveragePooling1D()(x)\n",
    "x = layers.Dropout(0.1)(x)\n",
    "x = layers.Dense(20, activation=\"relu\")(x)\n",
    "x = layers.Dropout(0.1)(x)\n",
    "outputs = layers.Dense(3, activation=\"softmax\")(x)\n",
    "outputs = (outputs - 1) * 2\n",
    "\n",
    "model = keras.Model(inputs=inputs, outputs=outputs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "Failed to find data adapter that can handle input: <class 'numpy.ndarray'>, (<class 'list'> containing values of types {\"<class 'numpy.float64'>\"})",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[47], line 2\u001b[0m\n\u001b[1;32m      1\u001b[0m model\u001b[39m.\u001b[39mcompile(optimizer\u001b[39m=\u001b[39m\u001b[39m\"\u001b[39m\u001b[39madam\u001b[39m\u001b[39m\"\u001b[39m, loss\u001b[39m=\u001b[39m\u001b[39m\"\u001b[39m\u001b[39msparse_categorical_crossentropy\u001b[39m\u001b[39m\"\u001b[39m, metrics\u001b[39m=\u001b[39m[\u001b[39m\"\u001b[39m\u001b[39maccuracy\u001b[39m\u001b[39m\"\u001b[39m])\n\u001b[0;32m----> 2\u001b[0m history \u001b[39m=\u001b[39m model\u001b[39m.\u001b[39;49mfit(\n\u001b[1;32m      3\u001b[0m     x_train, y_train, batch_size\u001b[39m=\u001b[39;49m\u001b[39m32\u001b[39;49m, epochs\u001b[39m=\u001b[39;49m\u001b[39m2\u001b[39;49m, validation_data\u001b[39m=\u001b[39;49m(x_val, y_val)\n\u001b[1;32m      4\u001b[0m )\n",
      "File \u001b[0;32m~/Desktop/RedPILS/redpils/lib/python3.9/site-packages/keras/utils/traceback_utils.py:70\u001b[0m, in \u001b[0;36mfilter_traceback.<locals>.error_handler\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m     67\u001b[0m     filtered_tb \u001b[39m=\u001b[39m _process_traceback_frames(e\u001b[39m.\u001b[39m__traceback__)\n\u001b[1;32m     68\u001b[0m     \u001b[39m# To get the full stack trace, call:\u001b[39;00m\n\u001b[1;32m     69\u001b[0m     \u001b[39m# `tf.debugging.disable_traceback_filtering()`\u001b[39;00m\n\u001b[0;32m---> 70\u001b[0m     \u001b[39mraise\u001b[39;00m e\u001b[39m.\u001b[39mwith_traceback(filtered_tb) \u001b[39mfrom\u001b[39;00m \u001b[39mNone\u001b[39m\n\u001b[1;32m     71\u001b[0m \u001b[39mfinally\u001b[39;00m:\n\u001b[1;32m     72\u001b[0m     \u001b[39mdel\u001b[39;00m filtered_tb\n",
      "File \u001b[0;32m~/Desktop/RedPILS/redpils/lib/python3.9/site-packages/keras/engine/data_adapter.py:1082\u001b[0m, in \u001b[0;36mselect_data_adapter\u001b[0;34m(x, y)\u001b[0m\n\u001b[1;32m   1079\u001b[0m adapter_cls \u001b[39m=\u001b[39m [\u001b[39mcls\u001b[39m \u001b[39mfor\u001b[39;00m \u001b[39mcls\u001b[39m \u001b[39min\u001b[39;00m ALL_ADAPTER_CLS \u001b[39mif\u001b[39;00m \u001b[39mcls\u001b[39m\u001b[39m.\u001b[39mcan_handle(x, y)]\n\u001b[1;32m   1080\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mnot\u001b[39;00m adapter_cls:\n\u001b[1;32m   1081\u001b[0m     \u001b[39m# TODO(scottzhu): This should be a less implementation-specific error.\u001b[39;00m\n\u001b[0;32m-> 1082\u001b[0m     \u001b[39mraise\u001b[39;00m \u001b[39mValueError\u001b[39;00m(\n\u001b[1;32m   1083\u001b[0m         \u001b[39m\"\u001b[39m\u001b[39mFailed to find data adapter that can handle input: \u001b[39m\u001b[39m{}\u001b[39;00m\u001b[39m, \u001b[39m\u001b[39m{}\u001b[39;00m\u001b[39m\"\u001b[39m\u001b[39m.\u001b[39mformat(\n\u001b[1;32m   1084\u001b[0m             _type_name(x), _type_name(y)\n\u001b[1;32m   1085\u001b[0m         )\n\u001b[1;32m   1086\u001b[0m     )\n\u001b[1;32m   1087\u001b[0m \u001b[39melif\u001b[39;00m \u001b[39mlen\u001b[39m(adapter_cls) \u001b[39m>\u001b[39m \u001b[39m1\u001b[39m:\n\u001b[1;32m   1088\u001b[0m     \u001b[39mraise\u001b[39;00m \u001b[39mRuntimeError\u001b[39;00m(\n\u001b[1;32m   1089\u001b[0m         \u001b[39m\"\u001b[39m\u001b[39mData adapters should be mutually exclusive for \u001b[39m\u001b[39m\"\u001b[39m\n\u001b[1;32m   1090\u001b[0m         \u001b[39m\"\u001b[39m\u001b[39mhandling inputs. Found multiple adapters \u001b[39m\u001b[39m{}\u001b[39;00m\u001b[39m to handle \u001b[39m\u001b[39m\"\u001b[39m\n\u001b[1;32m   1091\u001b[0m         \u001b[39m\"\u001b[39m\u001b[39minput: \u001b[39m\u001b[39m{}\u001b[39;00m\u001b[39m, \u001b[39m\u001b[39m{}\u001b[39;00m\u001b[39m\"\u001b[39m\u001b[39m.\u001b[39mformat(adapter_cls, _type_name(x), _type_name(y))\n\u001b[1;32m   1092\u001b[0m     )\n",
      "\u001b[0;31mValueError\u001b[0m: Failed to find data adapter that can handle input: <class 'numpy.ndarray'>, (<class 'list'> containing values of types {\"<class 'numpy.float64'>\"})"
     ]
    }
   ],
   "source": [
    "model.compile(optimizer=\"adam\", loss=\"sparse_categorical_crossentropy\", metrics=[\"accuracy\"])\n",
    "history = model.fit(\n",
    "    x_train, y_train, batch_size=32, epochs=2, validation_data=(x_val, y_val)\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "redpils",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.6"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
