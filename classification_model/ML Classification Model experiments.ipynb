{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "6e6ddfd3",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import re\n",
    "import json"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "0f32d896",
   "metadata": {},
   "outputs": [],
   "source": [
    "import xgboost as xg\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import mean_squared_error, r2_score\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn import linear_model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "015b626d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "device(type='cuda')"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import torch\n",
    "from torch import nn\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "device"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7c0afeb7",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "f4135694",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>submission_title</th>\n",
       "      <th>comment</th>\n",
       "      <th>comment_id</th>\n",
       "      <th>url</th>\n",
       "      <th>subreddit_id</th>\n",
       "      <th>label1</th>\n",
       "      <th>label2</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Shashi Tharoor Set To Run For Congress Preside...</td>\n",
       "      <td>Extremely valid points but I believe he has th...</td>\n",
       "      <td>ip5g6vu</td>\n",
       "      <td>/r/india/comments/xif8wm/shashi_tharoor_set_to...</td>\n",
       "      <td>2qh1q</td>\n",
       "      <td>-1</td>\n",
       "      <td>-1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Yogi government puts Kolkata's image as part o...</td>\n",
       "      <td>Even if the ad was designed by the newspaper -...</td>\n",
       "      <td>hcontm8</td>\n",
       "      <td>/r/india/comments/pmn9o3/yogi_government_puts_...</td>\n",
       "      <td>2qh1q</td>\n",
       "      <td>-1</td>\n",
       "      <td>-1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>An attempt to address the list of \"simplified\"...</td>\n",
       "      <td>Diverse population including Muslims. Welcomin...</td>\n",
       "      <td>fbhlv40</td>\n",
       "      <td>/r/india/comments/ebdeup/an_attempt_to_address...</td>\n",
       "      <td>2qh1q</td>\n",
       "      <td>-1</td>\n",
       "      <td>-2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>You guys noticing what's happening in Sri Lanka?</td>\n",
       "      <td>&gt;The blockade was done by your own people.\\n\\n...</td>\n",
       "      <td>i2yrud3</td>\n",
       "      <td>/r/india/comments/tt1ryh/you_guys_noticing_wha...</td>\n",
       "      <td>2qh1q</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Just got abused on the train by a hyper-nation...</td>\n",
       "      <td>Ohoo bahut bura laga ye sunke ki aap Undergarm...</td>\n",
       "      <td>hooi92k</td>\n",
       "      <td>/r/india/comments/rh2kcs/just_got_abused_on_th...</td>\n",
       "      <td>2qh1q</td>\n",
       "      <td>-2</td>\n",
       "      <td>-2</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                    submission_title  \\\n",
       "0  Shashi Tharoor Set To Run For Congress Preside...   \n",
       "1  Yogi government puts Kolkata's image as part o...   \n",
       "2  An attempt to address the list of \"simplified\"...   \n",
       "3   You guys noticing what's happening in Sri Lanka?   \n",
       "4  Just got abused on the train by a hyper-nation...   \n",
       "\n",
       "                                             comment comment_id  \\\n",
       "0  Extremely valid points but I believe he has th...    ip5g6vu   \n",
       "1  Even if the ad was designed by the newspaper -...    hcontm8   \n",
       "2  Diverse population including Muslims. Welcomin...    fbhlv40   \n",
       "3  >The blockade was done by your own people.\\n\\n...    i2yrud3   \n",
       "4  Ohoo bahut bura laga ye sunke ki aap Undergarm...    hooi92k   \n",
       "\n",
       "                                                 url subreddit_id  label1  \\\n",
       "0  /r/india/comments/xif8wm/shashi_tharoor_set_to...        2qh1q      -1   \n",
       "1  /r/india/comments/pmn9o3/yogi_government_puts_...        2qh1q      -1   \n",
       "2  /r/india/comments/ebdeup/an_attempt_to_address...        2qh1q      -1   \n",
       "3  /r/india/comments/tt1ryh/you_guys_noticing_wha...        2qh1q       0   \n",
       "4  /r/india/comments/rh2kcs/just_got_abused_on_th...        2qh1q      -2   \n",
       "\n",
       "   label2  \n",
       "0      -1  \n",
       "1      -1  \n",
       "2      -2  \n",
       "3       0  \n",
       "4      -2  "
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "text_df = pd.read_csv(\"training_subset.csv\")\n",
    "text_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "5ee1dbb3",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>label1</th>\n",
       "      <th>label2</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>2045.000000</td>\n",
       "      <td>2045.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>-0.061125</td>\n",
       "      <td>-0.094866</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>0.884571</td>\n",
       "      <td>0.968081</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>-2.000000</td>\n",
       "      <td>-2.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>-1.000000</td>\n",
       "      <td>-1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>2.000000</td>\n",
       "      <td>2.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "            label1       label2\n",
       "count  2045.000000  2045.000000\n",
       "mean     -0.061125    -0.094866\n",
       "std       0.884571     0.968081\n",
       "min      -2.000000    -2.000000\n",
       "25%      -1.000000    -1.000000\n",
       "50%       0.000000     0.000000\n",
       "75%       0.000000     0.000000\n",
       "max       2.000000     2.000000"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "text_df.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "0a0698c5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>submission_title</th>\n",
       "      <th>comment</th>\n",
       "      <th>comment_id</th>\n",
       "      <th>url</th>\n",
       "      <th>subreddit_id</th>\n",
       "      <th>label1</th>\n",
       "      <th>label2</th>\n",
       "      <th>avg_score</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Shashi Tharoor Set To Run For Congress Preside...</td>\n",
       "      <td>Extremely valid points but I believe he has th...</td>\n",
       "      <td>ip5g6vu</td>\n",
       "      <td>/r/india/comments/xif8wm/shashi_tharoor_set_to...</td>\n",
       "      <td>2qh1q</td>\n",
       "      <td>-1</td>\n",
       "      <td>-1</td>\n",
       "      <td>-1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Yogi government puts Kolkata's image as part o...</td>\n",
       "      <td>Even if the ad was designed by the newspaper -...</td>\n",
       "      <td>hcontm8</td>\n",
       "      <td>/r/india/comments/pmn9o3/yogi_government_puts_...</td>\n",
       "      <td>2qh1q</td>\n",
       "      <td>-1</td>\n",
       "      <td>-1</td>\n",
       "      <td>-1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>An attempt to address the list of \"simplified\"...</td>\n",
       "      <td>Diverse population including Muslims. Welcomin...</td>\n",
       "      <td>fbhlv40</td>\n",
       "      <td>/r/india/comments/ebdeup/an_attempt_to_address...</td>\n",
       "      <td>2qh1q</td>\n",
       "      <td>-1</td>\n",
       "      <td>-2</td>\n",
       "      <td>-1.5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>You guys noticing what's happening in Sri Lanka?</td>\n",
       "      <td>&gt;The blockade was done by your own people.\\n\\n...</td>\n",
       "      <td>i2yrud3</td>\n",
       "      <td>/r/india/comments/tt1ryh/you_guys_noticing_wha...</td>\n",
       "      <td>2qh1q</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Just got abused on the train by a hyper-nation...</td>\n",
       "      <td>Ohoo bahut bura laga ye sunke ki aap Undergarm...</td>\n",
       "      <td>hooi92k</td>\n",
       "      <td>/r/india/comments/rh2kcs/just_got_abused_on_th...</td>\n",
       "      <td>2qh1q</td>\n",
       "      <td>-2</td>\n",
       "      <td>-2</td>\n",
       "      <td>-2.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                    submission_title  \\\n",
       "0  Shashi Tharoor Set To Run For Congress Preside...   \n",
       "1  Yogi government puts Kolkata's image as part o...   \n",
       "2  An attempt to address the list of \"simplified\"...   \n",
       "3   You guys noticing what's happening in Sri Lanka?   \n",
       "4  Just got abused on the train by a hyper-nation...   \n",
       "\n",
       "                                             comment comment_id  \\\n",
       "0  Extremely valid points but I believe he has th...    ip5g6vu   \n",
       "1  Even if the ad was designed by the newspaper -...    hcontm8   \n",
       "2  Diverse population including Muslims. Welcomin...    fbhlv40   \n",
       "3  >The blockade was done by your own people.\\n\\n...    i2yrud3   \n",
       "4  Ohoo bahut bura laga ye sunke ki aap Undergarm...    hooi92k   \n",
       "\n",
       "                                                 url subreddit_id  label1  \\\n",
       "0  /r/india/comments/xif8wm/shashi_tharoor_set_to...        2qh1q      -1   \n",
       "1  /r/india/comments/pmn9o3/yogi_government_puts_...        2qh1q      -1   \n",
       "2  /r/india/comments/ebdeup/an_attempt_to_address...        2qh1q      -1   \n",
       "3  /r/india/comments/tt1ryh/you_guys_noticing_wha...        2qh1q       0   \n",
       "4  /r/india/comments/rh2kcs/just_got_abused_on_th...        2qh1q      -2   \n",
       "\n",
       "   label2  avg_score  \n",
       "0      -1       -1.0  \n",
       "1      -1       -1.0  \n",
       "2      -2       -1.5  \n",
       "3       0        0.0  \n",
       "4      -2       -2.0  "
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "text_df['avg_score'] = text_df.apply(lambda x: np.mean(x[5:]), axis=1)\n",
    "text_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "69d4dcf1",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>label1</th>\n",
       "      <th>label2</th>\n",
       "      <th>avg_score</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>2045.000000</td>\n",
       "      <td>2045.000000</td>\n",
       "      <td>2045.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>-0.061125</td>\n",
       "      <td>-0.094866</td>\n",
       "      <td>-0.077995</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>0.884571</td>\n",
       "      <td>0.968081</td>\n",
       "      <td>0.866536</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>-2.000000</td>\n",
       "      <td>-2.000000</td>\n",
       "      <td>-2.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>-1.000000</td>\n",
       "      <td>-1.000000</td>\n",
       "      <td>-0.500000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.500000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>2.000000</td>\n",
       "      <td>2.000000</td>\n",
       "      <td>2.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "            label1       label2    avg_score\n",
       "count  2045.000000  2045.000000  2045.000000\n",
       "mean     -0.061125    -0.094866    -0.077995\n",
       "std       0.884571     0.968081     0.866536\n",
       "min      -2.000000    -2.000000    -2.000000\n",
       "25%      -1.000000    -1.000000    -0.500000\n",
       "50%       0.000000     0.000000     0.000000\n",
       "75%       0.000000     0.000000     0.500000\n",
       "max       2.000000     2.000000     2.000000"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "text_df.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "524f970c",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "32ef3cac",
   "metadata": {},
   "source": [
    "## Text Cleaning\n",
    " - Remove all quotes of previous comments (starts with \">\" and ends with newline)\n",
    " - Remove special characters other than ,.'\"?!\n",
    " - Remove links"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "a074e901",
   "metadata": {},
   "outputs": [],
   "source": [
    "def clean_quotations(text):\n",
    "    temp = re.sub(r'>.*?\\n', '', text)\n",
    "    return temp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "de7b5d9c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# clean_punc = re.compile('[^a-zA-Z0-9\\s]')\n",
    "# print(clean_punc.sub('', reviews[0][\"text\"][0].lower()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "028815bb",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\">The blockade was done by your own people.\\n\\nWhat a joke. \\n\\n>The simple truth is that your communist party aligned with China and created propaganda against India.\\n\\nThey didn't create any propaganda. India helped their civil war. They are puppet of India. Majority of them have no courage to talk anything about India. \\n\\nPeople in India die due to Koshi that's why India wants to construct another larger dam so that only Nepali would die.\\n\\nAnd another simple explanation, when India initiated a road in Lipulekh Kalapani area (which according to Sugauli treaty) is part of Nepal. India never talked about it with Nepal. Because India dissolved the treaty without Nepal's agreement. \\n\\nWhen every argument ends, we have common culture is your ultimate sword.\""
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "text_df['comment'][3]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "baf3e5cf",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"\\nWhat a joke. \\n\\n\\nThey didn't create any propaganda. India helped their civil war. They are puppet of India. Majority of them have no courage to talk anything about India. \\n\\nPeople in India die due to Koshi that's why India wants to construct another larger dam so that only Nepali would die.\\n\\nAnd another simple explanation, when India initiated a road in Lipulekh Kalapani area (which according to Sugauli treaty) is part of Nepal. India never talked about it with Nepal. Because India dissolved the treaty without Nepal's agreement. \\n\\nWhen every argument ends, we have common culture is your ultimate sword.\""
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "clean_quotations(text_df['comment'][3])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "9910f4a2",
   "metadata": {},
   "outputs": [],
   "source": [
    "def clean_url(text):\n",
    "    temp = re.sub(r'(http(s)?:\\/\\/.)?(www\\.)?[-a-zA-Z0-9@:%._\\+~#=]{2,256}\\.[a-z]{2,6}\\b([-a-zA-Z0-9@:%_\\+\\.~#?&\\/=]*)', '', text)\n",
    "    return temp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "0837a5db",
   "metadata": {},
   "outputs": [],
   "source": [
    "def clean_text(text):\n",
    "    temp = clean_quotations(text)\n",
    "    temp = clean_url(temp)\n",
    "    temp = re.sub(r'[^a-zA-Z0-9\\s\\.,?!\\'\\\"]', ' ', temp)\n",
    "    temp = re.sub(r'\\s+', ' ', temp)  # replace multiple spaces with single space\n",
    "    return temp.strip()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "8d8abdad",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"What a joke. They didn't create any propaganda. India helped their civil war. They are puppet of India. Majority of them have no courage to talk anything about India. People in India die due to Koshi that's why India wants to construct another larger dam so that only Nepali would die. And another simple explanation, when India initiated a road in Lipulekh Kalapani area which according to Sugauli treaty is part of Nepal. India never talked about it with Nepal. Because India dissolved the treaty without Nepal's agreement. When every argument ends, we have common culture is your ultimate sword.\""
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "clean_text(text_df['comment'][3])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "8ec1fc9e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Attempt at more elaborate translation, for those who might be interested:\n",
      "\n",
      "> They are plastering one movie's posters all over the place.\n",
      "> \n",
      "> The whole of BJP cadre is involved in plastering such posters.\n",
      "> \n",
      "> This is why you came in poltics? To plaster... what will you tell you children at home when they ask what do you do for living? - *I plaster movie's posters.*\n",
      "> \n",
      "> They are saying that Kashmir Files should be tax free, why not just upload it on Youtube? It'll be all free free.\n",
      "> \n",
      "> Why are you getting it tax free? Just ask Vivek Agnihotri to put it all on Youtube, it will all be free for everybody to watch.\n",
      "> \n",
      "> I read something in the newspaper yesterday - there's a Haryana BJP MLA who said that he will get a free screening of the movie held in some park - immediately, Vivek posted on twitter addressing Manohar Lal Khattar about this free screening and asking him to tell that MLA to pay for that screening. \n",
      "> \n",
      "> Listen, some guys are earning crores out of Kashmiri Pandits' tragedy, and you guys are plastering posters on the walls for them. Open your eyes! What has become of you people? \n",
      "> \n",
      "> After eight years of ruling a country, if that country's Prime Minister has to bend his knees in front of Vivek Agnihotri, it means that PM hasn't done any work in all those years.\n",
      "\n",
      "**Edit**: Full video here - https://youtube.com/watch?v=6zLEV34OZKA\n"
     ]
    }
   ],
   "source": [
    "print(text_df['comment'][14])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "20204588",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Attempt at more elaborate translation, for those who might be interested Edit Full video here'"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "clean_text(text_df['comment'][14])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "5d03fca9",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>clean_title</th>\n",
       "      <th>clean_comment</th>\n",
       "      <th>url</th>\n",
       "      <th>avg_score</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Shashi Tharoor Set To Run For Congress Preside...</td>\n",
       "      <td>Extremely valid points but I believe he has th...</td>\n",
       "      <td>/r/india/comments/xif8wm/shashi_tharoor_set_to...</td>\n",
       "      <td>-1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Yogi government puts Kolkata's image as part o...</td>\n",
       "      <td>Even if the ad was designed by the newspaper t...</td>\n",
       "      <td>/r/india/comments/pmn9o3/yogi_government_puts_...</td>\n",
       "      <td>-1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>An attempt to address the list of \"simplified\"...</td>\n",
       "      <td>Diverse population including Muslims. Welcomin...</td>\n",
       "      <td>/r/india/comments/ebdeup/an_attempt_to_address...</td>\n",
       "      <td>-1.5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>You guys noticing what's happening in Sri Lanka?</td>\n",
       "      <td>What a joke. They didn't create any propaganda...</td>\n",
       "      <td>/r/india/comments/tt1ryh/you_guys_noticing_wha...</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Just got abused on the train by a hyper nation...</td>\n",
       "      <td>Ohoo bahut bura laga ye sunke ki aap Undergarm...</td>\n",
       "      <td>/r/india/comments/rh2kcs/just_got_abused_on_th...</td>\n",
       "      <td>-2.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                         clean_title  \\\n",
       "0  Shashi Tharoor Set To Run For Congress Preside...   \n",
       "1  Yogi government puts Kolkata's image as part o...   \n",
       "2  An attempt to address the list of \"simplified\"...   \n",
       "3   You guys noticing what's happening in Sri Lanka?   \n",
       "4  Just got abused on the train by a hyper nation...   \n",
       "\n",
       "                                       clean_comment  \\\n",
       "0  Extremely valid points but I believe he has th...   \n",
       "1  Even if the ad was designed by the newspaper t...   \n",
       "2  Diverse population including Muslims. Welcomin...   \n",
       "3  What a joke. They didn't create any propaganda...   \n",
       "4  Ohoo bahut bura laga ye sunke ki aap Undergarm...   \n",
       "\n",
       "                                                 url  avg_score  \n",
       "0  /r/india/comments/xif8wm/shashi_tharoor_set_to...       -1.0  \n",
       "1  /r/india/comments/pmn9o3/yogi_government_puts_...       -1.0  \n",
       "2  /r/india/comments/ebdeup/an_attempt_to_address...       -1.5  \n",
       "3  /r/india/comments/tt1ryh/you_guys_noticing_wha...        0.0  \n",
       "4  /r/india/comments/rh2kcs/just_got_abused_on_th...       -2.0  "
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "clean_df = pd.DataFrame()\n",
    "clean_df['clean_title'] = text_df.apply(lambda x: clean_text(x['submission_title']), axis=1)\n",
    "clean_df['clean_comment'] = text_df.apply(lambda x: clean_text(x['comment']), axis=1)\n",
    "clean_df[['url', 'avg_score']] = text_df[['url', 'avg_score']]\n",
    "clean_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "58f1f1d7",
   "metadata": {},
   "outputs": [],
   "source": [
    "clean_df.to_csv(\"cleaned_subset.csv\", index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e01d1c1d",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "c9a6f4d7",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>clean_title</th>\n",
       "      <th>clean_comment</th>\n",
       "      <th>url</th>\n",
       "      <th>avg_score</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Shashi Tharoor Set To Run For Congress Preside...</td>\n",
       "      <td>Extremely valid points but I believe he has th...</td>\n",
       "      <td>/r/india/comments/xif8wm/shashi_tharoor_set_to...</td>\n",
       "      <td>-1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Yogi government puts Kolkata's image as part o...</td>\n",
       "      <td>Even if the ad was designed by the newspaper t...</td>\n",
       "      <td>/r/india/comments/pmn9o3/yogi_government_puts_...</td>\n",
       "      <td>-1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>An attempt to address the list of \"simplified\"...</td>\n",
       "      <td>Diverse population including Muslims. Welcomin...</td>\n",
       "      <td>/r/india/comments/ebdeup/an_attempt_to_address...</td>\n",
       "      <td>-1.5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>You guys noticing what's happening in Sri Lanka?</td>\n",
       "      <td>What a joke. They didn't create any propaganda...</td>\n",
       "      <td>/r/india/comments/tt1ryh/you_guys_noticing_wha...</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Just got abused on the train by a hyper nation...</td>\n",
       "      <td>Ohoo bahut bura laga ye sunke ki aap Undergarm...</td>\n",
       "      <td>/r/india/comments/rh2kcs/just_got_abused_on_th...</td>\n",
       "      <td>-2.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                         clean_title  \\\n",
       "0  Shashi Tharoor Set To Run For Congress Preside...   \n",
       "1  Yogi government puts Kolkata's image as part o...   \n",
       "2  An attempt to address the list of \"simplified\"...   \n",
       "3   You guys noticing what's happening in Sri Lanka?   \n",
       "4  Just got abused on the train by a hyper nation...   \n",
       "\n",
       "                                       clean_comment  \\\n",
       "0  Extremely valid points but I believe he has th...   \n",
       "1  Even if the ad was designed by the newspaper t...   \n",
       "2  Diverse population including Muslims. Welcomin...   \n",
       "3  What a joke. They didn't create any propaganda...   \n",
       "4  Ohoo bahut bura laga ye sunke ki aap Undergarm...   \n",
       "\n",
       "                                                 url  avg_score  \n",
       "0  /r/india/comments/xif8wm/shashi_tharoor_set_to...       -1.0  \n",
       "1  /r/india/comments/pmn9o3/yogi_government_puts_...       -1.0  \n",
       "2  /r/india/comments/ebdeup/an_attempt_to_address...       -1.5  \n",
       "3  /r/india/comments/tt1ryh/you_guys_noticing_wha...        0.0  \n",
       "4  /r/india/comments/rh2kcs/just_got_abused_on_th...       -2.0  "
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "clean_df = pd.read_csv(\"cleaned_subset.csv\")\n",
    "clean_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "8da45c61",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 2045 entries, 0 to 2044\n",
      "Data columns (total 4 columns):\n",
      " #   Column         Non-Null Count  Dtype  \n",
      "---  ------         --------------  -----  \n",
      " 0   clean_title    2045 non-null   object \n",
      " 1   clean_comment  2044 non-null   object \n",
      " 2   url            2045 non-null   object \n",
      " 3   avg_score      2045 non-null   float64\n",
      "dtypes: float64(1), object(3)\n",
      "memory usage: 64.0+ KB\n"
     ]
    }
   ],
   "source": [
    "clean_df.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "c1ed1907",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "Int64Index: 2044 entries, 0 to 2044\n",
      "Data columns (total 4 columns):\n",
      " #   Column         Non-Null Count  Dtype  \n",
      "---  ------         --------------  -----  \n",
      " 0   clean_title    2044 non-null   object \n",
      " 1   clean_comment  2044 non-null   object \n",
      " 2   url            2044 non-null   object \n",
      " 3   avg_score      2044 non-null   float64\n",
      "dtypes: float64(1), object(3)\n",
      "memory usage: 79.8+ KB\n"
     ]
    }
   ],
   "source": [
    "clean_df.dropna(inplace=True)\n",
    "clean_df.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "b13ae052",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>clean_title</th>\n",
       "      <th>clean_comment</th>\n",
       "      <th>url</th>\n",
       "      <th>avg_score</th>\n",
       "      <th>target</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Shashi Tharoor Set To Run For Congress Preside...</td>\n",
       "      <td>Extremely valid points but I believe he has th...</td>\n",
       "      <td>/r/india/comments/xif8wm/shashi_tharoor_set_to...</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-0.50</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Yogi government puts Kolkata's image as part o...</td>\n",
       "      <td>Even if the ad was designed by the newspaper t...</td>\n",
       "      <td>/r/india/comments/pmn9o3/yogi_government_puts_...</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-0.50</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>An attempt to address the list of \"simplified\"...</td>\n",
       "      <td>Diverse population including Muslims. Welcomin...</td>\n",
       "      <td>/r/india/comments/ebdeup/an_attempt_to_address...</td>\n",
       "      <td>-1.5</td>\n",
       "      <td>-0.75</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>You guys noticing what's happening in Sri Lanka?</td>\n",
       "      <td>What a joke. They didn't create any propaganda...</td>\n",
       "      <td>/r/india/comments/tt1ryh/you_guys_noticing_wha...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Just got abused on the train by a hyper nation...</td>\n",
       "      <td>Ohoo bahut bura laga ye sunke ki aap Undergarm...</td>\n",
       "      <td>/r/india/comments/rh2kcs/just_got_abused_on_th...</td>\n",
       "      <td>-2.0</td>\n",
       "      <td>-1.00</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                         clean_title  \\\n",
       "0  Shashi Tharoor Set To Run For Congress Preside...   \n",
       "1  Yogi government puts Kolkata's image as part o...   \n",
       "2  An attempt to address the list of \"simplified\"...   \n",
       "3   You guys noticing what's happening in Sri Lanka?   \n",
       "4  Just got abused on the train by a hyper nation...   \n",
       "\n",
       "                                       clean_comment  \\\n",
       "0  Extremely valid points but I believe he has th...   \n",
       "1  Even if the ad was designed by the newspaper t...   \n",
       "2  Diverse population including Muslims. Welcomin...   \n",
       "3  What a joke. They didn't create any propaganda...   \n",
       "4  Ohoo bahut bura laga ye sunke ki aap Undergarm...   \n",
       "\n",
       "                                                 url  avg_score  target  \n",
       "0  /r/india/comments/xif8wm/shashi_tharoor_set_to...       -1.0   -0.50  \n",
       "1  /r/india/comments/pmn9o3/yogi_government_puts_...       -1.0   -0.50  \n",
       "2  /r/india/comments/ebdeup/an_attempt_to_address...       -1.5   -0.75  \n",
       "3  /r/india/comments/tt1ryh/you_guys_noticing_wha...        0.0    0.00  \n",
       "4  /r/india/comments/rh2kcs/just_got_abused_on_th...       -2.0   -1.00  "
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "clean_df['target'] = clean_df['avg_score']/2\n",
    "clean_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "55b387c4",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "c434e4fd",
   "metadata": {},
   "source": [
    "## Rule-based classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7a73476a",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2c880ba3",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "24a146cb",
   "metadata": {},
   "source": [
    "## BERT-based classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "985802f8",
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import AutoTokenizer, AutoModelForMaskedLM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "c8a87a03",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "|===========================================================================|\n",
      "|                  PyTorch CUDA memory summary, device ID 0                 |\n",
      "|---------------------------------------------------------------------------|\n",
      "|            CUDA OOMs: 0            |        cudaMalloc retries: 0         |\n",
      "|===========================================================================|\n",
      "|        Metric         | Cur Usage  | Peak Usage | Tot Alloc  | Tot Freed  |\n",
      "|---------------------------------------------------------------------------|\n",
      "| Allocated memory      |       0 B  |       0 B  |       0 B  |       0 B  |\n",
      "|       from large pool |       0 B  |       0 B  |       0 B  |       0 B  |\n",
      "|       from small pool |       0 B  |       0 B  |       0 B  |       0 B  |\n",
      "|---------------------------------------------------------------------------|\n",
      "| Active memory         |       0 B  |       0 B  |       0 B  |       0 B  |\n",
      "|       from large pool |       0 B  |       0 B  |       0 B  |       0 B  |\n",
      "|       from small pool |       0 B  |       0 B  |       0 B  |       0 B  |\n",
      "|---------------------------------------------------------------------------|\n",
      "| GPU reserved memory   |       0 B  |       0 B  |       0 B  |       0 B  |\n",
      "|       from large pool |       0 B  |       0 B  |       0 B  |       0 B  |\n",
      "|       from small pool |       0 B  |       0 B  |       0 B  |       0 B  |\n",
      "|---------------------------------------------------------------------------|\n",
      "| Non-releasable memory |       0 B  |       0 B  |       0 B  |       0 B  |\n",
      "|       from large pool |       0 B  |       0 B  |       0 B  |       0 B  |\n",
      "|       from small pool |       0 B  |       0 B  |       0 B  |       0 B  |\n",
      "|---------------------------------------------------------------------------|\n",
      "| Allocations           |       0    |       0    |       0    |       0    |\n",
      "|       from large pool |       0    |       0    |       0    |       0    |\n",
      "|       from small pool |       0    |       0    |       0    |       0    |\n",
      "|---------------------------------------------------------------------------|\n",
      "| Active allocs         |       0    |       0    |       0    |       0    |\n",
      "|       from large pool |       0    |       0    |       0    |       0    |\n",
      "|       from small pool |       0    |       0    |       0    |       0    |\n",
      "|---------------------------------------------------------------------------|\n",
      "| GPU reserved segments |       0    |       0    |       0    |       0    |\n",
      "|       from large pool |       0    |       0    |       0    |       0    |\n",
      "|       from small pool |       0    |       0    |       0    |       0    |\n",
      "|---------------------------------------------------------------------------|\n",
      "| Non-releasable allocs |       0    |       0    |       0    |       0    |\n",
      "|       from large pool |       0    |       0    |       0    |       0    |\n",
      "|       from small pool |       0    |       0    |       0    |       0    |\n",
      "|---------------------------------------------------------------------------|\n",
      "| Oversize allocations  |       0    |       0    |       0    |       0    |\n",
      "|---------------------------------------------------------------------------|\n",
      "| Oversize GPU segments |       0    |       0    |       0    |       0    |\n",
      "|===========================================================================|\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(torch.cuda.memory_summary(device=None, abbreviated=False))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5735a634",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "3d3df4ef",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "615d4138e94a48bc964fdb830821cb5d",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading vocab.txt: 0.00B [00:00, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "tokenizer = AutoTokenizer.from_pretrained(\"google/muril-base-cased\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d67bffd0",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "89a8b9f6",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'input_ids': tensor([[   104,  96009,   1691,  38666,   6810,   1363,    148,   8994,   1157,\n",
       "           1207,   1108,  19794,   4394,   1192,   1113,   6952,   1750,  16762,\n",
       "          10743,   1341,   1121,   7783,   1108,   1936,  31551,  24418,  51325,\n",
       "           4382,  60648,    121,   7154,    119,    148,   1678,   5526,   1725,\n",
       "          44165,   6127,   2959, 183153, 159371,   1207,    172,  12521,   1109,\n",
       "          49676,   2219,   2733,   9610,   1113,   9989,   1147,    121,    105,\n",
       "              0,      0,      0,      0,      0,      0,      0,      0,      0,\n",
       "              0,      0,      0,      0,      0,      0,      0,      0,      0,\n",
       "              0,      0,      0,      0,      0,      0,      0,      0,      0,\n",
       "              0,      0,      0,      0,      0,      0,      0,      0,      0,\n",
       "              0,      0,      0,      0,      0,      0,      0,      0,      0,\n",
       "              0,      0,      0,      0,      0,      0,      0,      0,      0,\n",
       "              0,      0,      0,      0,      0,      0,      0,      0,      0,\n",
       "              0,      0,      0,      0,      0,      0,      0,      0,      0,\n",
       "              0,      0,      0,      0,      0,      0,      0,      0,      0,\n",
       "              0,      0,      0,      0,      0,      0,      0,      0,      0,\n",
       "              0,      0,      0,      0,      0,      0,      0,      0,      0,\n",
       "              0,      0,      0,      0,      0,      0,      0,      0,      0,\n",
       "              0,      0,      0,      0,      0,      0,      0,      0,      0,\n",
       "              0,      0,      0,      0,      0,      0,      0,      0,      0,\n",
       "              0,      0,      0,      0,      0,      0,      0,      0,      0,\n",
       "              0,      0,      0,      0,      0,      0,      0,      0,      0,\n",
       "              0,      0,      0,      0,      0,      0,      0,      0,      0,\n",
       "              0,      0,      0,      0,      0,      0,      0,      0,      0,\n",
       "              0,      0,      0,      0,      0,      0,      0,      0,      0,\n",
       "              0,      0,      0,      0,      0,      0,      0,      0,      0,\n",
       "              0,      0,      0,      0,      0,      0,      0,      0,      0,\n",
       "              0,      0,      0,      0,      0,      0,      0,      0,      0,\n",
       "              0,      0,      0,      0,      0,      0,      0,      0,      0,\n",
       "              0,      0,      0,      0,      0,      0,      0,      0,      0,\n",
       "              0,      0,      0,      0,      0,      0,      0,      0,      0,\n",
       "              0,      0,      0,      0,      0,      0,      0,      0,      0,\n",
       "              0,      0,      0,      0,      0,      0,      0,      0,      0,\n",
       "              0,      0,      0,      0,      0,      0,      0,      0,      0,\n",
       "              0,      0,      0,      0,      0,      0,      0,      0,      0,\n",
       "              0,      0,      0,      0,      0,      0,      0,      0,      0,\n",
       "              0,      0,      0,      0,      0,      0,      0,      0,      0,\n",
       "              0,      0,      0,      0,      0,      0,      0,      0,      0,\n",
       "              0,      0,      0,      0,      0,      0,      0,      0,      0,\n",
       "              0,      0,      0,      0,      0,      0,      0,      0,      0,\n",
       "              0,      0,      0,      0,      0,      0,      0,      0,      0,\n",
       "              0,      0,      0,      0,      0,      0,      0,      0,      0,\n",
       "              0,      0,      0,      0,      0,      0,      0,      0,      0,\n",
       "              0,      0,      0,      0,      0,      0,      0,      0,      0,\n",
       "              0,      0,      0,      0,      0,      0,      0,      0,      0,\n",
       "              0,      0,      0,      0,      0,      0,      0,      0,      0,\n",
       "              0,      0,      0,      0,      0,      0,      0,      0,      0,\n",
       "              0,      0,      0,      0,      0,      0,      0,      0,      0,\n",
       "              0,      0,      0,      0,      0,      0,      0,      0,      0,\n",
       "              0,      0,      0,      0,      0,      0,      0,      0,      0,\n",
       "              0,      0,      0,      0,      0,      0,      0,      0,      0,\n",
       "              0,      0,      0,      0,      0,      0,      0,      0,      0,\n",
       "              0,      0,      0,      0,      0,      0,      0,      0,      0,\n",
       "              0,      0,      0,      0,      0,      0,      0,      0,      0,\n",
       "              0,      0,      0,      0,      0,      0,      0,      0,      0,\n",
       "              0,      0,      0,      0,      0,      0,      0,      0,      0,\n",
       "              0,      0,      0,      0,      0,      0,      0,      0]]), 'token_type_ids': tensor([[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "         0, 0, 0, 0, 0, 0, 0, 0]]), 'attention_mask': tensor([[1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
       "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
       "         1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "         0, 0, 0, 0, 0, 0, 0, 0]])}"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tokenizer(clean_df['clean_comment'][0], padding='max_length', max_length = 512, truncation=True, return_tensors=\"pt\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "35845052",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "6f7e7cbf",
   "metadata": {},
   "outputs": [],
   "source": [
    "class MuRILbase(nn.Module):\n",
    "\n",
    "    def __init__(self, dropout=0.2):\n",
    "\n",
    "        super(MuRILbase, self).__init__()\n",
    "\n",
    "        self.bert = AutoModelForMaskedLM.from_pretrained('google/muril-base-cased')\n",
    "        self.dropout = nn.Dropout(dropout)\n",
    "        self.l1 = nn.Linear(768, 200)\n",
    "        self.l2 = nn.Linear(200, 1)\n",
    "        self.relu = nn.ReLU()\n",
    "        self.tanh = nn.Tanh()\n",
    "        \n",
    "        modules = [self.bert.bert.embeddings, *self.bert.bert.encoder.layer[:-3]]  # freeze all but last few\n",
    "        for module in modules:\n",
    "            for param in module.parameters():\n",
    "                param.requires_grad = False\n",
    "\n",
    "    def forward(self, input_id, mask):\n",
    "\n",
    "        b = self.bert(input_ids= input_id, attention_mask=mask, output_hidden_states=True)\n",
    "        x = b.hidden_states[-1][:, 0]  # this is what the bertpooler implementation does\n",
    "        x = self.dropout(x)\n",
    "        x = self.l1(x)\n",
    "        x = self.relu(x)\n",
    "        x = self.l2(x)\n",
    "        x = self.tanh(x)\n",
    "\n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e2b09418",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "fd5315af",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of the model checkpoint at google/muril-base-cased were not used when initializing BertModel: ['cls.predictions.transform.LayerNorm.bias', 'cls.predictions.transform.LayerNorm.weight', 'cls.predictions.transform.dense.bias', 'cls.predictions.decoder.bias', 'cls.predictions.transform.dense.weight', 'cls.seq_relationship.weight', 'cls.seq_relationship.bias', 'cls.predictions.bias', 'cls.predictions.decoder.weight']\n",
      "- This IS expected if you are initializing BertModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing BertModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "MuRILbase(\n",
       "  (bert): BertModel(\n",
       "    (embeddings): BertEmbeddings(\n",
       "      (word_embeddings): Embedding(197285, 768, padding_idx=0)\n",
       "      (position_embeddings): Embedding(512, 768)\n",
       "      (token_type_embeddings): Embedding(2, 768)\n",
       "      (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "      (dropout): Dropout(p=0.1, inplace=False)\n",
       "    )\n",
       "    (encoder): BertEncoder(\n",
       "      (layer): ModuleList(\n",
       "        (0): BertLayer(\n",
       "          (attention): BertAttention(\n",
       "            (self): BertSelfAttention(\n",
       "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (output): BertSelfOutput(\n",
       "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (intermediate): BertIntermediate(\n",
       "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "            (intermediate_act_fn): GELUActivation()\n",
       "          )\n",
       "          (output): BertOutput(\n",
       "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (1): BertLayer(\n",
       "          (attention): BertAttention(\n",
       "            (self): BertSelfAttention(\n",
       "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (output): BertSelfOutput(\n",
       "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (intermediate): BertIntermediate(\n",
       "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "            (intermediate_act_fn): GELUActivation()\n",
       "          )\n",
       "          (output): BertOutput(\n",
       "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (2): BertLayer(\n",
       "          (attention): BertAttention(\n",
       "            (self): BertSelfAttention(\n",
       "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (output): BertSelfOutput(\n",
       "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (intermediate): BertIntermediate(\n",
       "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "            (intermediate_act_fn): GELUActivation()\n",
       "          )\n",
       "          (output): BertOutput(\n",
       "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (3): BertLayer(\n",
       "          (attention): BertAttention(\n",
       "            (self): BertSelfAttention(\n",
       "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (output): BertSelfOutput(\n",
       "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (intermediate): BertIntermediate(\n",
       "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "            (intermediate_act_fn): GELUActivation()\n",
       "          )\n",
       "          (output): BertOutput(\n",
       "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (4): BertLayer(\n",
       "          (attention): BertAttention(\n",
       "            (self): BertSelfAttention(\n",
       "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (output): BertSelfOutput(\n",
       "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (intermediate): BertIntermediate(\n",
       "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "            (intermediate_act_fn): GELUActivation()\n",
       "          )\n",
       "          (output): BertOutput(\n",
       "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (5): BertLayer(\n",
       "          (attention): BertAttention(\n",
       "            (self): BertSelfAttention(\n",
       "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (output): BertSelfOutput(\n",
       "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (intermediate): BertIntermediate(\n",
       "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "            (intermediate_act_fn): GELUActivation()\n",
       "          )\n",
       "          (output): BertOutput(\n",
       "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (6): BertLayer(\n",
       "          (attention): BertAttention(\n",
       "            (self): BertSelfAttention(\n",
       "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (output): BertSelfOutput(\n",
       "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (intermediate): BertIntermediate(\n",
       "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "            (intermediate_act_fn): GELUActivation()\n",
       "          )\n",
       "          (output): BertOutput(\n",
       "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (7): BertLayer(\n",
       "          (attention): BertAttention(\n",
       "            (self): BertSelfAttention(\n",
       "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (output): BertSelfOutput(\n",
       "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (intermediate): BertIntermediate(\n",
       "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "            (intermediate_act_fn): GELUActivation()\n",
       "          )\n",
       "          (output): BertOutput(\n",
       "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (8): BertLayer(\n",
       "          (attention): BertAttention(\n",
       "            (self): BertSelfAttention(\n",
       "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (output): BertSelfOutput(\n",
       "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (intermediate): BertIntermediate(\n",
       "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "            (intermediate_act_fn): GELUActivation()\n",
       "          )\n",
       "          (output): BertOutput(\n",
       "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (9): BertLayer(\n",
       "          (attention): BertAttention(\n",
       "            (self): BertSelfAttention(\n",
       "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (output): BertSelfOutput(\n",
       "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (intermediate): BertIntermediate(\n",
       "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "            (intermediate_act_fn): GELUActivation()\n",
       "          )\n",
       "          (output): BertOutput(\n",
       "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (10): BertLayer(\n",
       "          (attention): BertAttention(\n",
       "            (self): BertSelfAttention(\n",
       "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (output): BertSelfOutput(\n",
       "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (intermediate): BertIntermediate(\n",
       "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "            (intermediate_act_fn): GELUActivation()\n",
       "          )\n",
       "          (output): BertOutput(\n",
       "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (11): BertLayer(\n",
       "          (attention): BertAttention(\n",
       "            (self): BertSelfAttention(\n",
       "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (output): BertSelfOutput(\n",
       "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (intermediate): BertIntermediate(\n",
       "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "            (intermediate_act_fn): GELUActivation()\n",
       "          )\n",
       "          (output): BertOutput(\n",
       "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "      )\n",
       "    )\n",
       "    (pooler): BertPooler(\n",
       "      (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "      (activation): Tanh()\n",
       "    )\n",
       "  )\n",
       "  (dropout): Dropout(p=0.2, inplace=False)\n",
       "  (l1): Linear(in_features=768, out_features=200, bias=True)\n",
       "  (l2): Linear(in_features=200, out_features=1, bias=True)\n",
       "  (relu): ReLU()\n",
       "  (tanh): Tanh()\n",
       ")"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model = MuRILbase()\n",
    "model.to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "e364786a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[-0.0133],\n",
      "        [-0.0146],\n",
      "        [-0.0140]], device='cuda:0')\n",
      "tensor([-0.0133, -0.0146, -0.0140], device='cuda:0')\n",
      "tensor([-0.5000, -0.5000, -0.7500], device='cuda:0')\n",
      "0.3380824625492096\n",
      "0.33807727694511414\n"
     ]
    }
   ],
   "source": [
    "# testing with a few inputs\n",
    "criterion = nn.MSELoss()\n",
    "\n",
    "temp_batch = list(clean_df['clean_comment'][0:3])\n",
    "temp_targets = torch.tensor(list(clean_df['target'][0:3])).to(device)\n",
    "temp = tokenizer(temp_batch, padding='max_length', max_length = 512, truncation=True, return_tensors=\"pt\")\n",
    "input_ids = temp['input_ids'].to(device)\n",
    "attention_mask = temp['attention_mask'].to(device)\n",
    "with torch.no_grad():\n",
    "    preds = model(input_ids, attention_mask)\n",
    "#     loss = criterion(preds, temp_targets)\n",
    "    print(preds)\n",
    "    print(preds.squeeze(1))\n",
    "    print(temp_targets)\n",
    "#     print(loss.item())\n",
    "    loss = criterion(preds.squeeze(1), temp_targets)\n",
    "    print(loss.item())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ebca7481",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "32b27dc5",
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_loop(model, train_df, num_epochs, batch_size, lr=0.001):\n",
    "    criterion = nn.MSELoss().to(device)\n",
    "    optimizer = torch.optim.Adam(model.parameters(), lr=lr)\n",
    "    losses = []\n",
    "    \n",
    "    inputs = train_df.copy()\n",
    "    for _ in range(num_epochs):\n",
    "        inputs = inputs.sample(frac=1).reset_index(drop=True)  # shuffle order\n",
    "        for i in range(int(np.ceil(len(inputs)/batch_size))):\n",
    "            model.zero_grad()\n",
    "            \n",
    "            # getting inputs\n",
    "            batch = list(inputs['clean_comment'][i:i+batch_size])\n",
    "            targets = torch.tensor(list(inputs['target'][i:i+batch_size])).to(device)\n",
    "            try:\n",
    "                temp = tokenizer(batch, padding='max_length', max_length = 512, truncation=True, return_tensors=\"pt\")\n",
    "            except ValueError:\n",
    "                print(\"Error with following batch, skipped:\")\n",
    "                print(len(batch))\n",
    "                print(batch)\n",
    "                print()\n",
    "                continue\n",
    "            input_ids, attention_mask = temp['input_ids'].to(device), temp['attention_mask'].to(device)\n",
    "            \n",
    "            # training model\n",
    "            preds = model(input_ids, attention_mask).squeeze(1)\n",
    "            batch_loss = criterion(preds, targets)\n",
    "            batch_loss.backward()\n",
    "            optimizer.step()\n",
    "            \n",
    "            losses.append(batch_loss.item())\n",
    "            \n",
    "            # excplicitly delete variables in cuda\n",
    "            del batch, targets, temp, input_ids, attention_mask, preds, batch_loss\n",
    "    return model, losses"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "ba4c54a0",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of the model checkpoint at google/muril-base-cased were not used when initializing BertForMaskedLM: ['cls.seq_relationship.bias', 'cls.seq_relationship.weight']\n",
      "- This IS expected if you are initializing BertForMaskedLM from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing BertForMaskedLM from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n"
     ]
    }
   ],
   "source": [
    "model = MuRILbase().to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "334929ad",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "|===========================================================================|\n",
      "|                  PyTorch CUDA memory summary, device ID 0                 |\n",
      "|---------------------------------------------------------------------------|\n",
      "|            CUDA OOMs: 0            |        cudaMalloc retries: 0         |\n",
      "|===========================================================================|\n",
      "|        Metric         | Cur Usage  | Peak Usage | Tot Alloc  | Tot Freed  |\n",
      "|---------------------------------------------------------------------------|\n",
      "| Allocated memory      |     908 MB |     908 MB |     908 MB |       0 B  |\n",
      "|       from large pool |     906 MB |     906 MB |     906 MB |       0 B  |\n",
      "|       from small pool |       1 MB |       1 MB |       1 MB |       0 B  |\n",
      "|---------------------------------------------------------------------------|\n",
      "| Active memory         |     908 MB |     908 MB |     908 MB |       0 B  |\n",
      "|       from large pool |     906 MB |     906 MB |     906 MB |       0 B  |\n",
      "|       from small pool |       1 MB |       1 MB |       1 MB |       0 B  |\n",
      "|---------------------------------------------------------------------------|\n",
      "| GPU reserved memory   |     960 MB |     960 MB |     960 MB |       0 B  |\n",
      "|       from large pool |     958 MB |     958 MB |     958 MB |       0 B  |\n",
      "|       from small pool |       2 MB |       2 MB |       2 MB |       0 B  |\n",
      "|---------------------------------------------------------------------------|\n",
      "| Non-releasable memory |   53169 KB |   54552 KB |  265210 KB |  212040 KB |\n",
      "|       from large pool |   52992 KB |   52992 KB |  263168 KB |  210176 KB |\n",
      "|       from small pool |     177 KB |    2042 KB |    2042 KB |    1864 KB |\n",
      "|---------------------------------------------------------------------------|\n",
      "| Allocations           |     208    |     208    |     208    |       0    |\n",
      "|       from large pool |      75    |      75    |      75    |       0    |\n",
      "|       from small pool |     133    |     133    |     133    |       0    |\n",
      "|---------------------------------------------------------------------------|\n",
      "| Active allocs         |     208    |     208    |     208    |       0    |\n",
      "|       from large pool |      75    |      75    |      75    |       0    |\n",
      "|       from small pool |     133    |     133    |     133    |       0    |\n",
      "|---------------------------------------------------------------------------|\n",
      "| GPU reserved segments |      21    |      21    |      21    |       0    |\n",
      "|       from large pool |      20    |      20    |      20    |       0    |\n",
      "|       from small pool |       1    |       1    |       1    |       0    |\n",
      "|---------------------------------------------------------------------------|\n",
      "| Non-releasable allocs |      19    |      19    |      20    |       1    |\n",
      "|       from large pool |      18    |      18    |      19    |       1    |\n",
      "|       from small pool |       1    |       1    |       1    |       0    |\n",
      "|---------------------------------------------------------------------------|\n",
      "| Oversize allocations  |       0    |       0    |       0    |       0    |\n",
      "|---------------------------------------------------------------------------|\n",
      "| Oversize GPU segments |       0    |       0    |       0    |       0    |\n",
      "|===========================================================================|\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# torch.cuda.empty_cache()\n",
    "print(torch.cuda.memory_summary(device=None, abbreviated=False))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "8e2ade2a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Wall time: 10min 4s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "model, losses = train_loop(model, clean_df, num_epochs=5, batch_size=4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "b8fb7246",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[<matplotlib.lines.Line2D at 0x24ef4307dc0>]"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.plot([i*5/len(losses) for i in range(len(losses))], losses)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "ef4c9efa",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "511.0"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(losses)/5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "f1e40252",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.4191313467870307"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.mean(losses[-511:])**0.5  # approx rmse"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "fc20c3bd",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "256"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# getting preds\n",
    "with torch.no_grad():\n",
    "#     model.eval()\n",
    "    preds = []\n",
    "    batch_size = 8\n",
    "    for i in range(0, len(clean_df), batch_size):\n",
    "        temp = tokenizer(list(clean_df['clean_comment'][i:i+batch_size]), padding='max_length', max_length = 512, truncation=True, return_tensors=\"pt\")\n",
    "        preds.append(model(temp['input_ids'].to(device), temp['attention_mask'].to(device)).cpu().detach().numpy().tolist())\n",
    "len(preds)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "64b87d90",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[[[-0.04186757653951645],\n",
       "  [-0.04186631739139557],\n",
       "  [-0.04186646267771721],\n",
       "  [-0.041866548359394073],\n",
       "  [-0.04186636209487915],\n",
       "  [-0.04186646267771721],\n",
       "  [-0.04186452925205231],\n",
       "  [-0.04186646267771721]],\n",
       " [[-0.0418664924800396],\n",
       "  [-0.04186708852648735],\n",
       "  [-0.041864797472953796],\n",
       "  [-0.04186587780714035],\n",
       "  [-0.041866712272167206],\n",
       "  [-0.04186646267771721],\n",
       "  [-0.04186539351940155],\n",
       "  [-0.04186646267771721]],\n",
       " [[-0.04186646267771721],\n",
       "  [-0.04186646267771721],\n",
       "  [-0.04186747595667839],\n",
       "  [-0.04186582565307617],\n",
       "  [-0.0418664775788784],\n",
       "  [-0.04186646267771721],\n",
       "  [-0.04186646267771721],\n",
       "  [-0.04186723753809929]],\n",
       " [[-0.04186646267771721],\n",
       "  [-0.04186629131436348],\n",
       "  [-0.04186353087425232],\n",
       "  [-0.04186646267771721],\n",
       "  [-0.041866485029459],\n",
       "  [-0.04186646267771721],\n",
       "  [-0.04186646267771721],\n",
       "  [-0.04186646267771721]],\n",
       " [[-0.041867323219776154],\n",
       "  [-0.041865866631269455],\n",
       "  [-0.04186646267771721],\n",
       "  [-0.04186646267771721],\n",
       "  [-0.04186646267771721],\n",
       "  [-0.04186616837978363],\n",
       "  [-0.041866470128297806],\n",
       "  [-0.04186646267771721]],\n",
       " [[-0.041866403073072433],\n",
       "  [-0.041866485029459],\n",
       "  [-0.04186646267771721],\n",
       "  [-0.04186646267771721],\n",
       "  [-0.04186616837978363],\n",
       "  [-0.04186646267771721],\n",
       "  [-0.041866786777973175],\n",
       "  [-0.04186646267771721]],\n",
       " [[-0.04186471179127693],\n",
       "  [-0.041867148131132126],\n",
       "  [-0.041866470128297806],\n",
       "  [-0.04186646267771721],\n",
       "  [-0.041866421699523926],\n",
       "  [-0.041866108775138855],\n",
       "  [-0.04186779260635376],\n",
       "  [-0.041866980493068695]],\n",
       " [[-0.041865602135658264],\n",
       "  [-0.04186680167913437],\n",
       "  [-0.041866615414619446],\n",
       "  [-0.04186646267771721],\n",
       "  [-0.04186646267771721],\n",
       "  [-0.04186646267771721],\n",
       "  [-0.0418664924800396],\n",
       "  [-0.04186646267771721]],\n",
       " [[-0.04186715930700302],\n",
       "  [-0.04186642915010452],\n",
       "  [-0.04186646267771721],\n",
       "  [-0.04186646267771721],\n",
       "  [-0.04186646267771721],\n",
       "  [-0.04186664894223213],\n",
       "  [-0.04186674952507019],\n",
       "  [-0.04186646267771721]],\n",
       " [[-0.04186666011810303],\n",
       "  [-0.04186646267771721],\n",
       "  [-0.04186655580997467],\n",
       "  [-0.041866838932037354],\n",
       "  [-0.04186646267771721],\n",
       "  [-0.04186595603823662],\n",
       "  [-0.041866522282361984],\n",
       "  [-0.04186646267771721]],\n",
       " [[-0.04186646267771721],\n",
       "  [-0.04186653345823288],\n",
       "  [-0.04186693951487541],\n",
       "  [-0.04186658933758736],\n",
       "  [-0.04186590015888214],\n",
       "  [-0.04186646267771721],\n",
       "  [-0.04186646267771721],\n",
       "  [-0.04186486452817917]],\n",
       " [[-0.041866738349199295],\n",
       "  [-0.041866667568683624],\n",
       "  [-0.04186646267771721],\n",
       "  [-0.04186645522713661],\n",
       "  [-0.04186646267771721],\n",
       "  [-0.04186682030558586],\n",
       "  [-0.04186646267771721],\n",
       "  [-0.04186646267771721]],\n",
       " [[-0.04186646267771721],\n",
       "  [-0.04186646267771721],\n",
       "  [-0.04186401143670082],\n",
       "  [-0.04186646267771721],\n",
       "  [-0.04186646267771721],\n",
       "  [-0.041866131126880646],\n",
       "  [-0.04186622425913811],\n",
       "  [-0.0418633371591568]],\n",
       " [[-0.04186636954545975],\n",
       "  [-0.041866615414619446],\n",
       "  [-0.04186646267771721],\n",
       "  [-0.04186646267771721],\n",
       "  [-0.04186687245965004],\n",
       "  [-0.04186692833900452],\n",
       "  [-0.04186646267771721],\n",
       "  [-0.041866667568683624]],\n",
       " [[-0.04186646267771721],\n",
       "  [-0.04186646267771721],\n",
       "  [-0.04186646267771721],\n",
       "  [-0.04186646267771721],\n",
       "  [-0.04186670482158661],\n",
       "  [-0.04186646267771721],\n",
       "  [-0.04186646267771721],\n",
       "  [-0.04186646267771721]],\n",
       " [[-0.04186621308326721],\n",
       "  [-0.04186646267771721],\n",
       "  [-0.04186646267771721],\n",
       "  [-0.04186646267771721],\n",
       "  [-0.04186639562249184],\n",
       "  [-0.04186646267771721],\n",
       "  [-0.04186646267771721],\n",
       "  [-0.041860274970531464]],\n",
       " [[-0.04186646267771721],\n",
       "  [-0.04186646267771721],\n",
       "  [-0.04186646267771721],\n",
       "  [-0.04186629131436348],\n",
       "  [-0.0418643020093441],\n",
       "  [-0.041866425424814224],\n",
       "  [-0.041862305253744125],\n",
       "  [-0.04186646267771721]],\n",
       " [[-0.04186646267771721],\n",
       "  [-0.04186646267771721],\n",
       "  [-0.04186646267771721],\n",
       "  [-0.04186646267771721],\n",
       "  [-0.04186646267771721],\n",
       "  [-0.04186646267771721],\n",
       "  [-0.041866593062877655],\n",
       "  [-0.04186755046248436]],\n",
       " [[-0.04186656326055527],\n",
       "  [-0.041866738349199295],\n",
       "  [-0.04186620935797691],\n",
       "  [-0.04186646267771721],\n",
       "  [-0.04186682775616646],\n",
       "  [-0.04186295345425606],\n",
       "  [-0.04186646267771721],\n",
       "  [-0.04186464473605156]],\n",
       " [[-0.04186538979411125],\n",
       "  [-0.04186646267771721],\n",
       "  [-0.04186646267771721],\n",
       "  [-0.041866548359394073],\n",
       "  [-0.041866570711135864],\n",
       "  [-0.04186662659049034],\n",
       "  [-0.04186646267771721],\n",
       "  [-0.04186646267771721]],\n",
       " [[-0.04186735674738884],\n",
       "  [-0.04186646267771721],\n",
       "  [-0.04186646267771721],\n",
       "  [-0.04186702147126198],\n",
       "  [-0.04186646267771721],\n",
       "  [-0.04186646267771721],\n",
       "  [-0.04186646267771721],\n",
       "  [-0.041867729276418686]],\n",
       " [[-0.04186646267771721],\n",
       "  [-0.04186646267771721],\n",
       "  [-0.04186628386378288],\n",
       "  [-0.0418664887547493],\n",
       "  [-0.04186646267771721],\n",
       "  [-0.04186646267771721],\n",
       "  [-0.041865311563014984],\n",
       "  [-0.04186646267771721]],\n",
       " [[-0.04186628386378288],\n",
       "  [-0.04186646267771721],\n",
       "  [-0.04186714068055153],\n",
       "  [-0.041867274791002274],\n",
       "  [-0.04186646267771721],\n",
       "  [-0.04186646267771721],\n",
       "  [-0.04186646267771721],\n",
       "  [-0.041863780468702316]],\n",
       " [[-0.04186646267771721],\n",
       "  [-0.04186646267771721],\n",
       "  [-0.04186646267771721],\n",
       "  [-0.04186646267771721],\n",
       "  [-0.041866883635520935],\n",
       "  [-0.041863296180963516],\n",
       "  [-0.04186646267771721],\n",
       "  [-0.04186663031578064]],\n",
       " [[-0.04186679795384407],\n",
       "  [-0.04186646267771721],\n",
       "  [-0.041864506900310516],\n",
       "  [-0.04186568036675453],\n",
       "  [-0.04186646267771721],\n",
       "  [-0.0418662428855896],\n",
       "  [-0.041866570711135864],\n",
       "  [-0.04186646267771721]],\n",
       " [[-0.04186650365591049],\n",
       "  [-0.04186708852648735],\n",
       "  [-0.04186699539422989],\n",
       "  [-0.04186655208468437],\n",
       "  [-0.04186646267771721],\n",
       "  [-0.04186646267771721],\n",
       "  [-0.04186392202973366],\n",
       "  [-0.041864681988954544]],\n",
       " [[-0.041865792125463486],\n",
       "  [-0.04186646267771721],\n",
       "  [-0.04186646267771721],\n",
       "  [-0.04186759144067764],\n",
       "  [-0.041866641491651535],\n",
       "  [-0.04186646267771721],\n",
       "  [-0.041866619139909744],\n",
       "  [-0.041857969015836716]],\n",
       " [[-0.04186646267771721],\n",
       "  [-0.04186646267771721],\n",
       "  [-0.04186646267771721],\n",
       "  [-0.041866645216941833],\n",
       "  [-0.04186646267771721],\n",
       "  [-0.04186689108610153],\n",
       "  [-0.04186416417360306],\n",
       "  [-0.041866350919008255]],\n",
       " [[-0.041862957179546356],\n",
       "  [-0.04186652973294258],\n",
       "  [-0.041865259408950806],\n",
       "  [-0.041862938553094864],\n",
       "  [-0.04186538979411125],\n",
       "  [-0.04186660051345825],\n",
       "  [-0.04186646267771721],\n",
       "  [-0.041866201907396317]],\n",
       " [[-0.04186646267771721],\n",
       "  [-0.04186753183603287],\n",
       "  [-0.0418667308986187],\n",
       "  [-0.04186667501926422],\n",
       "  [-0.041865214705467224],\n",
       "  [-0.04186646267771721],\n",
       "  [-0.04186646267771721],\n",
       "  [-0.04186646267771721]],\n",
       " [[-0.04186646267771721],\n",
       "  [-0.04186666011810303],\n",
       "  [-0.041866693645715714],\n",
       "  [-0.04186646267771721],\n",
       "  [-0.04186646267771721],\n",
       "  [-0.04186192527413368],\n",
       "  [-0.0418664887547493],\n",
       "  [-0.04186592623591423]],\n",
       " [[-0.04186704754829407],\n",
       "  [-0.04186691343784332],\n",
       "  [-0.04186646267771721],\n",
       "  [-0.041866734623909],\n",
       "  [-0.041865766048431396],\n",
       "  [-0.04186646267771721],\n",
       "  [-0.04186646267771721],\n",
       "  [-0.04186646267771721]],\n",
       " [[-0.041866470128297806],\n",
       "  [-0.04186646267771721],\n",
       "  [-0.041867662221193314],\n",
       "  [-0.04186646267771721],\n",
       "  [-0.04186641797423363],\n",
       "  [-0.04186643660068512],\n",
       "  [-0.04186689481139183],\n",
       "  [-0.04186685010790825]],\n",
       " [[-0.04186646267771721],\n",
       "  [-0.04186646267771721],\n",
       "  [-0.04186704009771347],\n",
       "  [-0.04186663776636124],\n",
       "  [-0.04186525195837021],\n",
       "  [-0.04186694696545601],\n",
       "  [-0.04186684265732765],\n",
       "  [-0.04186639189720154]],\n",
       " [[-0.04186646267771721],\n",
       "  [-0.041864387691020966],\n",
       "  [-0.04186665639281273],\n",
       "  [-0.041866485029459],\n",
       "  [-0.04186646267771721],\n",
       "  [-0.04186646267771721],\n",
       "  [-0.04186532273888588],\n",
       "  [-0.04186646267771721]],\n",
       " [[-0.041867293417453766],\n",
       "  [-0.04186646267771721],\n",
       "  [-0.04186646267771721],\n",
       "  [-0.041866060346364975],\n",
       "  [-0.04186646267771721],\n",
       "  [-0.04186646267771721],\n",
       "  [-0.04186646267771721],\n",
       "  [-0.04186658561229706]],\n",
       " [[-0.04186360910534859],\n",
       "  [-0.04186590388417244],\n",
       "  [-0.04186646267771721],\n",
       "  [-0.041866499930620193],\n",
       "  [-0.041866764426231384],\n",
       "  [-0.04186646267771721],\n",
       "  [-0.041863828897476196],\n",
       "  [-0.04186675325036049]],\n",
       " [[-0.04186646267771721],\n",
       "  [-0.04186646267771721],\n",
       "  [-0.04186646267771721],\n",
       "  [-0.04186641424894333],\n",
       "  [-0.04186646267771721],\n",
       "  [-0.04186674952507019],\n",
       "  [-0.04186646267771721],\n",
       "  [-0.04186660051345825]],\n",
       " [[-0.04186687245965004],\n",
       "  [-0.04186646267771721],\n",
       "  [-0.041861701756715775],\n",
       "  [-0.04186646267771721],\n",
       "  [-0.04186650365591049],\n",
       "  [-0.04186646267771721],\n",
       "  [-0.04186427220702171],\n",
       "  [-0.04186646267771721]],\n",
       " [[-0.04186687618494034],\n",
       "  [-0.04186646267771721],\n",
       "  [-0.04186646267771721],\n",
       "  [-0.04186646267771721],\n",
       "  [-0.04186646267771721],\n",
       "  [-0.04186646267771721],\n",
       "  [-0.04186519980430603],\n",
       "  [-0.04186646267771721]],\n",
       " [[-0.04186633974313736],\n",
       "  [-0.04186646267771721],\n",
       "  [-0.04186100885272026],\n",
       "  [-0.04186665639281273],\n",
       "  [-0.04186646267771721],\n",
       "  [-0.0418664775788784],\n",
       "  [-0.04186646267771721],\n",
       "  [-0.04186736047267914]],\n",
       " [[-0.04186646267771721],\n",
       "  [-0.04186646267771721],\n",
       "  [-0.04186645522713661],\n",
       "  [-0.04186667129397392],\n",
       "  [-0.041865769773721695],\n",
       "  [-0.041866470128297806],\n",
       "  [-0.041867416352033615],\n",
       "  [-0.04186646267771721]],\n",
       " [[-0.04186646267771721],\n",
       "  [-0.04186646267771721],\n",
       "  [-0.04186646267771721],\n",
       "  [-0.04186663404107094],\n",
       "  [-0.04186646267771721],\n",
       "  [-0.04186505079269409],\n",
       "  [-0.04186646267771721],\n",
       "  [-0.04186646267771721]],\n",
       " [[-0.04186646267771721],\n",
       "  [-0.04186645895242691],\n",
       "  [-0.041866470128297806],\n",
       "  [-0.04186650365591049],\n",
       "  [-0.04186646267771721],\n",
       "  [-0.04186630994081497],\n",
       "  [-0.04186646267771721],\n",
       "  [-0.0418655090034008]],\n",
       " [[-0.04186646267771721],\n",
       "  [-0.04186646267771721],\n",
       "  [-0.041866131126880646],\n",
       "  [-0.04186474531888962],\n",
       "  [-0.04186646267771721],\n",
       "  [-0.04186646267771721],\n",
       "  [-0.04186667501926422],\n",
       "  [-0.041866641491651535]],\n",
       " [[-0.04186646267771721],\n",
       "  [-0.041866485029459],\n",
       "  [-0.04186646267771721],\n",
       "  [-0.04186646267771721],\n",
       "  [-0.04186730831861496],\n",
       "  [-0.04186590388417244],\n",
       "  [-0.041866485029459],\n",
       "  [-0.04186660423874855]],\n",
       " [[-0.041866742074489594],\n",
       "  [-0.04186690226197243],\n",
       "  [-0.04186567664146423],\n",
       "  [-0.04186646267771721],\n",
       "  [-0.04186646267771721],\n",
       "  [-0.04186207801103592],\n",
       "  [-0.04186505079269409],\n",
       "  [-0.04186646267771721]],\n",
       " [[-0.04186646267771721],\n",
       "  [-0.041866205632686615],\n",
       "  [-0.04186646267771721],\n",
       "  [-0.04186646267771721],\n",
       "  [-0.04186646267771721],\n",
       "  [-0.04186646267771721],\n",
       "  [-0.041866566985845566],\n",
       "  [-0.04186560586094856]],\n",
       " [[-0.041866131126880646],\n",
       "  [-0.04186653718352318],\n",
       "  [-0.04186646267771721],\n",
       "  [-0.041867949068546295],\n",
       "  [-0.04186646267771721],\n",
       "  [-0.04186646267771721],\n",
       "  [-0.041867081075906754],\n",
       "  [-0.04186646267771721]],\n",
       " [[-0.04186631739139557],\n",
       "  [-0.04186646267771721],\n",
       "  [-0.041863445192575455],\n",
       "  [-0.041866663843393326],\n",
       "  [-0.04186651110649109],\n",
       "  [-0.04186658188700676],\n",
       "  [-0.04186588525772095],\n",
       "  [-0.04186597093939781]],\n",
       " [[-0.04186619073152542],\n",
       "  [-0.04186646267771721],\n",
       "  [-0.0418664924800396],\n",
       "  [-0.041867077350616455],\n",
       "  [-0.04186646267771721],\n",
       "  [-0.04186646267771721],\n",
       "  [-0.041866619139909744],\n",
       "  [-0.041866399347782135]],\n",
       " [[-0.04186643660068512],\n",
       "  [-0.04186665639281273],\n",
       "  [-0.04186646267771721],\n",
       "  [-0.04186646267771721],\n",
       "  [-0.04186646267771721],\n",
       "  [-0.04186646267771721],\n",
       "  [-0.041867177933454514],\n",
       "  [-0.04186646267771721]],\n",
       " [[-0.04186646267771721],\n",
       "  [-0.04186725988984108],\n",
       "  [-0.04186646267771721],\n",
       "  [-0.04186646267771721],\n",
       "  [-0.04186667874455452],\n",
       "  [-0.04186646267771721],\n",
       "  [-0.041866399347782135],\n",
       "  [-0.04186646267771721]],\n",
       " [[-0.04186675697565079],\n",
       "  [-0.04186646267771721],\n",
       "  [-0.04186646267771721],\n",
       "  [-0.04186646267771721],\n",
       "  [-0.04186625778675079],\n",
       "  [-0.04186646267771721],\n",
       "  [-0.04186646267771721],\n",
       "  [-0.04186646267771721]],\n",
       " [[-0.04186716303229332],\n",
       "  [-0.04186490923166275],\n",
       "  [-0.041863854974508286],\n",
       "  [-0.04186646267771721],\n",
       "  [-0.041863299906253815],\n",
       "  [-0.04186681658029556],\n",
       "  [-0.041864898055791855],\n",
       "  [-0.04186646267771721]],\n",
       " [[-0.041863128542900085],\n",
       "  [-0.04186646267771721],\n",
       "  [-0.0418672077357769],\n",
       "  [-0.04186646267771721],\n",
       "  [-0.04186646267771721],\n",
       "  [-0.04186646267771721],\n",
       "  [-0.04186646267771721],\n",
       "  [-0.041866932064294815]],\n",
       " [[-0.04186529666185379],\n",
       "  [-0.04186682775616646],\n",
       "  [-0.04186641052365303],\n",
       "  [-0.04186646267771721],\n",
       "  [-0.0418664924800396],\n",
       "  [-0.04186275228857994],\n",
       "  [-0.04186674579977989],\n",
       "  [-0.04186646267771721]],\n",
       " [[-0.041866485029459],\n",
       "  [-0.041862986981868744],\n",
       "  [-0.04186646267771721],\n",
       "  [-0.041875842958688736],\n",
       "  [-0.041866596788167953],\n",
       "  [-0.04186646267771721],\n",
       "  [-0.04186646267771721],\n",
       "  [-0.04186646267771721]],\n",
       " [[-0.04186646267771721],\n",
       "  [-0.04186646267771721],\n",
       "  [-0.04186730086803436],\n",
       "  [-0.04186714440584183],\n",
       "  [-0.04186646267771721],\n",
       "  [-0.04186646267771721],\n",
       "  [-0.0418664887547493],\n",
       "  [-0.04186646267771721]],\n",
       " [[-0.04186682030558586],\n",
       "  [-0.04186646267771721],\n",
       "  [-0.0418669767677784],\n",
       "  [-0.041866473853588104],\n",
       "  [-0.04186635836958885],\n",
       "  [-0.04186750203371048],\n",
       "  [-0.041866522282361984],\n",
       "  [-0.04186643287539482]],\n",
       " [[-0.041866619139909744],\n",
       "  [-0.04186646267771721],\n",
       "  [-0.04186646267771721],\n",
       "  [-0.04186708480119705],\n",
       "  [-0.04186650365591049],\n",
       "  [-0.04186646267771721],\n",
       "  [-0.04186218976974487],\n",
       "  [-0.04186646267771721]],\n",
       " [[-0.041866447776556015],\n",
       "  [-0.04185747727751732],\n",
       "  [-0.04186646267771721],\n",
       "  [-0.041867680847644806],\n",
       "  [-0.04186670854687691],\n",
       "  [-0.04186570644378662],\n",
       "  [-0.04186694324016571],\n",
       "  [-0.041865959763526917]],\n",
       " [[-0.04186646267771721],\n",
       "  [-0.041866619139909744],\n",
       "  [-0.04186621680855751],\n",
       "  [-0.04186646267771721],\n",
       "  [-0.04186646267771721],\n",
       "  [-0.04186646267771721],\n",
       "  [-0.04186646267771721],\n",
       "  [-0.04186683148145676]],\n",
       " [[-0.04186646267771721],\n",
       "  [-0.04186646267771721],\n",
       "  [-0.04186635464429855],\n",
       "  [-0.041866544634103775],\n",
       "  [-0.04186646267771721],\n",
       "  [-0.04186646267771721],\n",
       "  [-0.04186646267771721],\n",
       "  [-0.041865427047014236]],\n",
       " [[-0.04186646267771721],\n",
       "  [-0.041866496205329895],\n",
       "  [-0.04186462610960007],\n",
       "  [-0.04186646267771721],\n",
       "  [-0.04186646267771721],\n",
       "  [-0.041865624487400055],\n",
       "  [-0.041866328567266464],\n",
       "  [-0.04186294972896576]],\n",
       " [[-0.041866485029459],\n",
       "  [-0.04186694696545601],\n",
       "  [-0.04186646267771721],\n",
       "  [-0.041865985840559006],\n",
       "  [-0.04186646267771721],\n",
       "  [-0.041866909712553024],\n",
       "  [-0.04186290130019188],\n",
       "  [-0.04185810312628746]],\n",
       " [[-0.04186646267771721],\n",
       "  [-0.04186646267771721],\n",
       "  [-0.04186481609940529],\n",
       "  [-0.04186652973294258],\n",
       "  [-0.04186646267771721],\n",
       "  [-0.04186738654971123],\n",
       "  [-0.04186646267771721],\n",
       "  [-0.04186706244945526]],\n",
       " [[-0.04186658561229706],\n",
       "  [-0.04186646267771721],\n",
       "  [-0.041867222636938095],\n",
       "  [-0.04186646640300751],\n",
       "  [-0.04186646267771721],\n",
       "  [-0.04186646267771721],\n",
       "  [-0.04186646267771721],\n",
       "  [-0.04186646267771721]],\n",
       " [[-0.04186676815152168],\n",
       "  [-0.04186646267771721],\n",
       "  [-0.0418645478785038],\n",
       "  [-0.04186646267771721],\n",
       "  [-0.04186577349901199],\n",
       "  [-0.04186646267771721],\n",
       "  [-0.041867710649967194],\n",
       "  [-0.04186646267771721]],\n",
       " [[-0.04186646267771721],\n",
       "  [-0.04186646267771721],\n",
       "  [-0.04186646267771721],\n",
       "  [-0.04186646267771721],\n",
       "  [-0.04186644032597542],\n",
       "  [-0.04186646267771721],\n",
       "  [-0.0418659932911396],\n",
       "  [-0.041867662221193314]],\n",
       " [[-0.04186646267771721],\n",
       "  [-0.04186660423874855],\n",
       "  [-0.04186646267771721],\n",
       "  [-0.04186646267771721],\n",
       "  [-0.04186646267771721],\n",
       "  [-0.04186646267771721],\n",
       "  [-0.041869815438985825],\n",
       "  [-0.04186571016907692]],\n",
       " [[-0.04186646267771721],\n",
       "  [-0.04186646267771721],\n",
       "  [-0.04186646267771721],\n",
       "  [-0.04186646267771721],\n",
       "  [-0.04186657443642616],\n",
       "  [-0.041866485029459],\n",
       "  [-0.04186651483178139],\n",
       "  [-0.0418664924800396]],\n",
       " [[-0.04186646267771721],\n",
       "  [-0.04186646267771721],\n",
       "  [-0.04186652600765228],\n",
       "  [-0.0418621189892292],\n",
       "  [-0.04186646267771721],\n",
       "  [-0.04186653345823288],\n",
       "  [-0.04186646267771721],\n",
       "  [-0.04186646267771721]],\n",
       " [[-0.041866485029459],\n",
       "  [-0.04186646267771721],\n",
       "  [-0.041866473853588104],\n",
       "  [-0.04186646267771721],\n",
       "  [-0.041865430772304535],\n",
       "  [-0.04186646267771721],\n",
       "  [-0.04186243936419487],\n",
       "  [-0.041866760700941086]],\n",
       " [[-0.04186646267771721],\n",
       "  [-0.04186646267771721],\n",
       "  [-0.04186641052365303],\n",
       "  [-0.04186632111668587],\n",
       "  [-0.04186750203371048],\n",
       "  [-0.04186646267771721],\n",
       "  [-0.04186646267771721],\n",
       "  [-0.041864026337862015]],\n",
       " [[-0.04186668246984482],\n",
       "  [-0.04186646267771721],\n",
       "  [-0.04186646267771721],\n",
       "  [-0.04186646267771721],\n",
       "  [-0.04186568036675453],\n",
       "  [-0.04186646267771721],\n",
       "  [-0.041866350919008255],\n",
       "  [-0.04186667129397392]],\n",
       " [[-0.04186646267771721],\n",
       "  [-0.04186646267771721],\n",
       "  [-0.04186651483178139],\n",
       "  [-0.04186578094959259],\n",
       "  [-0.04186549410223961],\n",
       "  [-0.04186093062162399],\n",
       "  [-0.04186682775616646],\n",
       "  [-0.04186804220080376]],\n",
       " [[-0.04186640679836273],\n",
       "  [-0.04186660051345825],\n",
       "  [-0.041866399347782135],\n",
       "  [-0.041866615414619446],\n",
       "  [-0.04186646267771721],\n",
       "  [-0.04186646267771721],\n",
       "  [-0.04186646267771721],\n",
       "  [-0.04186658933758736]],\n",
       " [[-0.04186646267771721],\n",
       "  [-0.04186646267771721],\n",
       "  [-0.041865456849336624],\n",
       "  [-0.04186646267771721],\n",
       "  [-0.04186646267771721],\n",
       "  [-0.04186674952507019],\n",
       "  [-0.041866615414619446],\n",
       "  [-0.04186646267771721]],\n",
       " [[-0.04186646267771721],\n",
       "  [-0.04186646267771721],\n",
       "  [-0.04186675697565079],\n",
       "  [-0.04186644405126572],\n",
       "  [-0.0418669730424881],\n",
       "  [-0.04186520352959633],\n",
       "  [-0.04186391457915306],\n",
       "  [-0.0418672077357769]],\n",
       " [[-0.04186677560210228],\n",
       "  [-0.04186646267771721],\n",
       "  [-0.04186646267771721],\n",
       "  [-0.04186694696545601],\n",
       "  [-0.041867561638355255],\n",
       "  [-0.04186646267771721],\n",
       "  [-0.041867341846227646],\n",
       "  [-0.04186646267771721]],\n",
       " [[-0.041866421699523926],\n",
       "  [-0.04186646267771721],\n",
       "  [-0.041866082698106766],\n",
       "  [-0.041864097118377686],\n",
       "  [-0.041867151856422424],\n",
       "  [-0.04186646267771721],\n",
       "  [-0.04186646267771721],\n",
       "  [-0.04186646267771721]],\n",
       " [[-0.041866544634103775],\n",
       "  [-0.041867006570100784],\n",
       "  [-0.04186663031578064],\n",
       "  [-0.0418664887547493],\n",
       "  [-0.04186646267771721],\n",
       "  [-0.041867226362228394],\n",
       "  [-0.041866470128297806],\n",
       "  [-0.041865140199661255]],\n",
       " [[-0.04186646267771721],\n",
       "  [-0.04186646267771721],\n",
       "  [-0.04186646267771721],\n",
       "  [-0.04186638072133064],\n",
       "  [-0.04186646267771721],\n",
       "  [-0.04186687245965004],\n",
       "  [-0.04186646267771721],\n",
       "  [-0.04186723753809929]],\n",
       " [[-0.04186646267771721],\n",
       "  [-0.04186573252081871],\n",
       "  [-0.041866663843393326],\n",
       "  [-0.04186646267771721],\n",
       "  [-0.04186398908495903],\n",
       "  [-0.041866518557071686],\n",
       "  [-0.04186631739139557],\n",
       "  [-0.041866276413202286]],\n",
       " [[-0.041866619139909744],\n",
       "  [-0.04186646267771721],\n",
       "  [-0.04186678305268288],\n",
       "  [-0.04186646267771721],\n",
       "  [-0.04186646267771721],\n",
       "  [-0.04186646267771721],\n",
       "  [-0.04186646267771721],\n",
       "  [-0.04186646267771721]],\n",
       " [[-0.04186656326055527],\n",
       "  [-0.04186646267771721],\n",
       "  [-0.04186646267771721],\n",
       "  [-0.04186646267771721],\n",
       "  [-0.04186639562249184],\n",
       "  [-0.04186616092920303],\n",
       "  [-0.04186645522713661],\n",
       "  [-0.04186639562249184]],\n",
       " [[-0.041866518557071686],\n",
       "  [-0.041866566985845566],\n",
       "  [-0.04186646267771721],\n",
       "  [-0.04186646267771721],\n",
       "  [-0.0418664813041687],\n",
       "  [-0.041863925755023956],\n",
       "  [-0.04186646267771721],\n",
       "  [-0.04186646267771721]],\n",
       " [[-0.041866470128297806],\n",
       "  [-0.04186646267771721],\n",
       "  [-0.04186646267771721],\n",
       "  [-0.041864484548568726],\n",
       "  [-0.04186646267771721],\n",
       "  [-0.04186646267771721],\n",
       "  [-0.04186706990003586],\n",
       "  [-0.041866909712553024]],\n",
       " [[-0.04186639562249184],\n",
       "  [-0.04186646267771721],\n",
       "  [-0.04186646267771721],\n",
       "  [-0.04186532646417618],\n",
       "  [-0.04186539351940155],\n",
       "  [-0.04186646267771721],\n",
       "  [-0.04186646267771721],\n",
       "  [-0.04186646267771721]],\n",
       " [[-0.04186646267771721],\n",
       "  [-0.0418519489467144],\n",
       "  [-0.04186646267771721],\n",
       "  [-0.04186646267771721],\n",
       "  [-0.04186642915010452],\n",
       "  [-0.041866473853588104],\n",
       "  [-0.04186639189720154],\n",
       "  [-0.04186646267771721]],\n",
       " [[-0.04186646267771721],\n",
       "  [-0.041866593062877655],\n",
       "  [-0.04186646267771721],\n",
       "  [-0.041866861283779144],\n",
       "  [-0.04186634719371796],\n",
       "  [-0.04186646267771721],\n",
       "  [-0.0418669693171978],\n",
       "  [-0.04186646267771721]],\n",
       " [[-0.04186646267771721],\n",
       "  [-0.04186646267771721],\n",
       "  [-0.04186678305268288],\n",
       "  [-0.0418664775788784],\n",
       "  [-0.0418664775788784],\n",
       "  [-0.04186646267771721],\n",
       "  [-0.04186646267771721],\n",
       "  [-0.04186646267771721]],\n",
       " [[-0.04186651483178139],\n",
       "  [-0.04186646267771721],\n",
       "  [-0.04186750575900078],\n",
       "  [-0.04186653718352318],\n",
       "  [-0.04186701402068138],\n",
       "  [-0.041864778846502304],\n",
       "  [-0.04186646267771721],\n",
       "  [-0.04186643660068512]],\n",
       " [[-0.04186646267771721],\n",
       "  [-0.04186629131436348],\n",
       "  [-0.04186646267771721],\n",
       "  [-0.04186646267771721],\n",
       "  [-0.04186646267771721],\n",
       "  [-0.041862111538648605],\n",
       "  [-0.041866835206747055],\n",
       "  [-0.04186646267771721]],\n",
       " [[-0.041866522282361984],\n",
       "  [-0.04186620935797691],\n",
       "  [-0.04186638444662094],\n",
       "  [-0.04186646267771721],\n",
       "  [-0.04186646267771721],\n",
       "  [-0.04186646267771721],\n",
       "  [-0.04186411201953888],\n",
       "  [-0.04186635836958885]],\n",
       " [[-0.04186646267771721],\n",
       "  [-0.04186595603823662],\n",
       "  [-0.04186231642961502],\n",
       "  [-0.04186505824327469],\n",
       "  [-0.04186646267771721],\n",
       "  [-0.04186669737100601],\n",
       "  [-0.04186646267771721],\n",
       "  [-0.041866593062877655]],\n",
       " [[-0.0418667271733284],\n",
       "  [-0.041866447776556015],\n",
       "  [-0.041867759078741074],\n",
       "  [-0.04186646267771721],\n",
       "  [-0.04186646267771721],\n",
       "  [-0.04186646267771721],\n",
       "  [-0.041866838932037354],\n",
       "  [-0.04186646267771721]],\n",
       " [[-0.04186644032597542],\n",
       "  [-0.04186646267771721],\n",
       "  [-0.04186655580997467],\n",
       "  [-0.041859716176986694],\n",
       "  [-0.04186675697565079],\n",
       "  [-0.04186640679836273],\n",
       "  [-0.041866205632686615],\n",
       "  [-0.04186646267771721]],\n",
       " [[-0.04186643287539482],\n",
       "  [-0.04186646267771721],\n",
       "  [-0.04186646267771721],\n",
       "  [-0.04186549410223961],\n",
       "  [-0.04186646267771721],\n",
       "  [-0.04186646267771721],\n",
       "  [-0.041866403073072433],\n",
       "  [-0.04186752438545227]],\n",
       " [[-0.04186646267771721],\n",
       "  [-0.0418667234480381],\n",
       "  [-0.04186646267771721],\n",
       "  [-0.04186650365591049],\n",
       "  [-0.04186646267771721],\n",
       "  [-0.04186646267771721],\n",
       "  [-0.04186646267771721],\n",
       "  [-0.04186706617474556]],\n",
       " [[-0.04186646267771721],\n",
       "  [-0.04186646267771721],\n",
       "  [-0.04186663031578064],\n",
       "  [-0.04186646267771721],\n",
       "  [-0.04186646267771721],\n",
       "  [-0.04186646267771721],\n",
       "  [-0.04186646267771721],\n",
       "  [-0.04186663404107094]],\n",
       " [[-0.04186646267771721],\n",
       "  [-0.041866485029459],\n",
       "  [-0.04186646267771721],\n",
       "  [-0.04186662286520004],\n",
       "  [-0.04186646267771721],\n",
       "  [-0.04186650365591049],\n",
       "  [-0.04186646267771721],\n",
       "  [-0.041863273829221725]],\n",
       " [[-0.04186646267771721],\n",
       "  [-0.04186646267771721],\n",
       "  [-0.04186646267771721],\n",
       "  [-0.04186294227838516],\n",
       "  [-0.04186662659049034],\n",
       "  [-0.04186687618494034],\n",
       "  [-0.04186645895242691],\n",
       "  [-0.04186646267771721]],\n",
       " [[-0.04186646267771721],\n",
       "  [-0.04186646267771721],\n",
       "  [-0.04186728969216347],\n",
       "  [-0.04186646267771721],\n",
       "  [-0.04186646267771721],\n",
       "  [-0.04186646267771721],\n",
       "  [-0.041867174208164215],\n",
       "  [-0.0418672151863575]],\n",
       " [[-0.04186641052365303],\n",
       "  [-0.04186646267771721],\n",
       "  [-0.04186646267771721],\n",
       "  [-0.04186646267771721],\n",
       "  [-0.04186654090881348],\n",
       "  [-0.041866499930620193],\n",
       "  [-0.041866324841976166],\n",
       "  [-0.04186646267771721]],\n",
       " [[-0.04186646267771721],\n",
       "  [-0.04186660423874855],\n",
       "  [-0.041866641491651535],\n",
       "  [-0.04186646267771721],\n",
       "  [-0.04186685383319855],\n",
       "  [-0.04186779633164406],\n",
       "  [-0.04186646267771721],\n",
       "  [-0.04186641424894333]],\n",
       " [[-0.04186646267771721],\n",
       "  [-0.04186619073152542],\n",
       "  [-0.04186646267771721],\n",
       "  [-0.04186646267771721],\n",
       "  [-0.0418667234480381],\n",
       "  [-0.041866742074489594],\n",
       "  [-0.04186646267771721],\n",
       "  [-0.04186646267771721]],\n",
       " [[-0.04186646267771721],\n",
       "  [-0.041865117847919464],\n",
       "  [-0.04186646267771721],\n",
       "  [-0.04186646267771721],\n",
       "  [-0.04186646267771721],\n",
       "  [-0.041866425424814224],\n",
       "  [-0.04186646267771721],\n",
       "  [-0.04186646267771721]],\n",
       " [[-0.041867997497320175],\n",
       "  [-0.04186646267771721],\n",
       "  [-0.04186636582016945],\n",
       "  [-0.04186646267771721],\n",
       "  [-0.04186646267771721],\n",
       "  [-0.04186616465449333],\n",
       "  [-0.04186646267771721],\n",
       "  [-0.04186646267771721]],\n",
       " [[-0.041860442608594894],\n",
       "  [-0.04186369851231575],\n",
       "  [-0.04186657443642616],\n",
       "  [-0.04186634346842766],\n",
       "  [-0.04186646267771721],\n",
       "  [-0.04186739772558212],\n",
       "  [-0.041866667568683624],\n",
       "  [-0.04186646267771721]],\n",
       " [[-0.04186646267771721],\n",
       "  [-0.04186663404107094],\n",
       "  [-0.04186690226197243],\n",
       "  [-0.04186232015490532],\n",
       "  [-0.04186646267771721],\n",
       "  [-0.04186646267771721],\n",
       "  [-0.041866425424814224],\n",
       "  [-0.04186714440584183]],\n",
       " [[-0.04186646267771721],\n",
       "  [-0.04186646267771721],\n",
       "  [-0.04186678305268288],\n",
       "  [-0.04186560958623886],\n",
       "  [-0.04186639562249184],\n",
       "  [-0.04186646267771721],\n",
       "  [-0.04186646267771721],\n",
       "  [-0.04186680167913437]],\n",
       " [[-0.04186677560210228],\n",
       "  [-0.04186646267771721],\n",
       "  [-0.04186646267771721],\n",
       "  [-0.04186646267771721],\n",
       "  [-0.04186646267771721],\n",
       "  [-0.04186646267771721],\n",
       "  [-0.04186646267771721],\n",
       "  [-0.041866838932037354]],\n",
       " [[-0.04186660423874855],\n",
       "  [-0.04186641424894333],\n",
       "  [-0.04186534136533737],\n",
       "  [-0.04186275973916054],\n",
       "  [-0.04186618700623512],\n",
       "  [-0.041866485029459],\n",
       "  [-0.04186676815152168],\n",
       "  [-0.0418664813041687]],\n",
       " [[-0.04186646267771721],\n",
       "  [-0.04186646267771721],\n",
       "  [-0.04186646267771721],\n",
       "  [-0.041866499930620193],\n",
       "  [-0.04186644405126572],\n",
       "  [-0.04186646267771721],\n",
       "  [-0.04186646267771721],\n",
       "  [-0.04186646267771721]],\n",
       " [[-0.04186646267771721],\n",
       "  [-0.04186646267771721],\n",
       "  [-0.04186571389436722],\n",
       "  [-0.04186646267771721],\n",
       "  [-0.04186653345823288],\n",
       "  [-0.04186646267771721],\n",
       "  [-0.04186646267771721],\n",
       "  [-0.04186646267771721]],\n",
       " [[-0.04186646267771721],\n",
       "  [-0.04186498746275902],\n",
       "  [-0.04186651110649109],\n",
       "  [-0.04186646267771721],\n",
       "  [-0.04186646267771721],\n",
       "  [-0.041862647980451584],\n",
       "  [-0.04186639189720154],\n",
       "  [-0.04186563566327095]],\n",
       " [[-0.04186646267771721],\n",
       "  [-0.04186686500906944],\n",
       "  [-0.04186646267771721],\n",
       "  [-0.04186646267771721],\n",
       "  [-0.04186646267771721],\n",
       "  [-0.04186646267771721],\n",
       "  [-0.04186646267771721],\n",
       "  [-0.04186677187681198]],\n",
       " [[-0.04186585918068886],\n",
       "  [-0.04186645895242691],\n",
       "  [-0.041866447776556015],\n",
       "  [-0.04186646267771721],\n",
       "  [-0.04186646267771721],\n",
       "  [-0.04186646267771721],\n",
       "  [-0.04186466336250305],\n",
       "  [-0.04186674579977989]],\n",
       " [[-0.04186757281422615],\n",
       "  [-0.041867077350616455],\n",
       "  [-0.04186646267771721],\n",
       "  [-0.04186466708779335],\n",
       "  [-0.04186641797423363],\n",
       "  [-0.04186646267771721],\n",
       "  [-0.04186646267771721],\n",
       "  [-0.04186646267771721]],\n",
       " [[-0.04186646267771721],\n",
       "  [-0.04186646267771721],\n",
       "  [-0.041865091770887375],\n",
       "  [-0.04186646267771721],\n",
       "  [-0.04186646267771721],\n",
       "  [-0.04186687245965004],\n",
       "  [-0.04186646267771721],\n",
       "  [-0.04186646267771721]],\n",
       " [[-0.04186646267771721],\n",
       "  [-0.041866954416036606],\n",
       "  [-0.041866451501846313],\n",
       "  [-0.04186054691672325],\n",
       "  [-0.041866485029459],\n",
       "  [-0.04186646267771721],\n",
       "  [-0.04186646267771721],\n",
       "  [-0.04186315834522247]],\n",
       " [[-0.04186158627271652],\n",
       "  [-0.041864678263664246],\n",
       "  [-0.04186646267771721],\n",
       "  [-0.04186646267771721],\n",
       "  [-0.04186646267771721],\n",
       "  [-0.04186646267771721],\n",
       "  [-0.04186633601784706],\n",
       "  [-0.04186750203371048]],\n",
       " [[-0.04186753183603287],\n",
       "  [-0.04186646267771721],\n",
       "  [-0.04186679422855377],\n",
       "  [-0.04186646267771721],\n",
       "  [-0.04186646267771721],\n",
       "  [-0.04186456650495529],\n",
       "  [-0.04186646267771721],\n",
       "  [-0.04186646267771721]],\n",
       " [[-0.04186646267771721],\n",
       "  [-0.041866205632686615],\n",
       "  [-0.041862551122903824],\n",
       "  [-0.04186646267771721],\n",
       "  [-0.04186680540442467],\n",
       "  [-0.041865695267915726],\n",
       "  [-0.041864555329084396],\n",
       "  [-0.041866544634103775]],\n",
       " [[-0.04186646267771721],\n",
       "  [-0.0418669767677784],\n",
       "  [-0.04186341539025307],\n",
       "  [-0.04186668619513512],\n",
       "  [-0.04186646267771721],\n",
       "  [-0.0418647900223732],\n",
       "  [-0.04186646267771721],\n",
       "  [-0.04186646267771721]],\n",
       " [[-0.04186646267771721],\n",
       "  [-0.041866056621074677],\n",
       "  [-0.041867535561323166],\n",
       "  [-0.04186646267771721],\n",
       "  [-0.04186646267771721],\n",
       "  [-0.04186646267771721],\n",
       "  [-0.04186692088842392],\n",
       "  [-0.041864052414894104]],\n",
       " [[-0.04186646267771721],\n",
       "  [-0.04186639189720154],\n",
       "  [-0.04186646267771721],\n",
       "  [-0.041866861283779144],\n",
       "  [-0.04186646267771721],\n",
       "  [-0.04186564311385155],\n",
       "  [-0.04186670109629631],\n",
       "  [-0.04186646267771721]],\n",
       " [[-0.04186436906456947],\n",
       "  [-0.041866734623909],\n",
       "  [-0.04186658561229706],\n",
       "  [-0.04186642915010452],\n",
       "  [-0.041866499930620193],\n",
       "  [-0.041866544634103775],\n",
       "  [-0.04186677560210228],\n",
       "  [-0.04186646267771721]],\n",
       " [[-0.04186579957604408],\n",
       "  [-0.04186646267771721],\n",
       "  [-0.04186658933758736],\n",
       "  [-0.0418667234480381],\n",
       "  [-0.041866764426231384],\n",
       "  [-0.04186646267771721],\n",
       "  [-0.04186644405126572],\n",
       "  [-0.04186656326055527]],\n",
       " [[-0.04186646267771721],\n",
       "  [-0.04186749458312988],\n",
       "  [-0.04186646267771721],\n",
       "  [-0.041862912476062775],\n",
       "  [-0.04186646267771721],\n",
       "  [-0.04186646267771721],\n",
       "  [-0.04186510667204857],\n",
       "  [-0.041867028921842575]],\n",
       " [[-0.04186646267771721],\n",
       "  [-0.04186646267771721],\n",
       "  [-0.04186646267771721],\n",
       "  [-0.0418662428855896],\n",
       "  [-0.04186646267771721],\n",
       "  [-0.04186500236392021],\n",
       "  [-0.04186713322997093],\n",
       "  [-0.04186646267771721]],\n",
       " [[-0.04186653345823288],\n",
       "  [-0.04186646267771721],\n",
       "  [-0.04186638072133064],\n",
       "  [-0.041866496205329895],\n",
       "  [-0.04186471924185753],\n",
       "  [-0.04186646267771721],\n",
       "  [-0.04186646267771721],\n",
       "  [-0.04186663404107094]],\n",
       " [[-0.04186646267771721],\n",
       "  [-0.04186229780316353],\n",
       "  [-0.04186646267771721],\n",
       "  [-0.04186585918068886],\n",
       "  [-0.04186646267771721],\n",
       "  [-0.04186646640300751],\n",
       "  [-0.041867420077323914],\n",
       "  [-0.04186646267771721]],\n",
       " [[-0.04186646267771721],\n",
       "  [-0.04186646267771721],\n",
       "  [-0.04186289384961128],\n",
       "  [-0.04186658561229706],\n",
       "  [-0.04186646267771721],\n",
       "  [-0.04186646267771721],\n",
       "  [-0.04186667874455452],\n",
       "  [-0.04186704382300377]],\n",
       " [[-0.04186646267771721],\n",
       "  [-0.04186646267771721],\n",
       "  [-0.04186646267771721],\n",
       "  [-0.041866693645715714],\n",
       "  [-0.04186650738120079],\n",
       "  [-0.04186646267771721],\n",
       "  [-0.04186646267771721],\n",
       "  [-0.041864924132823944]],\n",
       " [[-0.04186646267771721],\n",
       "  [-0.041866980493068695],\n",
       "  [-0.04186644032597542],\n",
       "  [-0.041866544634103775],\n",
       "  [-0.04186646267771721],\n",
       "  [-0.04186668246984482],\n",
       "  [-0.04186646267771721],\n",
       "  [-0.041860561817884445]],\n",
       " [[-0.0418664813041687],\n",
       "  [-0.04186646267771721],\n",
       "  [-0.04186645895242691],\n",
       "  [-0.04186646267771721],\n",
       "  [-0.04186654090881348],\n",
       "  [-0.04186646267771721],\n",
       "  [-0.04186646267771721],\n",
       "  [-0.04186646267771721]],\n",
       " [[-0.04186694696545601],\n",
       "  [-0.04186646267771721],\n",
       "  [-0.04186646267771721],\n",
       "  [-0.04186646267771721],\n",
       "  [-0.04186646267771721],\n",
       "  [-0.04186646267771721],\n",
       "  [-0.04186476394534111],\n",
       "  [-0.04186581075191498]],\n",
       " [[-0.04186646267771721],\n",
       "  [-0.04186646267771721],\n",
       "  [-0.04186712205410004],\n",
       "  [-0.04186646267771721],\n",
       "  [-0.04186317324638367],\n",
       "  [-0.04186646267771721],\n",
       "  [-0.04186677560210228],\n",
       "  [-0.04186646267771721]],\n",
       " [[-0.04185689240694046],\n",
       "  [-0.041866350919008255],\n",
       "  [-0.041860152035951614],\n",
       "  [-0.04186646267771721],\n",
       "  [-0.04186631366610527],\n",
       "  [-0.041866883635520935],\n",
       "  [-0.04186692461371422],\n",
       "  [-0.04186646267771721]],\n",
       " [[-0.04186646267771721],\n",
       "  [-0.04186646267771721],\n",
       "  [-0.04186630621552467],\n",
       "  [-0.04186646267771721],\n",
       "  [-0.04186316207051277],\n",
       "  [-0.04186646267771721],\n",
       "  [-0.041866451501846313],\n",
       "  [-0.041865039616823196]],\n",
       " [[-0.04186666011810303],\n",
       "  [-0.041866399347782135],\n",
       "  [-0.041866663843393326],\n",
       "  [-0.041865672916173935],\n",
       "  [-0.04186682030558586],\n",
       "  [-0.04186646267771721],\n",
       "  [-0.041866470128297806],\n",
       "  [-0.04186646267771721]],\n",
       " [[-0.04186496138572693],\n",
       "  [-0.04186646267771721],\n",
       "  [-0.04186524450778961],\n",
       "  [-0.04186646267771721],\n",
       "  [-0.04186667501926422],\n",
       "  [-0.04186646267771721],\n",
       "  [-0.04186646267771721],\n",
       "  [-0.04186646267771721]],\n",
       " [[-0.04186646267771721],\n",
       "  [-0.04186607152223587],\n",
       "  [-0.04186646267771721],\n",
       "  [-0.04186646267771721],\n",
       "  [-0.04186642915010452],\n",
       "  [-0.041867662221193314],\n",
       "  [-0.04186646267771721],\n",
       "  [-0.04186665639281273]],\n",
       " [[-0.04186759516596794],\n",
       "  [-0.04186646267771721],\n",
       "  [-0.04186655953526497],\n",
       "  [-0.04186646267771721],\n",
       "  [-0.04186646267771721],\n",
       "  [-0.041866485029459],\n",
       "  [-0.04186512157320976],\n",
       "  [-0.041866399347782135]],\n",
       " [[-0.04186646267771721],\n",
       "  [-0.04186646267771721],\n",
       "  [-0.04186646267771721],\n",
       "  [-0.04186646267771721],\n",
       "  [-0.04186646267771721],\n",
       "  [-0.04186643287539482],\n",
       "  [-0.04186646267771721],\n",
       "  [-0.041866183280944824]],\n",
       " [[-0.041866764426231384],\n",
       "  [-0.04186646267771721],\n",
       "  [-0.04186336323618889],\n",
       "  [-0.04186360910534859],\n",
       "  [-0.041866812855005264],\n",
       "  [-0.041866376996040344],\n",
       "  [-0.04186646267771721],\n",
       "  [-0.04186646267771721]],\n",
       " [[-0.041866473853588104],\n",
       "  [-0.0418657548725605],\n",
       "  [-0.041867200285196304],\n",
       "  [-0.04186598211526871],\n",
       "  [-0.04186646267771721],\n",
       "  [-0.04186646267771721],\n",
       "  [-0.04186646267771721],\n",
       "  [-0.04186646267771721]],\n",
       " [[-0.04186646267771721],\n",
       "  [-0.04186646267771721],\n",
       "  [-0.04186646267771721],\n",
       "  [-0.04186646267771721],\n",
       "  [-0.04186754301190376],\n",
       "  [-0.04186646267771721],\n",
       "  [-0.04186644405126572],\n",
       "  [-0.041866451501846313]],\n",
       " [[-0.041866738349199295],\n",
       "  [-0.04186713322997093],\n",
       "  [-0.04186670109629631],\n",
       "  [-0.04186604171991348],\n",
       "  [-0.04186646267771721],\n",
       "  [-0.04186662286520004],\n",
       "  [-0.041863445192575455],\n",
       "  [-0.04186646267771721]],\n",
       " [[-0.04186631739139557],\n",
       "  [-0.04186646267771721],\n",
       "  [-0.04186646267771721],\n",
       "  [-0.04186646267771721],\n",
       "  [-0.04186646267771721],\n",
       "  [-0.04186646267771721],\n",
       "  [-0.04186646267771721],\n",
       "  [-0.04186641797423363]],\n",
       " [[-0.04186646267771721],\n",
       "  [-0.04186646267771721],\n",
       "  [-0.04186646267771721],\n",
       "  [-0.04186650365591049],\n",
       "  [-0.04186655580997467],\n",
       "  [-0.041866742074489594],\n",
       "  [-0.0418672114610672],\n",
       "  [-0.04186629131436348]],\n",
       " [[-0.04186636954545975],\n",
       "  [-0.04186646267771721],\n",
       "  [-0.04186493158340454],\n",
       "  [-0.04186646267771721],\n",
       "  [-0.04186674579977989],\n",
       "  [-0.04186653345823288],\n",
       "  [-0.041858792304992676],\n",
       "  [-0.04186646267771721]],\n",
       " [[-0.04186804220080376],\n",
       "  [-0.04186646267771721],\n",
       "  [-0.04186646267771721],\n",
       "  [-0.04186534509062767],\n",
       "  [-0.04186646267771721],\n",
       "  [-0.04186646267771721],\n",
       "  [-0.04186646267771721],\n",
       "  [-0.04186646267771721]],\n",
       " [[-0.04186646267771721],\n",
       "  [-0.04186646267771721],\n",
       "  [-0.04186646267771721],\n",
       "  [-0.041866425424814224],\n",
       "  [-0.041858524084091187],\n",
       "  [-0.04186646267771721],\n",
       "  [-0.04186646267771721],\n",
       "  [-0.0418672040104866]],\n",
       " [[-0.04186682403087616],\n",
       "  [-0.04186320677399635],\n",
       "  [-0.04186733439564705],\n",
       "  [-0.04186646267771721],\n",
       "  [-0.04186646267771721],\n",
       "  [-0.04186646267771721],\n",
       "  [-0.04186646267771721],\n",
       "  [-0.04186644032597542]],\n",
       " [[-0.04186646267771721],\n",
       "  [-0.04186646267771721],\n",
       "  [-0.04186183586716652],\n",
       "  [-0.04186646267771721],\n",
       "  [-0.04186646267771721],\n",
       "  [-0.04186646267771721],\n",
       "  [-0.04186646267771721],\n",
       "  [-0.04186597466468811]],\n",
       " [[-0.04186646267771721],\n",
       "  [-0.04186702519655228],\n",
       "  [-0.041864458471536636],\n",
       "  [-0.041866548359394073],\n",
       "  [-0.04186646267771721],\n",
       "  [-0.0418645516037941],\n",
       "  [-0.04186632111668587],\n",
       "  [-0.04186646267771721]],\n",
       " [[-0.04186646267771721],\n",
       "  [-0.04186660423874855],\n",
       "  [-0.04186791926622391],\n",
       "  [-0.04186646267771721],\n",
       "  [-0.04186650738120079],\n",
       "  [-0.04186657443642616],\n",
       "  [-0.04186636954545975],\n",
       "  [-0.041866522282361984]],\n",
       " [[-0.04186646267771721],\n",
       "  [-0.04186670854687691],\n",
       "  [-0.04186646267771721],\n",
       "  [-0.041867636144161224],\n",
       "  [-0.04186646267771721],\n",
       "  [-0.04186646267771721],\n",
       "  [-0.04186646267771721],\n",
       "  [-0.04186658188700676]],\n",
       " [[-0.04186646267771721],\n",
       "  [-0.04186602309346199],\n",
       "  [-0.04186646267771721],\n",
       "  [-0.04186670854687691],\n",
       "  [-0.04186556115746498],\n",
       "  [-0.04186641424894333],\n",
       "  [-0.04186646267771721],\n",
       "  [-0.04186428338289261]],\n",
       " [[-0.04186646267771721],\n",
       "  [-0.04186646267771721],\n",
       "  [-0.04186646267771721],\n",
       "  [-0.04186766967177391],\n",
       "  [-0.04186436906456947],\n",
       "  [-0.04186646267771721],\n",
       "  [-0.041866447776556015],\n",
       "  [-0.04186641052365303]],\n",
       " [[-0.04186301305890083],\n",
       "  [-0.04186646267771721],\n",
       "  [-0.04186621680855751],\n",
       "  [-0.04186646267771721],\n",
       "  [-0.04186646267771721],\n",
       "  [-0.0418667308986187],\n",
       "  [-0.04186646267771721],\n",
       "  [-0.04186646267771721]],\n",
       " [[-0.04186646267771721],\n",
       "  [-0.041865311563014984],\n",
       "  [-0.04186646267771721],\n",
       "  [-0.04186331853270531],\n",
       "  [-0.04186646267771721],\n",
       "  [-0.04186646267771721],\n",
       "  [-0.04186646267771721],\n",
       "  [-0.04186646267771721]],\n",
       " [[-0.04186725243926048],\n",
       "  [-0.041867077350616455],\n",
       "  [-0.04186646267771721],\n",
       "  [-0.04186682775616646],\n",
       "  [-0.04186646267771721],\n",
       "  [-0.04186646267771721],\n",
       "  [-0.04186646267771721],\n",
       "  [-0.04186646267771721]],\n",
       " [[-0.04186646267771721],\n",
       "  [-0.041866473853588104],\n",
       "  [-0.041865333914756775],\n",
       "  [-0.04186602681875229],\n",
       "  [-0.04186646267771721],\n",
       "  [-0.04186646267771721],\n",
       "  [-0.04186636954545975],\n",
       "  [-0.04186594858765602]],\n",
       " [[-0.04186404123902321],\n",
       "  [-0.04186646267771721],\n",
       "  [-0.0418664813041687],\n",
       "  [-0.04186646267771721],\n",
       "  [-0.04186646267771721],\n",
       "  [-0.04186498001217842],\n",
       "  [-0.04186587035655975],\n",
       "  [-0.04186439886689186]],\n",
       " [[-0.04186646267771721],\n",
       "  [-0.04186660051345825],\n",
       "  [-0.0418669655919075],\n",
       "  [-0.04186646267771721],\n",
       "  [-0.04186646267771721],\n",
       "  [-0.041863974183797836],\n",
       "  [-0.041866548359394073],\n",
       "  [-0.04186646267771721]],\n",
       " [[-0.04186646267771721],\n",
       "  [-0.04186716675758362],\n",
       "  [-0.04186646267771721],\n",
       "  [-0.04186646267771721],\n",
       "  [-0.04186685383319855],\n",
       "  [-0.04186646267771721],\n",
       "  [-0.04186646267771721],\n",
       "  [-0.04186646267771721]],\n",
       " [[-0.04186651110649109],\n",
       "  [-0.04186408221721649],\n",
       "  [-0.04186735302209854],\n",
       "  [-0.04186646267771721],\n",
       "  [-0.04186646267771721],\n",
       "  [-0.04186646267771721],\n",
       "  [-0.04186546057462692],\n",
       "  [-0.04186646267771721]],\n",
       " [[-0.04186711460351944],\n",
       "  [-0.041861820966005325],\n",
       "  [-0.04186646267771721],\n",
       "  [-0.04186646267771721],\n",
       "  [-0.04186646267771721],\n",
       "  [-0.04186290502548218],\n",
       "  [-0.04186646267771721],\n",
       "  [-0.04186646267771721]],\n",
       " [[-0.04186650365591049],\n",
       "  [-0.041866984218358994],\n",
       "  [-0.04186398163437843],\n",
       "  [-0.04186646267771721],\n",
       "  [-0.041867613792419434],\n",
       "  [-0.04186633601784706],\n",
       "  [-0.04186646267771721],\n",
       "  [-0.04186710715293884]],\n",
       " [[-0.041866544634103775],\n",
       "  [-0.041866201907396317],\n",
       "  [-0.04186646267771721],\n",
       "  [-0.04186646267771721],\n",
       "  [-0.04186645895242691],\n",
       "  [-0.04186646267771721],\n",
       "  [-0.04186701402068138],\n",
       "  [-0.04186573624610901]],\n",
       " [[-0.04186660796403885],\n",
       "  [-0.04185536131262779],\n",
       "  [-0.04186646640300751],\n",
       "  [-0.04186646267771721],\n",
       "  [-0.04186588153243065],\n",
       "  [-0.041862551122903824],\n",
       "  [-0.04186642915010452],\n",
       "  [-0.04186646267771721]],\n",
       " [[-0.041865214705467224],\n",
       "  [-0.0418664813041687],\n",
       "  [-0.04186646267771721],\n",
       "  [-0.04186452552676201],\n",
       "  [-0.04186646267771721],\n",
       "  [-0.041867174208164215],\n",
       "  [-0.041866421699523926],\n",
       "  [-0.04186194762587547]],\n",
       " [[-0.041866835206747055],\n",
       "  [-0.04186691343784332],\n",
       "  [-0.04186646267771721],\n",
       "  [-0.04186592996120453],\n",
       "  [-0.04186646267771721],\n",
       "  [-0.041866905987262726],\n",
       "  [-0.041866835206747055],\n",
       "  [-0.04186646267771721]],\n",
       " [[-0.04186646267771721],\n",
       "  [-0.04186646267771721],\n",
       "  [-0.04186646267771721],\n",
       "  [-0.0418640673160553],\n",
       "  [-0.04186646267771721],\n",
       "  [-0.04186684265732765],\n",
       "  [-0.041866615414619446],\n",
       "  [-0.04186604544520378]],\n",
       " [[-0.04186511039733887],\n",
       "  [-0.04186161980032921],\n",
       "  [-0.04186641797423363],\n",
       "  [-0.04186646267771721],\n",
       "  [-0.04186520352959633],\n",
       "  [-0.04186104238033295],\n",
       "  [-0.04186699911952019],\n",
       "  [-0.041866958141326904]],\n",
       " [[-0.04186641424894333],\n",
       "  [-0.04186646267771721],\n",
       "  [-0.04186643660068512],\n",
       "  [-0.04186362028121948],\n",
       "  [-0.04186646267771721],\n",
       "  [-0.04186210036277771],\n",
       "  [-0.04186650738120079],\n",
       "  [-0.04186684265732765]],\n",
       " [[-0.04186646267771721],\n",
       "  [-0.04186428710818291],\n",
       "  [-0.041866451501846313],\n",
       "  [-0.04186646267771721],\n",
       "  [-0.04186646267771721],\n",
       "  [-0.04186663776636124],\n",
       "  [-0.041862860321998596],\n",
       "  [-0.041866499930620193]],\n",
       " [[-0.04186670854687691],\n",
       "  [-0.04186646267771721],\n",
       "  [-0.041864920407533646],\n",
       "  [-0.04186715558171272],\n",
       "  [-0.04186725616455078],\n",
       "  [-0.04186646267771721],\n",
       "  [-0.04186509922146797],\n",
       "  [-0.04186646267771721]],\n",
       " [[-0.04186646267771721],\n",
       "  [-0.04186646267771721],\n",
       "  [-0.041866470128297806],\n",
       "  [-0.04186611622571945],\n",
       "  [-0.04186646267771721],\n",
       "  [-0.04186646267771721],\n",
       "  [-0.04186646267771721],\n",
       "  [-0.04186646267771721]],\n",
       " [[-0.04186646267771721],\n",
       "  [-0.04186646267771721],\n",
       "  [-0.04186646267771721],\n",
       "  [-0.04186646267771721],\n",
       "  [-0.04186646267771721],\n",
       "  [-0.0418664924800396],\n",
       "  [-0.04186781495809555],\n",
       "  [-0.04186345636844635]],\n",
       " [[-0.0418667197227478],\n",
       "  [-0.041866447776556015],\n",
       "  [-0.041867125779390335],\n",
       "  [-0.04186741262674332],\n",
       "  [-0.04186483845114708],\n",
       "  [-0.041866809129714966],\n",
       "  [-0.04186646267771721],\n",
       "  [-0.04186587780714035]],\n",
       " [[-0.041866302490234375],\n",
       "  [-0.04186646267771721],\n",
       "  [-0.04186636954545975],\n",
       "  [-0.04186444729566574],\n",
       "  [-0.041866350919008255],\n",
       "  [-0.04186646267771721],\n",
       "  [-0.041867319494485855],\n",
       "  [-0.04186676815152168]],\n",
       " [[-0.04186646267771721],\n",
       "  [-0.0418669618666172],\n",
       "  [-0.04186646267771721],\n",
       "  [-0.04186646267771721],\n",
       "  [-0.041866518557071686],\n",
       "  [-0.04186664894223213],\n",
       "  [-0.04186646640300751],\n",
       "  [-0.04186666011810303]],\n",
       " [[-0.04186646267771721],\n",
       "  [-0.041864316910505295],\n",
       "  [-0.041863568127155304],\n",
       "  [-0.04186646267771721],\n",
       "  [-0.04186646267771721],\n",
       "  [-0.041865311563014984],\n",
       "  [-0.04186646267771721],\n",
       "  [-0.04186646267771721]],\n",
       " [[-0.04186646267771721],\n",
       "  [-0.04186646267771721],\n",
       "  [-0.041866909712553024],\n",
       "  [-0.041859954595565796],\n",
       "  [-0.0418650284409523],\n",
       "  [-0.04186702519655228],\n",
       "  [-0.041865989565849304],\n",
       "  [-0.04186646267771721]],\n",
       " [[-0.041866473853588104],\n",
       "  [-0.041861843317747116],\n",
       "  [-0.04186646267771721],\n",
       "  [-0.041866693645715714],\n",
       "  [-0.04186496138572693],\n",
       "  [-0.04186621308326721],\n",
       "  [-0.04186158999800682],\n",
       "  [-0.04186694696545601]],\n",
       " [[-0.04186646267771721],\n",
       "  [-0.04186646267771721],\n",
       "  [-0.04186646267771721],\n",
       "  [-0.041864313185214996],\n",
       "  [-0.0418664887547493],\n",
       "  [-0.04186646267771721],\n",
       "  [-0.04186642915010452],\n",
       "  [-0.04186380282044411]],\n",
       " [[-0.04186457395553589],\n",
       "  [-0.04186646267771721],\n",
       "  [-0.04186646267771721],\n",
       "  [-0.04186646267771721],\n",
       "  [-0.04186670482158661],\n",
       "  [-0.04186646267771721],\n",
       "  [-0.04186646267771721],\n",
       "  [-0.04186646267771721]],\n",
       " [[-0.041865311563014984],\n",
       "  [-0.04186646267771721],\n",
       "  [-0.04186646267771721],\n",
       "  [-0.04186643660068512],\n",
       "  [-0.04186656326055527],\n",
       "  [-0.04186646267771721],\n",
       "  [-0.04186536744236946],\n",
       "  [-0.04186646267771721]],\n",
       " [[-0.04186646267771721],\n",
       "  [-0.04186646267771721],\n",
       "  [-0.04186646267771721],\n",
       "  [-0.04186692461371422],\n",
       "  [-0.04186625778675079],\n",
       "  [-0.04186646267771721],\n",
       "  [-0.04186646267771721],\n",
       "  [-0.04186762496829033]],\n",
       " [[-0.04186654090881348],\n",
       "  [-0.04186655580997467],\n",
       "  [-0.041866280138492584],\n",
       "  [-0.04186515510082245],\n",
       "  [-0.04186701774597168],\n",
       "  [-0.04186410829424858],\n",
       "  [-0.041866548359394073],\n",
       "  [-0.04186495020985603]],\n",
       " [[-0.0418664924800396],\n",
       "  [-0.04186646267771721],\n",
       "  [-0.04186646267771721],\n",
       "  [-0.04186646267771721],\n",
       "  [-0.041867807507514954],\n",
       "  [-0.041866376996040344],\n",
       "  [-0.04186634719371796],\n",
       "  [-0.04186709597706795]],\n",
       " [[-0.0418664813041687],\n",
       "  [-0.04186658933758736],\n",
       "  [-0.04186646267771721],\n",
       "  [-0.04186646640300751],\n",
       "  [-0.04186646640300751],\n",
       "  [-0.04186646267771721],\n",
       "  [-0.04186646267771721],\n",
       "  [-0.0418664813041687]],\n",
       " [[-0.04186646267771721],\n",
       "  [-0.041866615414619446],\n",
       "  [-0.04186739772558212],\n",
       "  [-0.04186646267771721],\n",
       "  [-0.041864410042762756],\n",
       "  [-0.041866473853588104],\n",
       "  [-0.04186646267771721],\n",
       "  [-0.04186661168932915]],\n",
       " [[-0.04186644405126572],\n",
       "  [-0.041866715997457504],\n",
       "  [-0.04186568781733513],\n",
       "  [-0.04186719283461571],\n",
       "  [-0.04186646267771721],\n",
       "  [-0.04186425358057022],\n",
       "  [-0.0418664924800396],\n",
       "  [-0.04186481237411499]],\n",
       " [[-0.041865698993206024],\n",
       "  [-0.04186646267771721],\n",
       "  [-0.04186646267771721],\n",
       "  [-0.04186646267771721],\n",
       "  [-0.04186646267771721],\n",
       "  [-0.04186646267771721],\n",
       "  [-0.04186644032597542],\n",
       "  [-0.04186646267771721]],\n",
       " [[-0.04186636209487915],\n",
       "  [-0.04186646267771721],\n",
       "  [-0.04186646267771721],\n",
       "  [-0.04186646267771721],\n",
       "  [-0.04186629503965378],\n",
       "  [-0.04186646267771721],\n",
       "  [-0.04186713322997093],\n",
       "  [-0.04186646267771721]],\n",
       " [[-0.04186517745256424],\n",
       "  [-0.04186646267771721],\n",
       "  [-0.04186646267771721],\n",
       "  [-0.0418640598654747],\n",
       "  [-0.04186646267771721],\n",
       "  [-0.04186646267771721],\n",
       "  [-0.041867416352033615],\n",
       "  [-0.04186646267771721]],\n",
       " [[-0.04186646640300751],\n",
       "  [-0.04186656326055527],\n",
       "  [-0.041864268481731415],\n",
       "  [-0.04186620935797691],\n",
       "  [-0.04186646267771721],\n",
       "  [-0.0418664887547493],\n",
       "  [-0.04186646267771721],\n",
       "  [-0.04186646267771721]],\n",
       " [[-0.04186663031578064],\n",
       "  [-0.04186646267771721],\n",
       "  [-0.04186646267771721],\n",
       "  [-0.04186646267771721],\n",
       "  [-0.04186653345823288],\n",
       "  [-0.04186646267771721],\n",
       "  [-0.041866447776556015],\n",
       "  [-0.04186528921127319]],\n",
       " [[-0.04186644032597542],\n",
       "  [-0.04186646267771721],\n",
       "  [-0.04186670109629631],\n",
       "  [-0.04186662286520004],\n",
       "  [-0.04186646267771721],\n",
       "  [-0.04186693951487541],\n",
       "  [-0.041867103427648544],\n",
       "  [-0.04186646267771721]],\n",
       " [[-0.041866742074489594],\n",
       "  [-0.04186646267771721],\n",
       "  [-0.04186646267771721],\n",
       "  [-0.04186646267771721],\n",
       "  [-0.0418657548725605],\n",
       "  [-0.041866883635520935],\n",
       "  [-0.04186646267771721],\n",
       "  [-0.04186646267771721]],\n",
       " [[-0.0418635793030262],\n",
       "  [-0.04186646267771721],\n",
       "  [-0.041862037032842636],\n",
       "  [-0.04186645895242691],\n",
       "  [-0.04186646267771721],\n",
       "  [-0.04186474159359932],\n",
       "  [-0.04186725616455078],\n",
       "  [-0.04186645895242691]],\n",
       " [[-0.04186651483178139],\n",
       "  [-0.04186646267771721],\n",
       "  [-0.0418657548725605],\n",
       "  [-0.04186633601784706],\n",
       "  [-0.04186646267771721],\n",
       "  [-0.041864052414894104],\n",
       "  [-0.04186646267771721],\n",
       "  [-0.041866105049848557]],\n",
       " [[-0.04186626523733139],\n",
       "  [-0.04186238348484039],\n",
       "  [-0.04186646267771721],\n",
       "  [-0.04186646267771721],\n",
       "  [-0.04186646267771721],\n",
       "  [-0.04186651483178139],\n",
       "  [-0.041864413768053055],\n",
       "  [-0.04186646267771721]],\n",
       " [[-0.04186474531888962],\n",
       "  [-0.04186407849192619],\n",
       "  [-0.04186646267771721],\n",
       "  [-0.04186646267771721],\n",
       "  [-0.04186662659049034],\n",
       "  [-0.04186684265732765],\n",
       "  [-0.041864197701215744],\n",
       "  [-0.04186646267771721]],\n",
       " [[-0.04186714440584183],\n",
       "  [-0.04186646267771721],\n",
       "  [-0.041864462196826935],\n",
       "  [-0.04186619818210602],\n",
       "  [-0.04186646267771721],\n",
       "  [-0.041866485029459],\n",
       "  [-0.04186691343784332],\n",
       "  [-0.04186646267771721]],\n",
       " [[-0.04186646267771721],\n",
       "  [-0.04186646267771721],\n",
       "  [-0.041867367923259735],\n",
       "  [-0.04186646267771721],\n",
       "  [-0.04186598211526871],\n",
       "  [-0.04186639189720154],\n",
       "  [-0.04186616092920303],\n",
       "  [-0.04186646267771721]],\n",
       " [[-0.041866518557071686],\n",
       "  [-0.04186646267771721],\n",
       "  [-0.04186646267771721],\n",
       "  [-0.04186646267771721],\n",
       "  [-0.041866399347782135],\n",
       "  [-0.04186646267771721],\n",
       "  [-0.04186498001217842],\n",
       "  [-0.04186646267771721]],\n",
       " [[-0.04186646267771721],\n",
       "  [-0.041866470128297806],\n",
       "  [-0.04186687991023064],\n",
       "  [-0.04186646267771721],\n",
       "  [-0.04186677560210228],\n",
       "  [-0.04186646267771721],\n",
       "  [-0.04186646267771721],\n",
       "  [-0.04186680167913437]],\n",
       " [[-0.041866715997457504],\n",
       "  [-0.04186646267771721],\n",
       "  [-0.04186646267771721],\n",
       "  [-0.04186646267771721],\n",
       "  [-0.04186713695526123],\n",
       "  [-0.04186756908893585],\n",
       "  [-0.041866399347782135],\n",
       "  [-0.04186646267771721]],\n",
       " [[-0.041866615414619446],\n",
       "  [-0.04186646267771721],\n",
       "  [-0.04186646267771721],\n",
       "  [-0.04186646267771721],\n",
       "  [-0.04186655208468437],\n",
       "  [-0.04186646267771721],\n",
       "  [-0.041866809129714966],\n",
       "  [-0.04186646267771721]],\n",
       " [[-0.04186646267771721],\n",
       "  [-0.04186646267771721],\n",
       "  [-0.04186646267771721],\n",
       "  [-0.041866596788167953],\n",
       "  [-0.041866909712553024],\n",
       "  [-0.04186646267771721],\n",
       "  [-0.0418669767677784],\n",
       "  [-0.04186646267771721]],\n",
       " [[-0.04186609014868736],\n",
       "  [-0.04186549037694931],\n",
       "  [-0.04186635464429855],\n",
       "  [-0.04186660423874855],\n",
       "  [-0.041866838932037354],\n",
       "  [-0.041866544634103775],\n",
       "  [-0.04186646267771721],\n",
       "  [-0.04186665639281273]],\n",
       " [[-0.04186646267771721],\n",
       "  [-0.04186646267771721],\n",
       "  [-0.04186646267771721],\n",
       "  [-0.04186646267771721],\n",
       "  [-0.04186636582016945],\n",
       "  [-0.04186646267771721],\n",
       "  [-0.04186646267771721],\n",
       "  [-0.04186646267771721]],\n",
       " [[-0.04186646267771721],\n",
       "  [-0.04186646267771721],\n",
       "  [-0.04186767712235451],\n",
       "  [-0.04186646267771721],\n",
       "  [-0.04186646267771721],\n",
       "  [-0.04186695069074631],\n",
       "  [-0.04186646267771721],\n",
       "  [-0.04186643660068512]],\n",
       " [[-0.04186652973294258],\n",
       "  [-0.04186646267771721],\n",
       "  [-0.04186646267771721],\n",
       "  [-0.04186670482158661],\n",
       "  [-0.04186667501926422],\n",
       "  [-0.0418664775788784],\n",
       "  [-0.04186646267771721],\n",
       "  [-0.041867174208164215]],\n",
       " [[-0.04186646267771721],\n",
       "  [-0.04186662286520004],\n",
       "  [-0.04186660051345825],\n",
       "  [-0.04186646267771721],\n",
       "  [-0.04186646267771721],\n",
       "  [-0.04186630994081497],\n",
       "  [-0.04186630621552467],\n",
       "  [-0.04186645522713661]],\n",
       " [[-0.041866566985845566],\n",
       "  [-0.04186646267771721],\n",
       "  [-0.04186631366610527],\n",
       "  [-0.04186280444264412],\n",
       "  [-0.04186646267771721],\n",
       "  [-0.04186646267771721],\n",
       "  [-0.04186646267771721],\n",
       "  [-0.04186650738120079]],\n",
       " [[-0.04186522215604782],\n",
       "  [-0.041866544634103775],\n",
       "  [-0.04186646267771721],\n",
       "  [-0.04186646267771721],\n",
       "  [-0.04186699166893959],\n",
       "  [-0.04186448082327843],\n",
       "  [-0.04186646267771721],\n",
       "  [-0.04186588153243065]],\n",
       " [[-0.04186580330133438],\n",
       "  [-0.04186646267771721],\n",
       "  [-0.0418664775788784],\n",
       "  [-0.04186668619513512],\n",
       "  [-0.04186646267771721],\n",
       "  [-0.041865088045597076],\n",
       "  [-0.04186646267771721],\n",
       "  [-0.04186643287539482]],\n",
       " [[-0.041866060346364975],\n",
       "  [-0.0418664887547493],\n",
       "  [-0.04186612367630005],\n",
       "  [-0.04186693951487541],\n",
       "  [-0.04186757281422615],\n",
       "  [-0.04186663776636124],\n",
       "  [-0.04186646267771721],\n",
       "  [-0.04186646267771721]],\n",
       " [[-0.04186636209487915],\n",
       "  [-0.04186646267771721],\n",
       "  [-0.04186646267771721],\n",
       "  [-0.04186667501926422],\n",
       "  [-0.04186646267771721],\n",
       "  [-0.04186549782752991],\n",
       "  [-0.0418664775788784],\n",
       "  [-0.04186652973294258]],\n",
       " [[-0.04186638817191124],\n",
       "  [-0.04186646267771721],\n",
       "  [-0.04186646267771721],\n",
       "  [-0.04186646267771721],\n",
       "  [-0.04186646267771721],\n",
       "  [-0.041866905987262726],\n",
       "  [-0.04186646267771721],\n",
       "  [-0.04186646267771721]],\n",
       " [[-0.041866276413202286],\n",
       "  [-0.04186646267771721],\n",
       "  [-0.04186646267771721],\n",
       "  [-0.04186646267771721],\n",
       "  [-0.04186646267771721],\n",
       "  [-0.04186646640300751],\n",
       "  [-0.04186653718352318],\n",
       "  [-0.041862260550260544]],\n",
       " [[-0.04186674579977989],\n",
       "  [-0.04186754301190376],\n",
       "  [-0.04186646267771721],\n",
       "  [-0.04186701402068138],\n",
       "  [-0.04186701029539108],\n",
       "  [-0.04186646267771721],\n",
       "  [-0.04186646267771721],\n",
       "  [-0.04186646267771721]],\n",
       " [[-0.04186220467090607],\n",
       "  [-0.04186635836958885],\n",
       "  [-0.04186633229255676],\n",
       "  [-0.04186646267771721],\n",
       "  [-0.04186646267771721],\n",
       "  [-0.04186646267771721],\n",
       "  [-0.04186676815152168],\n",
       "  [-0.041865620762109756]],\n",
       " [[-0.04186646267771721],\n",
       "  [-0.0418667234480381],\n",
       "  [-0.04186646267771721],\n",
       "  [-0.04186646267771721],\n",
       "  [-0.04186663031578064],\n",
       "  [-0.041867394000291824],\n",
       "  [-0.04186607152223587],\n",
       "  [-0.04186512157320976]],\n",
       " [[-0.041864361613988876],\n",
       "  [-0.04186646267771721],\n",
       "  [-0.04186628386378288],\n",
       "  [-0.04186646267771721],\n",
       "  [-0.04186646267771721],\n",
       "  [-0.04186646267771721],\n",
       "  [-0.04186465963721275],\n",
       "  [-0.0418662503361702]],\n",
       " [[-0.041866812855005264],\n",
       "  [-0.04186646267771721],\n",
       "  [-0.04186568036675453],\n",
       "  [-0.041866693645715714],\n",
       "  [-0.04186646267771721],\n",
       "  [-0.04186646267771721],\n",
       "  [-0.04186651483178139],\n",
       "  [-0.04186646267771721]],\n",
       " [[-0.04186646267771721],\n",
       "  [-0.04186646267771721],\n",
       "  [-0.0418667308986187],\n",
       "  [-0.04186689853668213],\n",
       "  [-0.04186646267771721],\n",
       "  [-0.0418626107275486],\n",
       "  [-0.041866425424814224],\n",
       "  [-0.0418667234480381]],\n",
       " [[-0.04186646267771721],\n",
       "  [-0.041858769953250885],\n",
       "  [-0.04186646267771721],\n",
       "  [-0.04186646267771721],\n",
       "  [-0.04186646267771721],\n",
       "  [-0.04186640679836273],\n",
       "  [-0.04186646267771721],\n",
       "  [-0.04186646267771721]],\n",
       " [[-0.04186646267771721],\n",
       "  [-0.04186646267771721],\n",
       "  [-0.04186476767063141],\n",
       "  [-0.041865330189466476],\n",
       "  [-0.04186675325036049],\n",
       "  [-0.04186646267771721],\n",
       "  [-0.041866373270750046],\n",
       "  [-0.04186630994081497]],\n",
       " [[-0.04186646267771721],\n",
       "  [-0.04186646267771721],\n",
       "  [-0.04186646267771721],\n",
       "  [-0.04186646267771721],\n",
       "  [-0.04186646267771721],\n",
       "  [-0.041867438703775406],\n",
       "  [-0.04186646267771721],\n",
       "  [-0.04186646267771721]],\n",
       " [[-0.04186643660068512],\n",
       "  [-0.04186646267771721],\n",
       "  [-0.04186573624610901],\n",
       "  [-0.04186704009771347],\n",
       "  [-0.04186718165874481],\n",
       "  [-0.04186646267771721],\n",
       "  [-0.04186084121465683],\n",
       "  [-0.04186646267771721]],\n",
       " [[-0.04186636954545975],\n",
       "  [-0.04186483100056648],\n",
       "  [-0.04186646267771721],\n",
       "  [-0.04186646267771721],\n",
       "  [-0.04186646267771721],\n",
       "  [-0.041866522282361984],\n",
       "  [-0.04186698794364929],\n",
       "  [-0.04186645895242691]],\n",
       " [[-0.041855163872241974],\n",
       "  [-0.04186701774597168],\n",
       "  [-0.04186646267771721],\n",
       "  [-0.041866861283779144],\n",
       "  [-0.04186655208468437],\n",
       "  [-0.04186646267771721],\n",
       "  [-0.04186651110649109],\n",
       "  [-0.04186646267771721]],\n",
       " [[-0.04186663031578064],\n",
       "  [-0.04186646267771721],\n",
       "  [-0.04186646267771721],\n",
       "  [-0.04186646267771721],\n",
       "  [-0.04186646267771721],\n",
       "  [-0.041867420077323914],\n",
       "  [-0.041862595826387405],\n",
       "  [-0.041865553706884384]],\n",
       " [[-0.04186646267771721],\n",
       "  [-0.04186646267771721],\n",
       "  [-0.04186646267771721],\n",
       "  [-0.04186646267771721],\n",
       "  [-0.04186684265732765],\n",
       "  [-0.04186646267771721],\n",
       "  [-0.04186638072133064],\n",
       "  [-0.041857607662677765]],\n",
       " [[-0.04186646267771721],\n",
       "  [-0.041865602135658264],\n",
       "  [-0.04186617210507393],\n",
       "  [-0.04186646267771721],\n",
       "  [-0.04186646267771721],\n",
       "  [-0.04186515510082245],\n",
       "  [-0.04186646267771721],\n",
       "  [-0.04186646267771721]],\n",
       " [[-0.04186677187681198],\n",
       "  [-0.04186423867940903],\n",
       "  [-0.04186646267771721],\n",
       "  [-0.04186636582016945],\n",
       "  [-0.04186646640300751],\n",
       "  [-0.04186496511101723],\n",
       "  [-0.04186646267771721],\n",
       "  [-0.04186646267771721]],\n",
       " [[-0.041866764426231384],\n",
       "  [-0.04186646267771721],\n",
       "  [-0.04186566546559334],\n",
       "  [-0.04186646267771721],\n",
       "  [-0.04186655208468437],\n",
       "  [-0.04186646267771721],\n",
       "  [-0.04186646267771721],\n",
       "  [-0.041863445192575455]],\n",
       " [[-0.04186646267771721],\n",
       "  [-0.0418667308986187],\n",
       "  [-0.04186646267771721],\n",
       "  [-0.04186588153243065],\n",
       "  [-0.04186646267771721],\n",
       "  [-0.04186646267771721],\n",
       "  [-0.04186646267771721],\n",
       "  [-0.04186401143670082]],\n",
       " [[-0.04186535254120827],\n",
       "  [-0.041866451501846313],\n",
       "  [-0.04186653718352318],\n",
       "  [-0.04186646267771721],\n",
       "  [-0.04186646267771721],\n",
       "  [-0.04186655953526497],\n",
       "  [-0.041866544634103775],\n",
       "  [-0.04186646267771721]],\n",
       " [[-0.04186652973294258],\n",
       "  [-0.04186646267771721],\n",
       "  [-0.041866522282361984],\n",
       "  [-0.04186646267771721],\n",
       "  [-0.04186542332172394],\n",
       "  [-0.04186646267771721],\n",
       "  [-0.04186646267771721],\n",
       "  [-0.04186692833900452]],\n",
       " [[-0.041866302490234375],\n",
       "  [-0.04186646267771721],\n",
       "  [-0.04186646267771721],\n",
       "  [-0.04186644032597542],\n",
       "  [-0.04186646267771721],\n",
       "  [-0.041861873120069504],\n",
       "  [-0.04186646267771721],\n",
       "  [-0.04186653345823288]],\n",
       " [[-0.04186646267771721],\n",
       "  [-0.04186646267771721],\n",
       "  [-0.04186646267771721],\n",
       "  [-0.04186693951487541],\n",
       "  [-0.04186396673321724],\n",
       "  [-0.04186644405126572],\n",
       "  [-0.041866715997457504],\n",
       "  [-0.04186661168932915]],\n",
       " [[-0.04186625778675079],\n",
       "  [-0.04186646267771721],\n",
       "  [-0.04186646267771721],\n",
       "  [-0.041868165135383606],\n",
       "  [-0.04186646267771721],\n",
       "  [-0.04186662286520004],\n",
       "  [-0.04186626523733139],\n",
       "  [-0.04186614602804184]],\n",
       " [[-0.04186618700623512],\n",
       "  [-0.04186421260237694],\n",
       "  [-0.04186646267771721],\n",
       "  [-0.04186646267771721],\n",
       "  [-0.04186646267771721],\n",
       "  [-0.04186646267771721],\n",
       "  [-0.04186646267771721],\n",
       "  [-0.04186639189720154]],\n",
       " [[-0.041866425424814224],\n",
       "  [-0.04186646267771721],\n",
       "  [-0.0418672040104866],\n",
       "  [-0.04186641052365303],\n",
       "  [-0.04186646267771721],\n",
       "  [-0.041864216327667236],\n",
       "  [-0.04186646267771721],\n",
       "  [-0.04186663031578064]],\n",
       " [[-0.04186646267771721],\n",
       "  [-0.04186684638261795],\n",
       "  [-0.04186622425913811],\n",
       "  [-0.04186646267771721]]]"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "preds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "655feae9",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[-0.04186757653951645,\n",
       " -0.04186631739139557,\n",
       " -0.04186646267771721,\n",
       " -0.041866548359394073,\n",
       " -0.04186636209487915,\n",
       " -0.04186646267771721,\n",
       " -0.04186452925205231,\n",
       " -0.04186646267771721,\n",
       " -0.0418664924800396,\n",
       " -0.04186708852648735,\n",
       " -0.041864797472953796,\n",
       " -0.04186587780714035,\n",
       " -0.041866712272167206,\n",
       " -0.04186646267771721,\n",
       " -0.04186539351940155,\n",
       " -0.04186646267771721,\n",
       " -0.04186646267771721,\n",
       " -0.04186646267771721,\n",
       " -0.04186747595667839,\n",
       " -0.04186582565307617,\n",
       " -0.0418664775788784,\n",
       " -0.04186646267771721,\n",
       " -0.04186646267771721,\n",
       " -0.04186723753809929,\n",
       " -0.04186646267771721,\n",
       " -0.04186629131436348,\n",
       " -0.04186353087425232,\n",
       " -0.04186646267771721,\n",
       " -0.041866485029459,\n",
       " -0.04186646267771721,\n",
       " -0.04186646267771721,\n",
       " -0.04186646267771721,\n",
       " -0.041867323219776154,\n",
       " -0.041865866631269455,\n",
       " -0.04186646267771721,\n",
       " -0.04186646267771721,\n",
       " -0.04186646267771721,\n",
       " -0.04186616837978363,\n",
       " -0.041866470128297806,\n",
       " -0.04186646267771721,\n",
       " -0.041866403073072433,\n",
       " -0.041866485029459,\n",
       " -0.04186646267771721,\n",
       " -0.04186646267771721,\n",
       " -0.04186616837978363,\n",
       " -0.04186646267771721,\n",
       " -0.041866786777973175,\n",
       " -0.04186646267771721,\n",
       " -0.04186471179127693,\n",
       " -0.041867148131132126,\n",
       " -0.041866470128297806,\n",
       " -0.04186646267771721,\n",
       " -0.041866421699523926,\n",
       " -0.041866108775138855,\n",
       " -0.04186779260635376,\n",
       " -0.041866980493068695,\n",
       " -0.041865602135658264,\n",
       " -0.04186680167913437,\n",
       " -0.041866615414619446,\n",
       " -0.04186646267771721,\n",
       " -0.04186646267771721,\n",
       " -0.04186646267771721,\n",
       " -0.0418664924800396,\n",
       " -0.04186646267771721,\n",
       " -0.04186715930700302,\n",
       " -0.04186642915010452,\n",
       " -0.04186646267771721,\n",
       " -0.04186646267771721,\n",
       " -0.04186646267771721,\n",
       " -0.04186664894223213,\n",
       " -0.04186674952507019,\n",
       " -0.04186646267771721,\n",
       " -0.04186666011810303,\n",
       " -0.04186646267771721,\n",
       " -0.04186655580997467,\n",
       " -0.041866838932037354,\n",
       " -0.04186646267771721,\n",
       " -0.04186595603823662,\n",
       " -0.041866522282361984,\n",
       " -0.04186646267771721,\n",
       " -0.04186646267771721,\n",
       " -0.04186653345823288,\n",
       " -0.04186693951487541,\n",
       " -0.04186658933758736,\n",
       " -0.04186590015888214,\n",
       " -0.04186646267771721,\n",
       " -0.04186646267771721,\n",
       " -0.04186486452817917,\n",
       " -0.041866738349199295,\n",
       " -0.041866667568683624,\n",
       " -0.04186646267771721,\n",
       " -0.04186645522713661,\n",
       " -0.04186646267771721,\n",
       " -0.04186682030558586,\n",
       " -0.04186646267771721,\n",
       " -0.04186646267771721,\n",
       " -0.04186646267771721,\n",
       " -0.04186646267771721,\n",
       " -0.04186401143670082,\n",
       " -0.04186646267771721,\n",
       " -0.04186646267771721,\n",
       " -0.041866131126880646,\n",
       " -0.04186622425913811,\n",
       " -0.0418633371591568,\n",
       " -0.04186636954545975,\n",
       " -0.041866615414619446,\n",
       " -0.04186646267771721,\n",
       " -0.04186646267771721,\n",
       " -0.04186687245965004,\n",
       " -0.04186692833900452,\n",
       " -0.04186646267771721,\n",
       " -0.041866667568683624,\n",
       " -0.04186646267771721,\n",
       " -0.04186646267771721,\n",
       " -0.04186646267771721,\n",
       " -0.04186646267771721,\n",
       " -0.04186670482158661,\n",
       " -0.04186646267771721,\n",
       " -0.04186646267771721,\n",
       " -0.04186646267771721,\n",
       " -0.04186621308326721,\n",
       " -0.04186646267771721,\n",
       " -0.04186646267771721,\n",
       " -0.04186646267771721,\n",
       " -0.04186639562249184,\n",
       " -0.04186646267771721,\n",
       " -0.04186646267771721,\n",
       " -0.041860274970531464,\n",
       " -0.04186646267771721,\n",
       " -0.04186646267771721,\n",
       " -0.04186646267771721,\n",
       " -0.04186629131436348,\n",
       " -0.0418643020093441,\n",
       " -0.041866425424814224,\n",
       " -0.041862305253744125,\n",
       " -0.04186646267771721,\n",
       " -0.04186646267771721,\n",
       " -0.04186646267771721,\n",
       " -0.04186646267771721,\n",
       " -0.04186646267771721,\n",
       " -0.04186646267771721,\n",
       " -0.04186646267771721,\n",
       " -0.041866593062877655,\n",
       " -0.04186755046248436,\n",
       " -0.04186656326055527,\n",
       " -0.041866738349199295,\n",
       " -0.04186620935797691,\n",
       " -0.04186646267771721,\n",
       " -0.04186682775616646,\n",
       " -0.04186295345425606,\n",
       " -0.04186646267771721,\n",
       " -0.04186464473605156,\n",
       " -0.04186538979411125,\n",
       " -0.04186646267771721,\n",
       " -0.04186646267771721,\n",
       " -0.041866548359394073,\n",
       " -0.041866570711135864,\n",
       " -0.04186662659049034,\n",
       " -0.04186646267771721,\n",
       " -0.04186646267771721,\n",
       " -0.04186735674738884,\n",
       " -0.04186646267771721,\n",
       " -0.04186646267771721,\n",
       " -0.04186702147126198,\n",
       " -0.04186646267771721,\n",
       " -0.04186646267771721,\n",
       " -0.04186646267771721,\n",
       " -0.041867729276418686,\n",
       " -0.04186646267771721,\n",
       " -0.04186646267771721,\n",
       " -0.04186628386378288,\n",
       " -0.0418664887547493,\n",
       " -0.04186646267771721,\n",
       " -0.04186646267771721,\n",
       " -0.041865311563014984,\n",
       " -0.04186646267771721,\n",
       " -0.04186628386378288,\n",
       " -0.04186646267771721,\n",
       " -0.04186714068055153,\n",
       " -0.041867274791002274,\n",
       " -0.04186646267771721,\n",
       " -0.04186646267771721,\n",
       " -0.04186646267771721,\n",
       " -0.041863780468702316,\n",
       " -0.04186646267771721,\n",
       " -0.04186646267771721,\n",
       " -0.04186646267771721,\n",
       " -0.04186646267771721,\n",
       " -0.041866883635520935,\n",
       " -0.041863296180963516,\n",
       " -0.04186646267771721,\n",
       " -0.04186663031578064,\n",
       " -0.04186679795384407,\n",
       " -0.04186646267771721,\n",
       " -0.041864506900310516,\n",
       " -0.04186568036675453,\n",
       " -0.04186646267771721,\n",
       " -0.0418662428855896,\n",
       " -0.041866570711135864,\n",
       " -0.04186646267771721,\n",
       " -0.04186650365591049,\n",
       " -0.04186708852648735,\n",
       " -0.04186699539422989,\n",
       " -0.04186655208468437,\n",
       " -0.04186646267771721,\n",
       " -0.04186646267771721,\n",
       " -0.04186392202973366,\n",
       " -0.041864681988954544,\n",
       " -0.041865792125463486,\n",
       " -0.04186646267771721,\n",
       " -0.04186646267771721,\n",
       " -0.04186759144067764,\n",
       " -0.041866641491651535,\n",
       " -0.04186646267771721,\n",
       " -0.041866619139909744,\n",
       " -0.041857969015836716,\n",
       " -0.04186646267771721,\n",
       " -0.04186646267771721,\n",
       " -0.04186646267771721,\n",
       " -0.041866645216941833,\n",
       " -0.04186646267771721,\n",
       " -0.04186689108610153,\n",
       " -0.04186416417360306,\n",
       " -0.041866350919008255,\n",
       " -0.041862957179546356,\n",
       " -0.04186652973294258,\n",
       " -0.041865259408950806,\n",
       " -0.041862938553094864,\n",
       " -0.04186538979411125,\n",
       " -0.04186660051345825,\n",
       " -0.04186646267771721,\n",
       " -0.041866201907396317,\n",
       " -0.04186646267771721,\n",
       " -0.04186753183603287,\n",
       " -0.0418667308986187,\n",
       " -0.04186667501926422,\n",
       " -0.041865214705467224,\n",
       " -0.04186646267771721,\n",
       " -0.04186646267771721,\n",
       " -0.04186646267771721,\n",
       " -0.04186646267771721,\n",
       " -0.04186666011810303,\n",
       " -0.041866693645715714,\n",
       " -0.04186646267771721,\n",
       " -0.04186646267771721,\n",
       " -0.04186192527413368,\n",
       " -0.0418664887547493,\n",
       " -0.04186592623591423,\n",
       " -0.04186704754829407,\n",
       " -0.04186691343784332,\n",
       " -0.04186646267771721,\n",
       " -0.041866734623909,\n",
       " -0.041865766048431396,\n",
       " -0.04186646267771721,\n",
       " -0.04186646267771721,\n",
       " -0.04186646267771721,\n",
       " -0.041866470128297806,\n",
       " -0.04186646267771721,\n",
       " -0.041867662221193314,\n",
       " -0.04186646267771721,\n",
       " -0.04186641797423363,\n",
       " -0.04186643660068512,\n",
       " -0.04186689481139183,\n",
       " -0.04186685010790825,\n",
       " -0.04186646267771721,\n",
       " -0.04186646267771721,\n",
       " -0.04186704009771347,\n",
       " -0.04186663776636124,\n",
       " -0.04186525195837021,\n",
       " -0.04186694696545601,\n",
       " -0.04186684265732765,\n",
       " -0.04186639189720154,\n",
       " -0.04186646267771721,\n",
       " -0.041864387691020966,\n",
       " -0.04186665639281273,\n",
       " -0.041866485029459,\n",
       " -0.04186646267771721,\n",
       " -0.04186646267771721,\n",
       " -0.04186532273888588,\n",
       " -0.04186646267771721,\n",
       " -0.041867293417453766,\n",
       " -0.04186646267771721,\n",
       " -0.04186646267771721,\n",
       " -0.041866060346364975,\n",
       " -0.04186646267771721,\n",
       " -0.04186646267771721,\n",
       " -0.04186646267771721,\n",
       " -0.04186658561229706,\n",
       " -0.04186360910534859,\n",
       " -0.04186590388417244,\n",
       " -0.04186646267771721,\n",
       " -0.041866499930620193,\n",
       " -0.041866764426231384,\n",
       " -0.04186646267771721,\n",
       " -0.041863828897476196,\n",
       " -0.04186675325036049,\n",
       " -0.04186646267771721,\n",
       " -0.04186646267771721,\n",
       " -0.04186646267771721,\n",
       " -0.04186641424894333,\n",
       " -0.04186646267771721,\n",
       " -0.04186674952507019,\n",
       " -0.04186646267771721,\n",
       " -0.04186660051345825,\n",
       " -0.04186687245965004,\n",
       " -0.04186646267771721,\n",
       " -0.041861701756715775,\n",
       " -0.04186646267771721,\n",
       " -0.04186650365591049,\n",
       " -0.04186646267771721,\n",
       " -0.04186427220702171,\n",
       " -0.04186646267771721,\n",
       " -0.04186687618494034,\n",
       " -0.04186646267771721,\n",
       " -0.04186646267771721,\n",
       " -0.04186646267771721,\n",
       " -0.04186646267771721,\n",
       " -0.04186646267771721,\n",
       " -0.04186519980430603,\n",
       " -0.04186646267771721,\n",
       " -0.04186633974313736,\n",
       " -0.04186646267771721,\n",
       " -0.04186100885272026,\n",
       " -0.04186665639281273,\n",
       " -0.04186646267771721,\n",
       " -0.0418664775788784,\n",
       " -0.04186646267771721,\n",
       " -0.04186736047267914,\n",
       " -0.04186646267771721,\n",
       " -0.04186646267771721,\n",
       " -0.04186645522713661,\n",
       " -0.04186667129397392,\n",
       " -0.041865769773721695,\n",
       " -0.041866470128297806,\n",
       " -0.041867416352033615,\n",
       " -0.04186646267771721,\n",
       " -0.04186646267771721,\n",
       " -0.04186646267771721,\n",
       " -0.04186646267771721,\n",
       " -0.04186663404107094,\n",
       " -0.04186646267771721,\n",
       " -0.04186505079269409,\n",
       " -0.04186646267771721,\n",
       " -0.04186646267771721,\n",
       " -0.04186646267771721,\n",
       " -0.04186645895242691,\n",
       " -0.041866470128297806,\n",
       " -0.04186650365591049,\n",
       " -0.04186646267771721,\n",
       " -0.04186630994081497,\n",
       " -0.04186646267771721,\n",
       " -0.0418655090034008,\n",
       " -0.04186646267771721,\n",
       " -0.04186646267771721,\n",
       " -0.041866131126880646,\n",
       " -0.04186474531888962,\n",
       " -0.04186646267771721,\n",
       " -0.04186646267771721,\n",
       " -0.04186667501926422,\n",
       " -0.041866641491651535,\n",
       " -0.04186646267771721,\n",
       " -0.041866485029459,\n",
       " -0.04186646267771721,\n",
       " -0.04186646267771721,\n",
       " -0.04186730831861496,\n",
       " -0.04186590388417244,\n",
       " -0.041866485029459,\n",
       " -0.04186660423874855,\n",
       " -0.041866742074489594,\n",
       " -0.04186690226197243,\n",
       " -0.04186567664146423,\n",
       " -0.04186646267771721,\n",
       " -0.04186646267771721,\n",
       " -0.04186207801103592,\n",
       " -0.04186505079269409,\n",
       " -0.04186646267771721,\n",
       " -0.04186646267771721,\n",
       " -0.041866205632686615,\n",
       " -0.04186646267771721,\n",
       " -0.04186646267771721,\n",
       " -0.04186646267771721,\n",
       " -0.04186646267771721,\n",
       " -0.041866566985845566,\n",
       " -0.04186560586094856,\n",
       " -0.041866131126880646,\n",
       " -0.04186653718352318,\n",
       " -0.04186646267771721,\n",
       " -0.041867949068546295,\n",
       " -0.04186646267771721,\n",
       " -0.04186646267771721,\n",
       " -0.041867081075906754,\n",
       " -0.04186646267771721,\n",
       " -0.04186631739139557,\n",
       " -0.04186646267771721,\n",
       " -0.041863445192575455,\n",
       " -0.041866663843393326,\n",
       " -0.04186651110649109,\n",
       " -0.04186658188700676,\n",
       " -0.04186588525772095,\n",
       " -0.04186597093939781,\n",
       " -0.04186619073152542,\n",
       " -0.04186646267771721,\n",
       " -0.0418664924800396,\n",
       " -0.041867077350616455,\n",
       " -0.04186646267771721,\n",
       " -0.04186646267771721,\n",
       " -0.041866619139909744,\n",
       " -0.041866399347782135,\n",
       " -0.04186643660068512,\n",
       " -0.04186665639281273,\n",
       " -0.04186646267771721,\n",
       " -0.04186646267771721,\n",
       " -0.04186646267771721,\n",
       " -0.04186646267771721,\n",
       " -0.041867177933454514,\n",
       " -0.04186646267771721,\n",
       " -0.04186646267771721,\n",
       " -0.04186725988984108,\n",
       " -0.04186646267771721,\n",
       " -0.04186646267771721,\n",
       " -0.04186667874455452,\n",
       " -0.04186646267771721,\n",
       " -0.041866399347782135,\n",
       " -0.04186646267771721,\n",
       " -0.04186675697565079,\n",
       " -0.04186646267771721,\n",
       " -0.04186646267771721,\n",
       " -0.04186646267771721,\n",
       " -0.04186625778675079,\n",
       " -0.04186646267771721,\n",
       " -0.04186646267771721,\n",
       " -0.04186646267771721,\n",
       " -0.04186716303229332,\n",
       " -0.04186490923166275,\n",
       " -0.041863854974508286,\n",
       " -0.04186646267771721,\n",
       " -0.041863299906253815,\n",
       " -0.04186681658029556,\n",
       " -0.041864898055791855,\n",
       " -0.04186646267771721,\n",
       " -0.041863128542900085,\n",
       " -0.04186646267771721,\n",
       " -0.0418672077357769,\n",
       " -0.04186646267771721,\n",
       " -0.04186646267771721,\n",
       " -0.04186646267771721,\n",
       " -0.04186646267771721,\n",
       " -0.041866932064294815,\n",
       " -0.04186529666185379,\n",
       " -0.04186682775616646,\n",
       " -0.04186641052365303,\n",
       " -0.04186646267771721,\n",
       " -0.0418664924800396,\n",
       " -0.04186275228857994,\n",
       " -0.04186674579977989,\n",
       " -0.04186646267771721,\n",
       " -0.041866485029459,\n",
       " -0.041862986981868744,\n",
       " -0.04186646267771721,\n",
       " -0.041875842958688736,\n",
       " -0.041866596788167953,\n",
       " -0.04186646267771721,\n",
       " -0.04186646267771721,\n",
       " -0.04186646267771721,\n",
       " -0.04186646267771721,\n",
       " -0.04186646267771721,\n",
       " -0.04186730086803436,\n",
       " -0.04186714440584183,\n",
       " -0.04186646267771721,\n",
       " -0.04186646267771721,\n",
       " -0.0418664887547493,\n",
       " -0.04186646267771721,\n",
       " -0.04186682030558586,\n",
       " -0.04186646267771721,\n",
       " -0.0418669767677784,\n",
       " -0.041866473853588104,\n",
       " -0.04186635836958885,\n",
       " -0.04186750203371048,\n",
       " -0.041866522282361984,\n",
       " -0.04186643287539482,\n",
       " -0.041866619139909744,\n",
       " -0.04186646267771721,\n",
       " -0.04186646267771721,\n",
       " -0.04186708480119705,\n",
       " -0.04186650365591049,\n",
       " -0.04186646267771721,\n",
       " -0.04186218976974487,\n",
       " -0.04186646267771721,\n",
       " -0.041866447776556015,\n",
       " -0.04185747727751732,\n",
       " -0.04186646267771721,\n",
       " -0.041867680847644806,\n",
       " -0.04186670854687691,\n",
       " -0.04186570644378662,\n",
       " -0.04186694324016571,\n",
       " -0.041865959763526917,\n",
       " -0.04186646267771721,\n",
       " -0.041866619139909744,\n",
       " -0.04186621680855751,\n",
       " -0.04186646267771721,\n",
       " -0.04186646267771721,\n",
       " -0.04186646267771721,\n",
       " -0.04186646267771721,\n",
       " -0.04186683148145676,\n",
       " -0.04186646267771721,\n",
       " -0.04186646267771721,\n",
       " -0.04186635464429855,\n",
       " -0.041866544634103775,\n",
       " -0.04186646267771721,\n",
       " -0.04186646267771721,\n",
       " -0.04186646267771721,\n",
       " -0.041865427047014236,\n",
       " -0.04186646267771721,\n",
       " -0.041866496205329895,\n",
       " -0.04186462610960007,\n",
       " -0.04186646267771721,\n",
       " -0.04186646267771721,\n",
       " -0.041865624487400055,\n",
       " -0.041866328567266464,\n",
       " -0.04186294972896576,\n",
       " -0.041866485029459,\n",
       " -0.04186694696545601,\n",
       " -0.04186646267771721,\n",
       " -0.041865985840559006,\n",
       " -0.04186646267771721,\n",
       " -0.041866909712553024,\n",
       " -0.04186290130019188,\n",
       " -0.04185810312628746,\n",
       " -0.04186646267771721,\n",
       " -0.04186646267771721,\n",
       " -0.04186481609940529,\n",
       " -0.04186652973294258,\n",
       " -0.04186646267771721,\n",
       " -0.04186738654971123,\n",
       " -0.04186646267771721,\n",
       " -0.04186706244945526,\n",
       " -0.04186658561229706,\n",
       " -0.04186646267771721,\n",
       " -0.041867222636938095,\n",
       " -0.04186646640300751,\n",
       " -0.04186646267771721,\n",
       " -0.04186646267771721,\n",
       " -0.04186646267771721,\n",
       " -0.04186646267771721,\n",
       " -0.04186676815152168,\n",
       " -0.04186646267771721,\n",
       " -0.0418645478785038,\n",
       " -0.04186646267771721,\n",
       " -0.04186577349901199,\n",
       " -0.04186646267771721,\n",
       " -0.041867710649967194,\n",
       " -0.04186646267771721,\n",
       " -0.04186646267771721,\n",
       " -0.04186646267771721,\n",
       " -0.04186646267771721,\n",
       " -0.04186646267771721,\n",
       " -0.04186644032597542,\n",
       " -0.04186646267771721,\n",
       " -0.0418659932911396,\n",
       " -0.041867662221193314,\n",
       " -0.04186646267771721,\n",
       " -0.04186660423874855,\n",
       " -0.04186646267771721,\n",
       " -0.04186646267771721,\n",
       " -0.04186646267771721,\n",
       " -0.04186646267771721,\n",
       " -0.041869815438985825,\n",
       " -0.04186571016907692,\n",
       " -0.04186646267771721,\n",
       " -0.04186646267771721,\n",
       " -0.04186646267771721,\n",
       " -0.04186646267771721,\n",
       " -0.04186657443642616,\n",
       " -0.041866485029459,\n",
       " -0.04186651483178139,\n",
       " -0.0418664924800396,\n",
       " -0.04186646267771721,\n",
       " -0.04186646267771721,\n",
       " -0.04186652600765228,\n",
       " -0.0418621189892292,\n",
       " -0.04186646267771721,\n",
       " -0.04186653345823288,\n",
       " -0.04186646267771721,\n",
       " -0.04186646267771721,\n",
       " -0.041866485029459,\n",
       " -0.04186646267771721,\n",
       " -0.041866473853588104,\n",
       " -0.04186646267771721,\n",
       " -0.041865430772304535,\n",
       " -0.04186646267771721,\n",
       " -0.04186243936419487,\n",
       " -0.041866760700941086,\n",
       " -0.04186646267771721,\n",
       " -0.04186646267771721,\n",
       " -0.04186641052365303,\n",
       " -0.04186632111668587,\n",
       " -0.04186750203371048,\n",
       " -0.04186646267771721,\n",
       " -0.04186646267771721,\n",
       " -0.041864026337862015,\n",
       " -0.04186668246984482,\n",
       " -0.04186646267771721,\n",
       " -0.04186646267771721,\n",
       " -0.04186646267771721,\n",
       " -0.04186568036675453,\n",
       " -0.04186646267771721,\n",
       " -0.041866350919008255,\n",
       " -0.04186667129397392,\n",
       " -0.04186646267771721,\n",
       " -0.04186646267771721,\n",
       " -0.04186651483178139,\n",
       " -0.04186578094959259,\n",
       " -0.04186549410223961,\n",
       " -0.04186093062162399,\n",
       " -0.04186682775616646,\n",
       " -0.04186804220080376,\n",
       " -0.04186640679836273,\n",
       " -0.04186660051345825,\n",
       " -0.041866399347782135,\n",
       " -0.041866615414619446,\n",
       " -0.04186646267771721,\n",
       " -0.04186646267771721,\n",
       " -0.04186646267771721,\n",
       " -0.04186658933758736,\n",
       " -0.04186646267771721,\n",
       " -0.04186646267771721,\n",
       " -0.041865456849336624,\n",
       " -0.04186646267771721,\n",
       " -0.04186646267771721,\n",
       " -0.04186674952507019,\n",
       " -0.041866615414619446,\n",
       " -0.04186646267771721,\n",
       " -0.04186646267771721,\n",
       " -0.04186646267771721,\n",
       " -0.04186675697565079,\n",
       " -0.04186644405126572,\n",
       " -0.0418669730424881,\n",
       " -0.04186520352959633,\n",
       " -0.04186391457915306,\n",
       " -0.0418672077357769,\n",
       " -0.04186677560210228,\n",
       " -0.04186646267771721,\n",
       " -0.04186646267771721,\n",
       " -0.04186694696545601,\n",
       " -0.041867561638355255,\n",
       " -0.04186646267771721,\n",
       " -0.041867341846227646,\n",
       " -0.04186646267771721,\n",
       " -0.041866421699523926,\n",
       " -0.04186646267771721,\n",
       " -0.041866082698106766,\n",
       " -0.041864097118377686,\n",
       " -0.041867151856422424,\n",
       " -0.04186646267771721,\n",
       " -0.04186646267771721,\n",
       " -0.04186646267771721,\n",
       " -0.041866544634103775,\n",
       " -0.041867006570100784,\n",
       " -0.04186663031578064,\n",
       " -0.0418664887547493,\n",
       " -0.04186646267771721,\n",
       " -0.041867226362228394,\n",
       " -0.041866470128297806,\n",
       " -0.041865140199661255,\n",
       " -0.04186646267771721,\n",
       " -0.04186646267771721,\n",
       " -0.04186646267771721,\n",
       " -0.04186638072133064,\n",
       " -0.04186646267771721,\n",
       " -0.04186687245965004,\n",
       " -0.04186646267771721,\n",
       " -0.04186723753809929,\n",
       " -0.04186646267771721,\n",
       " -0.04186573252081871,\n",
       " -0.041866663843393326,\n",
       " -0.04186646267771721,\n",
       " -0.04186398908495903,\n",
       " -0.041866518557071686,\n",
       " -0.04186631739139557,\n",
       " -0.041866276413202286,\n",
       " -0.041866619139909744,\n",
       " -0.04186646267771721,\n",
       " -0.04186678305268288,\n",
       " -0.04186646267771721,\n",
       " -0.04186646267771721,\n",
       " -0.04186646267771721,\n",
       " -0.04186646267771721,\n",
       " -0.04186646267771721,\n",
       " -0.04186656326055527,\n",
       " -0.04186646267771721,\n",
       " -0.04186646267771721,\n",
       " -0.04186646267771721,\n",
       " -0.04186639562249184,\n",
       " -0.04186616092920303,\n",
       " -0.04186645522713661,\n",
       " -0.04186639562249184,\n",
       " -0.041866518557071686,\n",
       " -0.041866566985845566,\n",
       " -0.04186646267771721,\n",
       " -0.04186646267771721,\n",
       " -0.0418664813041687,\n",
       " -0.041863925755023956,\n",
       " -0.04186646267771721,\n",
       " -0.04186646267771721,\n",
       " -0.041866470128297806,\n",
       " -0.04186646267771721,\n",
       " -0.04186646267771721,\n",
       " -0.041864484548568726,\n",
       " -0.04186646267771721,\n",
       " -0.04186646267771721,\n",
       " -0.04186706990003586,\n",
       " -0.041866909712553024,\n",
       " -0.04186639562249184,\n",
       " -0.04186646267771721,\n",
       " -0.04186646267771721,\n",
       " -0.04186532646417618,\n",
       " -0.04186539351940155,\n",
       " -0.04186646267771721,\n",
       " -0.04186646267771721,\n",
       " -0.04186646267771721,\n",
       " -0.04186646267771721,\n",
       " -0.0418519489467144,\n",
       " -0.04186646267771721,\n",
       " -0.04186646267771721,\n",
       " -0.04186642915010452,\n",
       " -0.041866473853588104,\n",
       " -0.04186639189720154,\n",
       " -0.04186646267771721,\n",
       " -0.04186646267771721,\n",
       " -0.041866593062877655,\n",
       " -0.04186646267771721,\n",
       " -0.041866861283779144,\n",
       " -0.04186634719371796,\n",
       " -0.04186646267771721,\n",
       " -0.0418669693171978,\n",
       " -0.04186646267771721,\n",
       " -0.04186646267771721,\n",
       " -0.04186646267771721,\n",
       " -0.04186678305268288,\n",
       " -0.0418664775788784,\n",
       " -0.0418664775788784,\n",
       " -0.04186646267771721,\n",
       " -0.04186646267771721,\n",
       " -0.04186646267771721,\n",
       " -0.04186651483178139,\n",
       " -0.04186646267771721,\n",
       " -0.04186750575900078,\n",
       " -0.04186653718352318,\n",
       " -0.04186701402068138,\n",
       " -0.041864778846502304,\n",
       " -0.04186646267771721,\n",
       " -0.04186643660068512,\n",
       " -0.04186646267771721,\n",
       " -0.04186629131436348,\n",
       " -0.04186646267771721,\n",
       " -0.04186646267771721,\n",
       " -0.04186646267771721,\n",
       " -0.041862111538648605,\n",
       " -0.041866835206747055,\n",
       " -0.04186646267771721,\n",
       " -0.041866522282361984,\n",
       " -0.04186620935797691,\n",
       " -0.04186638444662094,\n",
       " -0.04186646267771721,\n",
       " -0.04186646267771721,\n",
       " -0.04186646267771721,\n",
       " -0.04186411201953888,\n",
       " -0.04186635836958885,\n",
       " -0.04186646267771721,\n",
       " -0.04186595603823662,\n",
       " -0.04186231642961502,\n",
       " -0.04186505824327469,\n",
       " -0.04186646267771721,\n",
       " -0.04186669737100601,\n",
       " -0.04186646267771721,\n",
       " -0.041866593062877655,\n",
       " -0.0418667271733284,\n",
       " -0.041866447776556015,\n",
       " -0.041867759078741074,\n",
       " -0.04186646267771721,\n",
       " -0.04186646267771721,\n",
       " -0.04186646267771721,\n",
       " -0.041866838932037354,\n",
       " -0.04186646267771721,\n",
       " -0.04186644032597542,\n",
       " -0.04186646267771721,\n",
       " -0.04186655580997467,\n",
       " -0.041859716176986694,\n",
       " -0.04186675697565079,\n",
       " -0.04186640679836273,\n",
       " -0.041866205632686615,\n",
       " -0.04186646267771721,\n",
       " -0.04186643287539482,\n",
       " -0.04186646267771721,\n",
       " -0.04186646267771721,\n",
       " -0.04186549410223961,\n",
       " -0.04186646267771721,\n",
       " -0.04186646267771721,\n",
       " -0.041866403073072433,\n",
       " -0.04186752438545227,\n",
       " -0.04186646267771721,\n",
       " -0.0418667234480381,\n",
       " -0.04186646267771721,\n",
       " -0.04186650365591049,\n",
       " -0.04186646267771721,\n",
       " -0.04186646267771721,\n",
       " -0.04186646267771721,\n",
       " -0.04186706617474556,\n",
       " -0.04186646267771721,\n",
       " -0.04186646267771721,\n",
       " -0.04186663031578064,\n",
       " -0.04186646267771721,\n",
       " -0.04186646267771721,\n",
       " -0.04186646267771721,\n",
       " -0.04186646267771721,\n",
       " -0.04186663404107094,\n",
       " -0.04186646267771721,\n",
       " -0.041866485029459,\n",
       " -0.04186646267771721,\n",
       " -0.04186662286520004,\n",
       " -0.04186646267771721,\n",
       " -0.04186650365591049,\n",
       " -0.04186646267771721,\n",
       " -0.041863273829221725,\n",
       " -0.04186646267771721,\n",
       " -0.04186646267771721,\n",
       " -0.04186646267771721,\n",
       " -0.04186294227838516,\n",
       " -0.04186662659049034,\n",
       " -0.04186687618494034,\n",
       " -0.04186645895242691,\n",
       " -0.04186646267771721,\n",
       " -0.04186646267771721,\n",
       " -0.04186646267771721,\n",
       " -0.04186728969216347,\n",
       " -0.04186646267771721,\n",
       " -0.04186646267771721,\n",
       " -0.04186646267771721,\n",
       " -0.041867174208164215,\n",
       " -0.0418672151863575,\n",
       " -0.04186641052365303,\n",
       " -0.04186646267771721,\n",
       " -0.04186646267771721,\n",
       " -0.04186646267771721,\n",
       " -0.04186654090881348,\n",
       " -0.041866499930620193,\n",
       " -0.041866324841976166,\n",
       " -0.04186646267771721,\n",
       " -0.04186646267771721,\n",
       " -0.04186660423874855,\n",
       " -0.041866641491651535,\n",
       " -0.04186646267771721,\n",
       " -0.04186685383319855,\n",
       " -0.04186779633164406,\n",
       " -0.04186646267771721,\n",
       " -0.04186641424894333,\n",
       " -0.04186646267771721,\n",
       " -0.04186619073152542,\n",
       " -0.04186646267771721,\n",
       " -0.04186646267771721,\n",
       " -0.0418667234480381,\n",
       " -0.041866742074489594,\n",
       " -0.04186646267771721,\n",
       " -0.04186646267771721,\n",
       " -0.04186646267771721,\n",
       " -0.041865117847919464,\n",
       " -0.04186646267771721,\n",
       " -0.04186646267771721,\n",
       " -0.04186646267771721,\n",
       " -0.041866425424814224,\n",
       " -0.04186646267771721,\n",
       " -0.04186646267771721,\n",
       " -0.041867997497320175,\n",
       " -0.04186646267771721,\n",
       " -0.04186636582016945,\n",
       " -0.04186646267771721,\n",
       " -0.04186646267771721,\n",
       " -0.04186616465449333,\n",
       " -0.04186646267771721,\n",
       " -0.04186646267771721,\n",
       " -0.041860442608594894,\n",
       " -0.04186369851231575,\n",
       " -0.04186657443642616,\n",
       " -0.04186634346842766,\n",
       " -0.04186646267771721,\n",
       " -0.04186739772558212,\n",
       " -0.041866667568683624,\n",
       " -0.04186646267771721,\n",
       " -0.04186646267771721,\n",
       " -0.04186663404107094,\n",
       " -0.04186690226197243,\n",
       " -0.04186232015490532,\n",
       " -0.04186646267771721,\n",
       " -0.04186646267771721,\n",
       " -0.041866425424814224,\n",
       " -0.04186714440584183,\n",
       " -0.04186646267771721,\n",
       " -0.04186646267771721,\n",
       " -0.04186678305268288,\n",
       " -0.04186560958623886,\n",
       " -0.04186639562249184,\n",
       " -0.04186646267771721,\n",
       " -0.04186646267771721,\n",
       " -0.04186680167913437,\n",
       " -0.04186677560210228,\n",
       " -0.04186646267771721,\n",
       " -0.04186646267771721,\n",
       " -0.04186646267771721,\n",
       " -0.04186646267771721,\n",
       " -0.04186646267771721,\n",
       " -0.04186646267771721,\n",
       " -0.041866838932037354,\n",
       " -0.04186660423874855,\n",
       " -0.04186641424894333,\n",
       " -0.04186534136533737,\n",
       " -0.04186275973916054,\n",
       " -0.04186618700623512,\n",
       " -0.041866485029459,\n",
       " -0.04186676815152168,\n",
       " -0.0418664813041687,\n",
       " -0.04186646267771721,\n",
       " -0.04186646267771721,\n",
       " -0.04186646267771721,\n",
       " -0.041866499930620193,\n",
       " -0.04186644405126572,\n",
       " -0.04186646267771721,\n",
       " -0.04186646267771721,\n",
       " -0.04186646267771721,\n",
       " -0.04186646267771721,\n",
       " -0.04186646267771721,\n",
       " -0.04186571389436722,\n",
       " -0.04186646267771721,\n",
       " -0.04186653345823288,\n",
       " -0.04186646267771721,\n",
       " -0.04186646267771721,\n",
       " -0.04186646267771721,\n",
       " -0.04186646267771721,\n",
       " -0.04186498746275902,\n",
       " -0.04186651110649109,\n",
       " -0.04186646267771721,\n",
       " -0.04186646267771721,\n",
       " -0.041862647980451584,\n",
       " -0.04186639189720154,\n",
       " -0.04186563566327095,\n",
       " -0.04186646267771721,\n",
       " -0.04186686500906944,\n",
       " -0.04186646267771721,\n",
       " -0.04186646267771721,\n",
       " -0.04186646267771721,\n",
       " -0.04186646267771721,\n",
       " -0.04186646267771721,\n",
       " -0.04186677187681198,\n",
       " -0.04186585918068886,\n",
       " -0.04186645895242691,\n",
       " -0.041866447776556015,\n",
       " -0.04186646267771721,\n",
       " -0.04186646267771721,\n",
       " -0.04186646267771721,\n",
       " -0.04186466336250305,\n",
       " -0.04186674579977989,\n",
       " -0.04186757281422615,\n",
       " -0.041867077350616455,\n",
       " -0.04186646267771721,\n",
       " -0.04186466708779335,\n",
       " -0.04186641797423363,\n",
       " -0.04186646267771721,\n",
       " -0.04186646267771721,\n",
       " -0.04186646267771721,\n",
       " -0.04186646267771721,\n",
       " -0.04186646267771721,\n",
       " -0.041865091770887375,\n",
       " -0.04186646267771721,\n",
       " -0.04186646267771721,\n",
       " -0.04186687245965004,\n",
       " -0.04186646267771721,\n",
       " -0.04186646267771721,\n",
       " -0.04186646267771721,\n",
       " -0.041866954416036606,\n",
       " -0.041866451501846313,\n",
       " -0.04186054691672325,\n",
       " -0.041866485029459,\n",
       " -0.04186646267771721,\n",
       " -0.04186646267771721,\n",
       " -0.04186315834522247,\n",
       " -0.04186158627271652,\n",
       " -0.041864678263664246,\n",
       " -0.04186646267771721,\n",
       " -0.04186646267771721,\n",
       " -0.04186646267771721,\n",
       " -0.04186646267771721,\n",
       " -0.04186633601784706,\n",
       " -0.04186750203371048,\n",
       " -0.04186753183603287,\n",
       " -0.04186646267771721,\n",
       " -0.04186679422855377,\n",
       " -0.04186646267771721,\n",
       " -0.04186646267771721,\n",
       " -0.04186456650495529,\n",
       " -0.04186646267771721,\n",
       " -0.04186646267771721,\n",
       " ...]"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sum(sum(preds, []), [])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6980eec7",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "0b282768",
   "metadata": {},
   "source": [
    "## Siamese Embeddings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "ab4ab4cc",
   "metadata": {},
   "outputs": [],
   "source": [
    "class MuRILemb(nn.Module):\n",
    "\n",
    "    def __init__(self, dropout=0.2):\n",
    "\n",
    "        super(MuRILemb, self).__init__()\n",
    "\n",
    "        self.bert = AutoModelForMaskedLM.from_pretrained('google/muril-base-cased')\n",
    "        self.dropout = nn.Dropout(dropout)\n",
    "        self.l1 = nn.Linear(768, 200)\n",
    "        self.relu = nn.ReLU()\n",
    "        \n",
    "        modules = [self.bert.bert.embeddings, *self.bert.bert.encoder.layer[:-3]]  # freeze all but last few\n",
    "        for module in modules:\n",
    "            for param in module.parameters():\n",
    "                param.requires_grad = False\n",
    "\n",
    "    def forward(self, input_id, mask):\n",
    "\n",
    "        b = self.bert(input_ids= input_id, attention_mask=mask, output_hidden_states=True)\n",
    "        x = b.hidden_states[-1][:, 0]  # this is what the bertpooler implementation does\n",
    "        x = self.dropout(x)\n",
    "        x = self.l1(x)\n",
    "\n",
    "        return x\n",
    "\n",
    "\n",
    "class SiameseModel(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(SiameseModel, self).__init__()\n",
    "        \n",
    "        self.embedder = MuRILemb()\n",
    "        self.cos = nn.CosineSimilarity()\n",
    "    \n",
    "    def forward(self, inputs1, inputs2):\n",
    "        # each input is (input_id, mask)\n",
    "        emb1 = self.embedder(inputs1[0], inputs1[1])\n",
    "        emb2 = self.embedder(inputs2[0], inputs2[1])\n",
    "        sim = self.cos(emb1, emb2)\n",
    "        return sim\n",
    "    \n",
    "    def get_emb(self, input_id, mask):\n",
    "        x = self.embedder(input_id, mask)\n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "790e2c14",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>clean_title</th>\n",
       "      <th>clean_comment</th>\n",
       "      <th>url</th>\n",
       "      <th>avg_score</th>\n",
       "      <th>target</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Shashi Tharoor Set To Run For Congress Preside...</td>\n",
       "      <td>Extremely valid points but I believe he has th...</td>\n",
       "      <td>/r/india/comments/xif8wm/shashi_tharoor_set_to...</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-0.50</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Yogi government puts Kolkata's image as part o...</td>\n",
       "      <td>Even if the ad was designed by the newspaper t...</td>\n",
       "      <td>/r/india/comments/pmn9o3/yogi_government_puts_...</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-0.50</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>An attempt to address the list of \"simplified\"...</td>\n",
       "      <td>Diverse population including Muslims. Welcomin...</td>\n",
       "      <td>/r/india/comments/ebdeup/an_attempt_to_address...</td>\n",
       "      <td>-1.5</td>\n",
       "      <td>-0.75</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>You guys noticing what's happening in Sri Lanka?</td>\n",
       "      <td>What a joke. They didn't create any propaganda...</td>\n",
       "      <td>/r/india/comments/tt1ryh/you_guys_noticing_wha...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Just got abused on the train by a hyper nation...</td>\n",
       "      <td>Ohoo bahut bura laga ye sunke ki aap Undergarm...</td>\n",
       "      <td>/r/india/comments/rh2kcs/just_got_abused_on_th...</td>\n",
       "      <td>-2.0</td>\n",
       "      <td>-1.00</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                         clean_title  \\\n",
       "0  Shashi Tharoor Set To Run For Congress Preside...   \n",
       "1  Yogi government puts Kolkata's image as part o...   \n",
       "2  An attempt to address the list of \"simplified\"...   \n",
       "3   You guys noticing what's happening in Sri Lanka?   \n",
       "4  Just got abused on the train by a hyper nation...   \n",
       "\n",
       "                                       clean_comment  \\\n",
       "0  Extremely valid points but I believe he has th...   \n",
       "1  Even if the ad was designed by the newspaper t...   \n",
       "2  Diverse population including Muslims. Welcomin...   \n",
       "3  What a joke. They didn't create any propaganda...   \n",
       "4  Ohoo bahut bura laga ye sunke ki aap Undergarm...   \n",
       "\n",
       "                                                 url  avg_score  target  \n",
       "0  /r/india/comments/xif8wm/shashi_tharoor_set_to...       -1.0   -0.50  \n",
       "1  /r/india/comments/pmn9o3/yogi_government_puts_...       -1.0   -0.50  \n",
       "2  /r/india/comments/ebdeup/an_attempt_to_address...       -1.5   -0.75  \n",
       "3  /r/india/comments/tt1ryh/you_guys_noticing_wha...        0.0    0.00  \n",
       "4  /r/india/comments/rh2kcs/just_got_abused_on_th...       -2.0   -1.00  "
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "clean_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "05b2c702",
   "metadata": {},
   "outputs": [],
   "source": [
    "def sim_score(s1, s2):\n",
    "    # given 2 scores such that both are [-1, 1] but not 0, we can take \n",
    "    # magnitude as geometric mean of absolute scores, sign from multiplying?\n",
    "    \n",
    "    # rescaling to 0 to 1 range due to cosine similarity\n",
    "    temp = s1*s2/(abs(s1)*abs(s2))**0.5\n",
    "    return (temp+1)/2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "2863404d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(0.14644660940672627, 0.75)"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sim_score(-1, 0.5), sim_score(1, 0.25)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "35b5f43f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>c1</th>\n",
       "      <th>c2</th>\n",
       "      <th>sim</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>I agree that 4th of july and 31st dec are equa...</td>\n",
       "      <td>What's wrong with staying United against China...</td>\n",
       "      <td>0.750000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>I think while Shashi has a lot of sensibilitie...</td>\n",
       "      <td>Sikhi and weapons go hand in hand. I also don'...</td>\n",
       "      <td>0.323223</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>These things happen when the miscreants are ba...</td>\n",
       "      <td>True af. People are sheeps man, shitting what ...</td>\n",
       "      <td>0.625000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>This is messed up, and I m not surprised, but ...</td>\n",
       "      <td>I live in haryana near Punjab border.. nd I ca...</td>\n",
       "      <td>0.716506</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Dude, I tried that with you, with a well reaso...</td>\n",
       "      <td>These kind of posts could never be seen on tha...</td>\n",
       "      <td>0.806186</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>995</th>\n",
       "      <td>I live in haryana near Punjab border.. nd I ca...</td>\n",
       "      <td>Are we going to pretend that women that age ha...</td>\n",
       "      <td>0.676777</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>996</th>\n",
       "      <td>Dude the right to peacefully protest against t...</td>\n",
       "      <td>Mujhe to bahut gussa aata h bahut si cheezo ko...</td>\n",
       "      <td>0.146447</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>997</th>\n",
       "      <td>Nahi bhai pappu aur jyada confuse kar dega... ...</td>\n",
       "      <td>They want to irritate their lives so that they...</td>\n",
       "      <td>0.193814</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>998</th>\n",
       "      <td>India overwhelmingly supports CAA... We have g...</td>\n",
       "      <td>Never forget the sacrifice of great Tukaram Om...</td>\n",
       "      <td>0.750000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>999</th>\n",
       "      <td>braindead comments here. \"it's people's choice...</td>\n",
       "      <td>Good job at making a manipulative title Well w...</td>\n",
       "      <td>0.806186</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>1000 rows × 3 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                    c1  \\\n",
       "0    I agree that 4th of july and 31st dec are equa...   \n",
       "1    I think while Shashi has a lot of sensibilitie...   \n",
       "2    These things happen when the miscreants are ba...   \n",
       "3    This is messed up, and I m not surprised, but ...   \n",
       "4    Dude, I tried that with you, with a well reaso...   \n",
       "..                                                 ...   \n",
       "995  I live in haryana near Punjab border.. nd I ca...   \n",
       "996  Dude the right to peacefully protest against t...   \n",
       "997  Nahi bhai pappu aur jyada confuse kar dega... ...   \n",
       "998  India overwhelmingly supports CAA... We have g...   \n",
       "999  braindead comments here. \"it's people's choice...   \n",
       "\n",
       "                                                    c2       sim  \n",
       "0    What's wrong with staying United against China...  0.750000  \n",
       "1    Sikhi and weapons go hand in hand. I also don'...  0.323223  \n",
       "2    True af. People are sheeps man, shitting what ...  0.625000  \n",
       "3    I live in haryana near Punjab border.. nd I ca...  0.716506  \n",
       "4    These kind of posts could never be seen on tha...  0.806186  \n",
       "..                                                 ...       ...  \n",
       "995  Are we going to pretend that women that age ha...  0.676777  \n",
       "996  Mujhe to bahut gussa aata h bahut si cheezo ko...  0.146447  \n",
       "997  They want to irritate their lives so that they...  0.193814  \n",
       "998  Never forget the sacrifice of great Tukaram Om...  0.750000  \n",
       "999  Good job at making a manipulative title Well w...  0.806186  \n",
       "\n",
       "[1000 rows x 3 columns]"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_size = 1000  # size of final dataset wanted\n",
    "temp = clean_df[clean_df['avg_score']!=0].copy()\n",
    "temp = temp[['clean_comment', 'target']].sample(df_size*2, replace=True)\n",
    "d1 = temp[:df_size].copy().to_records()\n",
    "d2 = temp[df_size:].copy().to_records()\n",
    "\n",
    "pair_dict = {'c1':[], 'c2':[], 'sim':[]}\n",
    "for i in range(df_size):\n",
    "    pair_dict['c1'].append(d1[i].clean_comment)\n",
    "    pair_dict['c2'].append(d2[i].clean_comment)\n",
    "    pair_dict['sim'].append(sim_score(d1[i].target, d2[i].target))\n",
    "pair_df = pd.DataFrame.from_dict(pair_dict)\n",
    "pair_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "76425af0",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(array([ 14., 132., 170., 179.,   0.,   0., 167., 187., 127.,  24.]),\n",
       " array([0. , 0.1, 0.2, 0.3, 0.4, 0.5, 0.6, 0.7, 0.8, 0.9, 1. ]),\n",
       " <BarContainer object of 10 artists>)"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.hist(pair_df.sim)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "id": "19665c5f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([ 0.0671, -0.0353,  0.0035,  0.0252,  0.0333])"
      ]
     },
     "execution_count": 63,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cos = nn.CosineSimilarity()\n",
    "cos(torch.randn(5, 128), torch.randn(5, 128))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "078d936d",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "5578d05e",
   "metadata": {},
   "outputs": [],
   "source": [
    "def siamese_train_loop(model, train_df, num_epochs, batch_size, lr=0.001):\n",
    "    model.train()  # set to train mode just in case\n",
    "    criterion = nn.MSELoss().to(device)\n",
    "    optimizer = torch.optim.Adam(model.parameters(), lr=lr)\n",
    "    losses = []\n",
    "    \n",
    "    df = train_df.copy()\n",
    "    for _ in range(num_epochs):\n",
    "        df = df.sample(frac=1).reset_index(drop=True)  # shuffle order\n",
    "        for i in range(int(np.ceil(len(df)/batch_size))):\n",
    "            model.zero_grad()\n",
    "            \n",
    "            # getting inputs\n",
    "            batch = df[i:i+batch_size]\n",
    "            targets = torch.tensor(list(batch['sim'])).to(device)\n",
    "            \n",
    "            temp = tokenizer(list(batch['c1']), padding='max_length', max_length = 512, truncation=True, return_tensors=\"pt\")\n",
    "            inputs1 = temp['input_ids'].to(device), temp['attention_mask'].to(device)\n",
    "            \n",
    "            temp = tokenizer(list(batch['c2']), padding='max_length', max_length = 512, truncation=True, return_tensors=\"pt\")\n",
    "            inputs2 = temp['input_ids'].to(device), temp['attention_mask'].to(device)\n",
    "            \n",
    "            # training model\n",
    "            preds = model(inputs1, inputs2)\n",
    "            batch_loss = criterion(preds, targets)\n",
    "            batch_loss.backward()\n",
    "            optimizer.step()\n",
    "            \n",
    "            losses.append(batch_loss.item())\n",
    "            \n",
    "            # excplicitly delete variables in cuda\n",
    "            del targets, temp, inputs1, inputs2, preds, batch_loss\n",
    "    return model, losses"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "6c514c68",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of the model checkpoint at google/muril-base-cased were not used when initializing BertForMaskedLM: ['cls.seq_relationship.bias', 'cls.seq_relationship.weight']\n",
      "- This IS expected if you are initializing BertForMaskedLM from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing BertForMaskedLM from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n"
     ]
    }
   ],
   "source": [
    "siamese_model = SiameseModel().to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "d5558d56",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "|===========================================================================|\n",
      "|                  PyTorch CUDA memory summary, device ID 0                 |\n",
      "|---------------------------------------------------------------------------|\n",
      "|            CUDA OOMs: 2            |        cudaMalloc retries: 3         |\n",
      "|===========================================================================|\n",
      "|        Metric         | Cur Usage  | Peak Usage | Tot Alloc  | Tot Freed  |\n",
      "|---------------------------------------------------------------------------|\n",
      "| Allocated memory      |    1832 MB |    4311 MB |   64423 GB |   64421 GB |\n",
      "|       from large pool |    1830 MB |    4307 MB |   64403 GB |   64401 GB |\n",
      "|       from small pool |       2 MB |       5 MB |      20 GB |      20 GB |\n",
      "|---------------------------------------------------------------------------|\n",
      "| Active memory         |    1832 MB |    4311 MB |   64423 GB |   64421 GB |\n",
      "|       from large pool |    1830 MB |    4307 MB |   64403 GB |   64401 GB |\n",
      "|       from small pool |       2 MB |       5 MB |      20 GB |      20 GB |\n",
      "|---------------------------------------------------------------------------|\n",
      "| GPU reserved memory   |    3058 MB |    4994 MB |   10686 MB |    7628 MB |\n",
      "|       from large pool |    3054 MB |    4986 MB |   10674 MB |    7620 MB |\n",
      "|       from small pool |       4 MB |       8 MB |      12 MB |       8 MB |\n",
      "|---------------------------------------------------------------------------|\n",
      "| Non-releasable memory |    1225 MB |    2053 MB |   46364 GB |   46362 GB |\n",
      "|       from large pool |    1224 MB |    2052 MB |   46293 GB |   46292 GB |\n",
      "|       from small pool |       1 MB |       3 MB |      70 GB |      70 GB |\n",
      "|---------------------------------------------------------------------------|\n",
      "| Allocations           |     288    |     502    |    5434 K  |    5434 K  |\n",
      "|       from large pool |     121    |     239    |    3787 K  |    3787 K  |\n",
      "|       from small pool |     167    |     285    |    1646 K  |    1646 K  |\n",
      "|---------------------------------------------------------------------------|\n",
      "| Active allocs         |     288    |     502    |    5434 K  |    5434 K  |\n",
      "|       from large pool |     121    |     239    |    3787 K  |    3787 K  |\n",
      "|       from small pool |     167    |     285    |    1646 K  |    1646 K  |\n",
      "|---------------------------------------------------------------------------|\n",
      "| GPU reserved segments |      32    |      59    |      84    |      52    |\n",
      "|       from large pool |      30    |      55    |      78    |      48    |\n",
      "|       from small pool |       2    |       4    |       6    |       4    |\n",
      "|---------------------------------------------------------------------------|\n",
      "| Non-releasable allocs |      40    |      54    |    2771 K  |    2771 K  |\n",
      "|       from large pool |      30    |      42    |    2101 K  |    2101 K  |\n",
      "|       from small pool |      10    |      17    |     670 K  |     670 K  |\n",
      "|---------------------------------------------------------------------------|\n",
      "| Oversize allocations  |       0    |       0    |       0    |       0    |\n",
      "|---------------------------------------------------------------------------|\n",
      "| Oversize GPU segments |       0    |       0    |       0    |       0    |\n",
      "|===========================================================================|\n",
      "\n"
     ]
    }
   ],
   "source": [
    "torch.cuda.empty_cache()\n",
    "print(torch.cuda.memory_summary(device=None, abbreviated=False))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "e9c18f29",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Wall time: 11min 18s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "siamese_model, siamese_losses = siamese_train_loop(siamese_model, pair_df, num_epochs=5, batch_size=4, lr=0.0001)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "649df44f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[<matplotlib.lines.Line2D at 0x1738de7e910>]"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.plot([i*5/len(siamese_losses) for i in range(len(siamese_losses))], siamese_losses)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "78648d63",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.28573366440409925"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.mean(siamese_losses)**0.5  # rmse"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "11bdc98d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1250"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(siamese_losses)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "17c7ceb0",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.7469985474633241"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "1 - np.mean(siamese_losses)/np.mean(pair_df['sim']**2)  # approx r2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "a6bacd12",
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.save(siamese_model, 'models/siamese_model.pkl')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3a78bc3d",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "152c970c",
   "metadata": {},
   "source": [
    "### Classification from Siamese Embeddings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "fef93b47",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>clean_title</th>\n",
       "      <th>clean_comment</th>\n",
       "      <th>url</th>\n",
       "      <th>avg_score</th>\n",
       "      <th>target</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Shashi Tharoor Set To Run For Congress Preside...</td>\n",
       "      <td>Extremely valid points but I believe he has th...</td>\n",
       "      <td>/r/india/comments/xif8wm/shashi_tharoor_set_to...</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-0.50</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Yogi government puts Kolkata's image as part o...</td>\n",
       "      <td>Even if the ad was designed by the newspaper t...</td>\n",
       "      <td>/r/india/comments/pmn9o3/yogi_government_puts_...</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-0.50</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>An attempt to address the list of \"simplified\"...</td>\n",
       "      <td>Diverse population including Muslims. Welcomin...</td>\n",
       "      <td>/r/india/comments/ebdeup/an_attempt_to_address...</td>\n",
       "      <td>-1.5</td>\n",
       "      <td>-0.75</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>You guys noticing what's happening in Sri Lanka?</td>\n",
       "      <td>What a joke. They didn't create any propaganda...</td>\n",
       "      <td>/r/india/comments/tt1ryh/you_guys_noticing_wha...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Just got abused on the train by a hyper nation...</td>\n",
       "      <td>Ohoo bahut bura laga ye sunke ki aap Undergarm...</td>\n",
       "      <td>/r/india/comments/rh2kcs/just_got_abused_on_th...</td>\n",
       "      <td>-2.0</td>\n",
       "      <td>-1.00</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                         clean_title  \\\n",
       "0  Shashi Tharoor Set To Run For Congress Preside...   \n",
       "1  Yogi government puts Kolkata's image as part o...   \n",
       "2  An attempt to address the list of \"simplified\"...   \n",
       "3   You guys noticing what's happening in Sri Lanka?   \n",
       "4  Just got abused on the train by a hyper nation...   \n",
       "\n",
       "                                       clean_comment  \\\n",
       "0  Extremely valid points but I believe he has th...   \n",
       "1  Even if the ad was designed by the newspaper t...   \n",
       "2  Diverse population including Muslims. Welcomin...   \n",
       "3  What a joke. They didn't create any propaganda...   \n",
       "4  Ohoo bahut bura laga ye sunke ki aap Undergarm...   \n",
       "\n",
       "                                                 url  avg_score  target  \n",
       "0  /r/india/comments/xif8wm/shashi_tharoor_set_to...       -1.0   -0.50  \n",
       "1  /r/india/comments/pmn9o3/yogi_government_puts_...       -1.0   -0.50  \n",
       "2  /r/india/comments/ebdeup/an_attempt_to_address...       -1.5   -0.75  \n",
       "3  /r/india/comments/tt1ryh/you_guys_noticing_wha...        0.0    0.00  \n",
       "4  /r/india/comments/rh2kcs/just_got_abused_on_th...       -2.0   -1.00  "
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "clean_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "6234cc3a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[-1.23233171e-02,  9.16410331e-03, -9.98836197e-03,\n",
       "        -1.48510616e-02,  1.20317191e-03, -6.32020063e-04,\n",
       "        -9.51469038e-03,  9.14787501e-03, -7.74967112e-03,\n",
       "        -1.37430802e-02,  9.17028636e-04, -2.52968073e-03,\n",
       "         7.07013765e-03,  1.07331462e-02,  2.67621712e-03,\n",
       "        -1.57944225e-02,  2.25701742e-02, -1.45315379e-03,\n",
       "        -2.47358400e-02, -9.62265860e-03,  1.90248434e-03,\n",
       "         4.56789136e-03,  2.52414495e-03,  4.84470837e-03,\n",
       "         1.08348373e-02,  2.54079700e-04,  1.34881139e-02,\n",
       "         4.00158614e-02, -1.92111265e-02, -1.44691207e-03,\n",
       "         8.91999155e-03, -1.75834209e-01,  6.62859855e-03,\n",
       "        -2.02636719e-02,  2.08885912e-02,  1.42671829e-02,\n",
       "         1.27223181e-02, -6.01575151e-03,  3.97900119e-04,\n",
       "        -2.02394053e-02,  1.55674443e-02,  2.16914862e-02,\n",
       "         1.19702406e-02,  1.00055989e-02, -1.15334447e-02,\n",
       "         7.63931684e-03,  9.46526602e-03, -2.21038051e-03,\n",
       "        -1.73629522e-02,  9.03666485e-03, -1.72467530e-03,\n",
       "        -1.37273790e-02,  1.36339879e-02,  1.74903590e-03,\n",
       "        -3.30096856e-03,  2.63968948e-04, -9.83832404e-03,\n",
       "        -6.73970534e-03, -1.92647893e-03, -7.91969150e-03,\n",
       "        -2.43842974e-03,  3.14188749e-03,  1.57511644e-02,\n",
       "         1.58105008e-02, -2.49497667e-02, -1.10423341e-02,\n",
       "         1.89572442e-02,  5.51794190e-03, -1.79920737e-02,\n",
       "         6.56107441e-04, -1.75212882e-03, -9.56886075e-03,\n",
       "        -3.62563133e-03,  1.41760362e-02, -3.86086851e-03,\n",
       "        -1.09475879e-02,  1.72391515e-02,  7.46222585e-03,\n",
       "        -7.72487558e-03,  9.31136310e-05, -7.54086301e-04,\n",
       "         8.59438255e-03, -6.59167208e-03, -2.19682939e-02,\n",
       "         7.35514611e-03,  3.58924642e-03,  4.63162642e-03,\n",
       "        -1.65484920e-02,  5.25542535e-03, -6.12703152e-03,\n",
       "        -8.38307198e-03, -1.36345439e-03,  6.47708774e-04,\n",
       "         9.67247225e-03,  3.74444202e-03, -7.10286479e-03,\n",
       "        -5.79478499e-03,  2.92297453e-03, -9.92622320e-03,\n",
       "        -8.43160786e-04,  5.17524453e-03,  1.26260296e-02,\n",
       "         1.37282964e-02, -6.74373060e-02,  6.54076785e-03,\n",
       "         1.11683505e-02, -9.96288098e-03, -7.83409923e-04,\n",
       "         8.53698049e-03,  1.40394643e-02,  9.53152403e-03,\n",
       "        -2.05962285e-02,  9.36541706e-04, -1.52565073e-03,\n",
       "         1.08318534e-02, -1.52117964e-02, -1.55059528e-02,\n",
       "        -2.08522156e-02,  2.59196386e-04,  1.14343204e-02,\n",
       "        -1.43200383e-02, -1.64381936e-02,  1.04017789e-02,\n",
       "        -8.23124126e-03, -1.28378961e-02, -7.50499777e-03,\n",
       "        -7.31213763e-03,  5.44128940e-03, -2.82993354e-03,\n",
       "        -7.39159994e-03,  1.65567175e-02, -8.47219303e-03,\n",
       "        -6.22994779e-03, -2.22863071e-03,  1.50175206e-03,\n",
       "         2.70920135e-02,  1.00112334e-03,  1.41042366e-03,\n",
       "        -6.49494678e-03, -4.12981026e-03,  6.13933802e-03,\n",
       "         1.12888319e-02, -5.18261082e-03,  2.32883245e-02,\n",
       "        -8.97859503e-03,  8.65156297e-03, -1.09710954e-02,\n",
       "         2.39358824e-02,  3.45135108e-03,  1.41561106e-02,\n",
       "        -4.59022215e-03,  3.32702510e-03,  3.99453565e-04,\n",
       "        -9.41946171e-03,  2.01623961e-02,  7.51631707e-03,\n",
       "        -1.27646513e-03, -5.05646784e-03,  9.77039337e-04,\n",
       "         1.72805656e-02, -7.47481268e-03, -9.01920535e-03,\n",
       "        -1.45089012e-02,  2.71263160e-03, -6.01952896e-03,\n",
       "        -4.50874493e-03, -1.38824936e-02,  7.94705935e-04,\n",
       "        -8.30064155e-03,  2.03233119e-03,  8.26618634e-03,\n",
       "         7.02141691e-03,  1.14908256e-02, -2.28833463e-02,\n",
       "         2.37723626e-03,  6.21046871e-03, -4.24064044e-03,\n",
       "         8.18945002e-03,  1.90558098e-03,  1.05377939e-03,\n",
       "         6.27017347e-03,  1.23246517e-02, -1.18817016e-02,\n",
       "         1.55323474e-02,  1.40568884e-02, -1.12543171e-02,\n",
       "        -1.81001029e-03, -3.36630642e-03,  4.49062418e-03,\n",
       "         2.17524245e-02,  1.18408641e-02, -5.74031845e-03,\n",
       "        -1.79828890e-02, -3.93743441e-03, -1.78592652e-03,\n",
       "         5.43074682e-04, -3.02099250e-03, -7.28917215e-03,\n",
       "        -1.00536477e-02,  2.92687304e-03],\n",
       "       [-1.23136220e-02,  9.17630270e-03, -9.98414960e-03,\n",
       "        -1.48621388e-02,  1.20648928e-03, -6.48953835e-04,\n",
       "        -9.50676575e-03,  9.15343687e-03, -7.74317235e-03,\n",
       "        -1.37281064e-02,  9.11096111e-04, -2.55473703e-03,\n",
       "         7.08512217e-03,  1.07329674e-02,  2.67505017e-03,\n",
       "        -1.57924332e-02,  2.25679614e-02, -1.43644400e-03,\n",
       "        -2.47402508e-02, -9.63639189e-03,  1.89593900e-03,\n",
       "         4.56621125e-03,  2.51417980e-03,  4.83400002e-03,\n",
       "         1.08286273e-02,  2.62327492e-04,  1.35073960e-02,\n",
       "         4.00248393e-02, -1.92184132e-02, -1.43333711e-03,\n",
       "         8.92337039e-03, -1.75821766e-01,  6.62516570e-03,\n",
       "        -2.02704556e-02,  2.08821036e-02,  1.42701669e-02,\n",
       "         1.27273118e-02, -6.01357222e-03,  3.91783193e-04,\n",
       "        -2.02486329e-02,  1.55719090e-02,  2.16881260e-02,\n",
       "         1.19784456e-02,  1.00100879e-02, -1.15308510e-02,\n",
       "         7.64341094e-03,  9.46723390e-03, -2.19284324e-03,\n",
       "        -1.73839647e-02,  9.03006084e-03, -1.73342414e-03,\n",
       "        -1.37240104e-02,  1.36340214e-02,  1.76219735e-03,\n",
       "        -3.32578085e-03,  2.67771538e-04, -9.83994268e-03,\n",
       "        -6.74485508e-03, -1.93170365e-03, -7.93292373e-03,\n",
       "        -2.44405493e-03,  3.14096361e-03,  1.57487113e-02,\n",
       "         1.58103555e-02, -2.49598976e-02, -1.10474713e-02,\n",
       "         1.89619120e-02,  5.53192664e-03, -1.80027150e-02,\n",
       "         6.62473962e-04, -1.74077973e-03, -9.56873782e-03,\n",
       "        -3.62678058e-03,  1.41849872e-02, -3.86376027e-03,\n",
       "        -1.09397313e-02,  1.72384381e-02,  7.46332295e-03,\n",
       "        -7.72375427e-03,  9.98303294e-05, -7.47451559e-04,\n",
       "         8.59451853e-03, -6.60570711e-03, -2.19533071e-02,\n",
       "         7.34124985e-03,  3.58549878e-03,  4.63579781e-03,\n",
       "        -1.65384896e-02,  5.25737181e-03, -6.12383150e-03,\n",
       "        -8.38396605e-03, -1.37627497e-03,  6.53699040e-04,\n",
       "         9.67316888e-03,  3.74161452e-03, -7.11218175e-03,\n",
       "        -5.80340996e-03,  2.93009914e-03, -9.91682243e-03,\n",
       "        -8.41803383e-04,  5.18450001e-03,  1.26244724e-02,\n",
       "         1.37259699e-02, -6.74424246e-02,  6.53070770e-03,\n",
       "         1.11625316e-02, -9.97428596e-03, -7.96116889e-04,\n",
       "         8.54646601e-03,  1.40338689e-02,  9.55518521e-03,\n",
       "        -2.05997676e-02,  9.25663859e-04, -1.52829476e-03,\n",
       "         1.08304154e-02, -1.52163114e-02, -1.55212749e-02,\n",
       "        -2.08592303e-02,  2.58043408e-04,  1.14217326e-02,\n",
       "        -1.43207759e-02, -1.64676867e-02,  1.03954216e-02,\n",
       "        -8.22099671e-03, -1.28349625e-02, -7.51534663e-03,\n",
       "        -7.29687233e-03,  5.45004383e-03, -2.83012167e-03,\n",
       "        -7.40264915e-03,  1.65569261e-02, -8.46047699e-03,\n",
       "        -6.22726930e-03, -2.22241506e-03,  1.50144659e-03,\n",
       "         2.70871129e-02,  1.01823732e-03,  1.41093682e-03,\n",
       "        -6.48557395e-03, -4.12944518e-03,  6.14429638e-03,\n",
       "         1.12799052e-02, -5.17452881e-03,  2.32978016e-02,\n",
       "        -8.99194647e-03,  8.64122342e-03, -1.09693184e-02,\n",
       "         2.39389464e-02,  3.44917551e-03,  1.41537096e-02,\n",
       "        -4.58929408e-03,  3.32775339e-03,  4.00224701e-04,\n",
       "        -9.41679627e-03,  2.01772004e-02,  7.49133155e-03,\n",
       "        -1.29021890e-03, -5.03859110e-03,  9.92285088e-04,\n",
       "         1.72797572e-02, -7.49854837e-03, -9.00805555e-03,\n",
       "        -1.44972298e-02,  2.71383952e-03, -6.02436066e-03,\n",
       "        -4.50646132e-03, -1.38921067e-02,  7.85960816e-04,\n",
       "        -8.29120725e-03,  2.02636886e-03,  8.25896114e-03,\n",
       "         7.00938329e-03,  1.14916181e-02, -2.28777435e-02,\n",
       "         2.37258896e-03,  6.22244924e-03, -4.23750468e-03,\n",
       "         8.18558689e-03,  1.90786831e-03,  1.03446376e-03,\n",
       "         6.27498282e-03,  1.23240761e-02, -1.18773635e-02,\n",
       "         1.55370133e-02,  1.40597494e-02, -1.12590520e-02,\n",
       "        -1.81326061e-03, -3.35718691e-03,  4.48205229e-03,\n",
       "         2.17515752e-02,  1.18443333e-02, -5.72537631e-03,\n",
       "        -1.79832689e-02, -3.93432984e-03, -1.79541856e-03,\n",
       "         5.50959259e-04, -3.02492455e-03, -7.29740132e-03,\n",
       "        -1.00480560e-02,  2.91720405e-03],\n",
       "       [-1.23242466e-02,  9.16245114e-03, -9.98900551e-03,\n",
       "        -1.48604736e-02,  1.21334381e-03, -6.29473128e-04,\n",
       "        -9.51827224e-03,  9.14943032e-03, -7.75844790e-03,\n",
       "        -1.37410890e-02,  9.11455601e-04, -2.53298134e-03,\n",
       "         7.07305875e-03,  1.07316002e-02,  2.67658639e-03,\n",
       "        -1.57900676e-02,  2.25709341e-02, -1.44181028e-03,\n",
       "        -2.47321762e-02, -9.62726306e-03,  1.90010853e-03,\n",
       "         4.56589088e-03,  2.52038799e-03,  4.84628975e-03,\n",
       "         1.08347051e-02,  2.45738775e-04,  1.34895239e-02,\n",
       "         4.00176197e-02, -1.92162264e-02, -1.44674815e-03,\n",
       "         8.92394036e-03, -1.75832793e-01,  6.62370166e-03,\n",
       "        -2.02602707e-02,  2.08866596e-02,  1.42574860e-02,\n",
       "         1.27287367e-02, -6.03004545e-03,  3.83900478e-04,\n",
       "        -2.02428512e-02,  1.55749172e-02,  2.16874443e-02,\n",
       "         1.19677987e-02,  1.00104250e-02, -1.15269367e-02,\n",
       "         7.63284229e-03,  9.46915522e-03, -2.20246240e-03,\n",
       "        -1.73701141e-02,  9.03873146e-03, -1.73265487e-03,\n",
       "        -1.37242712e-02,  1.36271967e-02,  1.75094977e-03,\n",
       "        -3.31433117e-03,  2.61974055e-04, -9.83516127e-03,\n",
       "        -6.74732868e-03, -1.92793924e-03, -7.92036951e-03,\n",
       "        -2.45060027e-03,  3.14464606e-03,  1.57541391e-02,\n",
       "         1.58081464e-02, -2.49541309e-02, -1.10481419e-02,\n",
       "         1.89632792e-02,  5.51637169e-03, -1.79911554e-02,\n",
       "         6.60393387e-04, -1.75214373e-03, -9.56834666e-03,\n",
       "        -3.62048671e-03,  1.41740330e-02, -3.86044895e-03,\n",
       "        -1.09486291e-02,  1.72361657e-02,  7.46939145e-03,\n",
       "        -7.72063248e-03,  1.02978200e-04, -7.50096515e-04,\n",
       "         8.59662145e-03, -6.58833608e-03, -2.19550543e-02,\n",
       "         7.34828226e-03,  3.59175354e-03,  4.62780334e-03,\n",
       "        -1.65440887e-02,  5.25426865e-03, -6.13290258e-03,\n",
       "        -8.37856065e-03, -1.36279501e-03,  6.43391162e-04,\n",
       "         9.67183430e-03,  3.74367088e-03, -7.11212959e-03,\n",
       "        -5.80399670e-03,  2.92794779e-03, -9.91539750e-03,\n",
       "        -8.38218722e-04,  5.17832348e-03,  1.26286484e-02,\n",
       "         1.37258088e-02, -6.74351603e-02,  6.53814338e-03,\n",
       "         1.11625372e-02, -9.96445864e-03, -7.92820007e-04,\n",
       "         8.54252093e-03,  1.40293222e-02,  9.54690389e-03,\n",
       "        -2.05888934e-02,  9.25442204e-04, -1.53374299e-03,\n",
       "         1.08262207e-02, -1.52098034e-02, -1.55086946e-02,\n",
       "        -2.08499972e-02,  2.57529318e-04,  1.14352666e-02,\n",
       "        -1.43221505e-02, -1.64373331e-02,  1.03909792e-02,\n",
       "        -8.23128223e-03, -1.28390417e-02, -7.50663877e-03,\n",
       "        -7.30525702e-03,  5.43903559e-03, -2.82763690e-03,\n",
       "        -7.40294904e-03,  1.65551975e-02, -8.47567804e-03,\n",
       "        -6.23077201e-03, -2.22497433e-03,  1.49044581e-03,\n",
       "         2.70878263e-02,  1.00539625e-03,  1.40773493e-03,\n",
       "        -6.49623200e-03, -4.12608124e-03,  6.14256971e-03,\n",
       "         1.12921819e-02, -5.18408045e-03,  2.32865997e-02,\n",
       "        -8.98491126e-03,  8.64702743e-03, -1.09723713e-02,\n",
       "         2.39421688e-02,  3.44785303e-03,  1.41458008e-02,\n",
       "        -4.59079817e-03,  3.33327986e-03,  4.00071964e-04,\n",
       "        -9.42289270e-03,  2.01625377e-02,  7.50353187e-03,\n",
       "        -1.28264166e-03, -5.05139213e-03,  9.75744799e-04,\n",
       "         1.72916017e-02, -7.48137850e-03, -9.00673307e-03,\n",
       "        -1.44977253e-02,  2.70783901e-03, -6.02965755e-03,\n",
       "        -4.50828671e-03, -1.38924420e-02,  7.94072635e-04,\n",
       "        -8.29654187e-03,  2.02726107e-03,  8.26306082e-03,\n",
       "         7.02011772e-03,  1.14888288e-02, -2.28872560e-02,\n",
       "         2.37235520e-03,  6.20736927e-03, -4.23516426e-03,\n",
       "         8.19208380e-03,  1.90506130e-03,  1.03963073e-03,\n",
       "         6.27894560e-03,  1.23180263e-02, -1.18797868e-02,\n",
       "         1.55376578e-02,  1.40562626e-02, -1.12550640e-02,\n",
       "        -1.80364377e-03, -3.36606055e-03,  4.48335893e-03,\n",
       "         2.17465758e-02,  1.18313003e-02, -5.73949143e-03,\n",
       "        -1.79847032e-02, -3.93695803e-03, -1.78450719e-03,\n",
       "         5.45484945e-04, -3.00961733e-03, -7.29475450e-03,\n",
       "        -1.00548994e-02,  2.92413589e-03],\n",
       "       [-1.23232882e-02,  9.18566808e-03, -9.99033079e-03,\n",
       "        -1.48548409e-02,  1.20900385e-03, -6.41089282e-04,\n",
       "        -9.50125325e-03,  9.14959237e-03, -7.73648731e-03,\n",
       "        -1.37187559e-02,  9.17099416e-04, -2.54744291e-03,\n",
       "         7.08578667e-03,  1.07299238e-02,  2.67500174e-03,\n",
       "        -1.57939605e-02,  2.25668624e-02, -1.43775903e-03,\n",
       "        -2.47410052e-02, -9.63178370e-03,  1.88957155e-03,\n",
       "         4.56795096e-03,  2.52946094e-03,  4.82616015e-03,\n",
       "         1.08324662e-02,  2.77079642e-04,  1.34996511e-02,\n",
       "         4.00126949e-02, -1.92302298e-02, -1.43322721e-03,\n",
       "         8.90701637e-03, -1.75824791e-01,  6.61854213e-03,\n",
       "        -2.02794392e-02,  2.08880566e-02,  1.42834242e-02,\n",
       "         1.27221709e-02, -6.01119921e-03,  3.92142683e-04,\n",
       "        -2.02543661e-02,  1.55846570e-02,  2.17099898e-02,\n",
       "         1.19790155e-02,  9.99713130e-03, -1.15362061e-02,\n",
       "         7.64008611e-03,  9.46751051e-03, -2.19230494e-03,\n",
       "        -1.73792318e-02,  9.03755054e-03, -1.73847005e-03,\n",
       "        -1.37214344e-02,  1.36354296e-02,  1.74342422e-03,\n",
       "        -3.32816690e-03,  2.64587346e-04, -9.84243397e-03,\n",
       "        -6.74158148e-03, -1.93046127e-03, -7.91598856e-03,\n",
       "        -2.44331732e-03,  3.14322487e-03,  1.57433618e-02,\n",
       "         1.58242434e-02, -2.49619372e-02, -1.10523719e-02,\n",
       "         1.89452823e-02,  5.52343484e-03, -1.80026945e-02,\n",
       "         6.71930611e-04, -1.73999928e-03, -9.57515277e-03,\n",
       "        -3.62169556e-03,  1.41791459e-02, -3.86214210e-03,\n",
       "        -1.09331990e-02,  1.72455609e-02,  7.47517310e-03,\n",
       "        -7.72907026e-03,  1.10633671e-04, -7.50977546e-04,\n",
       "         8.58914293e-03, -6.60762936e-03, -2.19639130e-02,\n",
       "         7.35384226e-03,  3.58090177e-03,  4.63531353e-03,\n",
       "        -1.65432133e-02,  5.24828210e-03, -6.12059981e-03,\n",
       "        -8.38275161e-03, -1.36405602e-03,  6.59361482e-04,\n",
       "         9.68044624e-03,  3.74065153e-03, -7.11015332e-03,\n",
       "        -5.80443721e-03,  2.92639062e-03, -9.91768111e-03,\n",
       "        -8.31892248e-04,  5.19320229e-03,  1.26118027e-02,\n",
       "         1.37299057e-02, -6.74517155e-02,  6.53591007e-03,\n",
       "         1.11765927e-02, -9.97051224e-03, -7.91043043e-04,\n",
       "         8.53830110e-03,  1.40374191e-02,  9.55285691e-03,\n",
       "        -2.06113197e-02,  9.27193090e-04, -1.53099559e-03,\n",
       "         1.08166365e-02, -1.52233001e-02, -1.55216660e-02,\n",
       "        -2.08481569e-02,  2.58538872e-04,  1.14405192e-02,\n",
       "        -1.43116862e-02, -1.64789222e-02,  1.04011279e-02,\n",
       "        -8.22745636e-03, -1.28286369e-02, -7.51324557e-03,\n",
       "        -7.29467627e-03,  5.44563122e-03, -2.81459838e-03,\n",
       "        -7.39948265e-03,  1.65387690e-02, -8.46198015e-03,\n",
       "        -6.21307036e-03, -2.21585110e-03,  1.49996765e-03,\n",
       "         2.70931218e-02,  1.01297721e-03,  1.41092099e-03,\n",
       "        -6.47757947e-03, -4.13142610e-03,  6.14500791e-03,\n",
       "         1.12798568e-02, -5.18164411e-03,  2.32959725e-02,\n",
       "        -9.00643505e-03,  8.63195863e-03, -1.09771881e-02,\n",
       "         2.39418745e-02,  3.45481187e-03,  1.41629353e-02,\n",
       "        -4.58109146e-03,  3.32667306e-03,  3.94597650e-04,\n",
       "        -9.40754265e-03,  2.01886799e-02,  7.49750063e-03,\n",
       "        -1.28330477e-03, -5.03929984e-03,  9.96023417e-04,\n",
       "         1.72779281e-02, -7.49473926e-03, -9.02019627e-03,\n",
       "        -1.44886877e-02,  2.71172822e-03, -6.01307116e-03,\n",
       "        -4.51350212e-03, -1.38771944e-02,  7.89270736e-04,\n",
       "        -8.30263831e-03,  2.03044433e-03,  8.26713443e-03,\n",
       "         7.01956078e-03,  1.14885056e-02, -2.28871722e-02,\n",
       "         2.37316079e-03,  6.21948391e-03, -4.24684957e-03,\n",
       "         8.19316972e-03,  1.91425718e-03,  1.04129594e-03,\n",
       "         6.27385871e-03,  1.23225721e-02, -1.18677616e-02,\n",
       "         1.55410180e-02,  1.40612330e-02, -1.12525569e-02,\n",
       "        -1.81414443e-03, -3.36810201e-03,  4.47347481e-03,\n",
       "         2.17624903e-02,  1.18389893e-02, -5.73324412e-03,\n",
       "        -1.79936960e-02, -3.92565085e-03, -1.78557262e-03,\n",
       "         5.58007509e-04, -3.04406509e-03, -7.30060413e-03,\n",
       "        -1.00462493e-02,  2.92256940e-03],\n",
       "       [-1.23216733e-02,  9.17821936e-03, -9.98511165e-03,\n",
       "        -1.48488935e-02,  1.20241381e-03, -6.31357892e-04,\n",
       "        -9.50498506e-03,  9.15006176e-03, -7.74458610e-03,\n",
       "        -1.37395915e-02,  9.15734097e-04, -2.53739581e-03,\n",
       "         7.08235614e-03,  1.07336305e-02,  2.66367872e-03,\n",
       "        -1.57879330e-02,  2.25672610e-02, -1.44310109e-03,\n",
       "        -2.47445144e-02, -9.62368306e-03,  1.89511757e-03,\n",
       "         4.56157327e-03,  2.51936913e-03,  4.83083911e-03,\n",
       "         1.08335279e-02,  2.58464366e-04,  1.34885740e-02,\n",
       "         4.00192477e-02, -1.92185584e-02, -1.44224428e-03,\n",
       "         8.91607814e-03, -1.75840199e-01,  6.62703393e-03,\n",
       "        -2.02798843e-02,  2.08832938e-02,  1.42805660e-02,\n",
       "         1.27296438e-02, -6.01645932e-03,  3.88534740e-04,\n",
       "        -2.02499516e-02,  1.55831017e-02,  2.17043571e-02,\n",
       "         1.19756237e-02,  1.00066084e-02, -1.15237646e-02,\n",
       "         7.65105337e-03,  9.46962461e-03, -2.20457185e-03,\n",
       "        -1.73715800e-02,  9.03954543e-03, -1.73333287e-03,\n",
       "        -1.37313679e-02,  1.36292679e-02,  1.75406737e-03,\n",
       "        -3.32495384e-03,  2.78079417e-04, -9.84019879e-03,\n",
       "        -6.73941756e-03, -1.93318818e-03, -7.92591274e-03,\n",
       "        -2.43882835e-03,  3.14311683e-03,  1.57614164e-02,\n",
       "         1.58026107e-02, -2.49543227e-02, -1.10565610e-02,\n",
       "         1.89626049e-02,  5.52083459e-03, -1.80027876e-02,\n",
       "         6.62030652e-04, -1.74076110e-03, -9.57313739e-03,\n",
       "        -3.62719782e-03,  1.41722150e-02, -3.86840245e-03,\n",
       "        -1.09375352e-02,  1.72539614e-02,  7.46480003e-03,\n",
       "        -7.72806816e-03,  8.87513161e-05, -7.59223476e-04,\n",
       "         8.57920386e-03, -6.59357384e-03, -2.19667330e-02,\n",
       "         7.36224838e-03,  3.59107926e-03,  4.63560596e-03,\n",
       "        -1.65478960e-02,  5.25335222e-03, -6.12275302e-03,\n",
       "        -8.38357490e-03, -1.37008354e-03,  6.44546002e-04,\n",
       "         9.67364758e-03,  3.73333320e-03, -7.11478386e-03,\n",
       "        -5.81516884e-03,  2.92037427e-03, -9.92735568e-03,\n",
       "        -8.45200848e-04,  5.18116960e-03,  1.26168728e-02,\n",
       "         1.37242377e-02, -6.74451143e-02,  6.53790683e-03,\n",
       "         1.11710159e-02, -9.95892473e-03, -7.85920769e-04,\n",
       "         8.52875225e-03,  1.40453428e-02,  9.55014862e-03,\n",
       "        -2.05994546e-02,  9.23916698e-04, -1.52807124e-03,\n",
       "         1.08183734e-02, -1.52134430e-02, -1.55066792e-02,\n",
       "        -2.08533406e-02,  2.58486718e-04,  1.14452504e-02,\n",
       "        -1.43131539e-02, -1.64502934e-02,  1.03943404e-02,\n",
       "        -8.22820142e-03, -1.28407236e-02, -7.51029514e-03,\n",
       "        -7.31306802e-03,  5.44742122e-03, -2.82367691e-03,\n",
       "        -7.40727969e-03,  1.65488124e-02, -8.45132023e-03,\n",
       "        -6.21234486e-03, -2.21930258e-03,  1.50527246e-03,\n",
       "         2.70940103e-02,  1.00709684e-03,  1.41533825e-03,\n",
       "        -6.48991391e-03, -4.12454270e-03,  6.14303909e-03,\n",
       "         1.12800607e-02, -5.18638082e-03,  2.32995581e-02,\n",
       "        -8.98594968e-03,  8.65263026e-03, -1.09774452e-02,\n",
       "         2.39356495e-02,  3.46314535e-03,  1.41526535e-02,\n",
       "        -4.58613038e-03,  3.31802107e-03,  4.03312966e-04,\n",
       "        -9.40790027e-03,  2.01681107e-02,  7.50456750e-03,\n",
       "        -1.28384866e-03, -5.05728088e-03,  9.83865932e-04,\n",
       "         1.72832459e-02, -7.48181064e-03, -9.02636908e-03,\n",
       "        -1.45071726e-02,  2.71780510e-03, -6.02002256e-03,\n",
       "        -4.51710448e-03, -1.38860382e-02,  7.92917795e-04,\n",
       "        -8.29622708e-03,  2.03459244e-03,  8.27251375e-03,\n",
       "         7.02335592e-03,  1.14914011e-02, -2.28814576e-02,\n",
       "         2.37143505e-03,  6.22597896e-03, -4.23808210e-03,\n",
       "         8.18758551e-03,  1.91008113e-03,  1.05566066e-03,\n",
       "         6.27237884e-03,  1.23114288e-02, -1.18711684e-02,\n",
       "         1.55506553e-02,  1.40532665e-02, -1.12560643e-02,\n",
       "        -1.81526481e-03, -3.37857753e-03,  4.48432658e-03,\n",
       "         2.17478722e-02,  1.18374694e-02, -5.73291257e-03,\n",
       "        -1.79946236e-02, -3.94252036e-03, -1.78749114e-03,\n",
       "         5.61740249e-04, -3.02603096e-03, -7.27480650e-03,\n",
       "        -1.00417938e-02,  2.93051731e-03]], dtype=float32)"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "with torch.no_grad():\n",
    "    siamese_model.eval()\n",
    "    temp = tokenizer(list(clean_df['clean_comment'][:5]), padding='max_length', max_length = 512, truncation=True, return_tensors=\"pt\")\n",
    "    temp_embs = siamese_model.get_emb(temp['input_ids'].to(device), temp['attention_mask'].to(device)).cpu().detach().numpy()\n",
    "temp_embs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "ace00184",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2044"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "with torch.no_grad():\n",
    "    siamese_model.eval()\n",
    "    comment_embs = []\n",
    "    batch_size=4\n",
    "    for i in range(0, len(clean_df), batch_size):\n",
    "        temp = tokenizer(list(clean_df['clean_comment'][i:i+batch_size]), padding='max_length', max_length = 512, truncation=True, return_tensors=\"pt\")\n",
    "        comment_embs.extend(siamese_model.get_emb(temp['input_ids'].to(device), temp['attention_mask'].to(device)).cpu().detach().numpy().tolist())\n",
    "len(comment_embs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "id": "4a8ca2e3",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[0.0010330984368920326,\n",
       " 0.0021282322704792023,\n",
       " 0.010343076661229134,\n",
       " 0.008804318495094776,\n",
       " 0.006543041206896305,\n",
       " -0.00418749637901783,\n",
       " -0.004169367253780365,\n",
       " 0.01086103543639183,\n",
       " 0.00490739569067955,\n",
       " -0.01188814640045166,\n",
       " 0.01522417739033699,\n",
       " 0.009816281497478485,\n",
       " -0.005128994584083557,\n",
       " -0.009730320423841476,\n",
       " 0.001095877494663,\n",
       " 0.001436181366443634,\n",
       " 0.011248903349041939,\n",
       " 0.013945233076810837,\n",
       " 0.007011214271187782,\n",
       " -0.0005766209214925766,\n",
       " -0.0046805404126644135,\n",
       " 0.0017718560993671417,\n",
       " 0.005152605473995209,\n",
       " -0.0022124052047729492,\n",
       " -0.0024828817695379257,\n",
       " 0.022188086062669754,\n",
       " -0.0020463773980736732,\n",
       " 0.0009299931116402149,\n",
       " 0.00382344052195549,\n",
       " -0.006208650767803192,\n",
       " 0.00835149921476841,\n",
       " 0.0031979791820049286,\n",
       " -0.0016398960724473,\n",
       " 0.0022911299020051956,\n",
       " -0.006500369869172573,\n",
       " -0.0002338513731956482,\n",
       " 0.003184921108186245,\n",
       " -0.008606663905084133,\n",
       " -0.007743306457996368,\n",
       " 0.003949424251914024,\n",
       " 0.004938815254718065,\n",
       " -0.0035108327865600586,\n",
       " -0.018039464950561523,\n",
       " 0.004800374619662762,\n",
       " -2.2528693079948425e-05,\n",
       " 0.007878352887928486,\n",
       " 0.01667579635977745,\n",
       " 0.007752374745905399,\n",
       " -0.0010445211082696915,\n",
       " -0.00857818964868784,\n",
       " 0.007653627544641495,\n",
       " -0.013895127922296524,\n",
       " 0.006744468584656715,\n",
       " 0.0031171441078186035,\n",
       " 0.007741698995232582,\n",
       " -0.0018598437309265137,\n",
       " -0.004196132533252239,\n",
       " 0.0040911659598350525,\n",
       " 0.012899712659418583,\n",
       " 0.0014782529324293137,\n",
       " -0.01468675583600998,\n",
       " 0.002095453441143036,\n",
       " 0.013899135403335094,\n",
       " -0.010528351180255413,\n",
       " 0.012915849685668945,\n",
       " -0.000674249604344368,\n",
       " -0.0033115744590759277,\n",
       " -0.00018248148262500763,\n",
       " -0.016211653128266335,\n",
       " -0.0069002630189061165,\n",
       " -0.008280486799776554,\n",
       " -0.011775238439440727,\n",
       " -0.008062126114964485,\n",
       " -0.001789828296750784,\n",
       " 0.00625653937458992,\n",
       " 0.018322622403502464,\n",
       " 0.01559816487133503,\n",
       " 0.011514300480484962,\n",
       " -0.0008717002347111702,\n",
       " -0.007198592647910118,\n",
       " 0.0009292131289839745,\n",
       " -0.010427230969071388,\n",
       " -0.00337810255587101,\n",
       " -0.0005443952977657318,\n",
       " -0.00543966144323349,\n",
       " -0.0015223491936922073,\n",
       " 0.00019841268658638,\n",
       " -0.01298587117344141,\n",
       " 0.0003476059064269066,\n",
       " 0.006176976952701807,\n",
       " -0.008109815418720245,\n",
       " -0.0068151578307151794,\n",
       " 0.005798520520329475,\n",
       " -0.016901934519410133,\n",
       " 0.0069047836586833,\n",
       " -0.002216724678874016,\n",
       " -0.0007661003619432449,\n",
       " 0.004385754466056824,\n",
       " 0.00024764612317085266,\n",
       " 0.010136185213923454,\n",
       " -0.005628015846014023,\n",
       " 0.010813435539603233,\n",
       " 0.0011332351714372635,\n",
       " 0.003206135705113411,\n",
       " -0.0003530234098434448,\n",
       " -0.006358616054058075,\n",
       " -0.004509469494223595,\n",
       " -0.0039711277931928635,\n",
       " -0.018414758145809174,\n",
       " 0.004493610467761755,\n",
       " -0.00891123153269291,\n",
       " -0.0007835179567337036,\n",
       " -0.0037130513228476048,\n",
       " -0.004533147439360619,\n",
       " 0.0004355013370513916,\n",
       " 0.007551632821559906,\n",
       " -0.007364928722381592,\n",
       " -0.00012850668281316757,\n",
       " 0.004523752257227898,\n",
       " -0.006006090901792049,\n",
       " -0.006392689421772957,\n",
       " 0.010729492641985416,\n",
       " 0.009125471115112305,\n",
       " 0.007129250094294548,\n",
       " -1.1675059795379639e-05,\n",
       " -0.0022340738214552402,\n",
       " 0.012688156217336655,\n",
       " 0.0016144253313541412,\n",
       " 0.016728539019823074,\n",
       " -0.006925213150680065,\n",
       " 0.004661560989916325,\n",
       " -0.0007894262671470642,\n",
       " 0.006843294948339462,\n",
       " 0.01883346401154995,\n",
       " 0.019865676760673523,\n",
       " 0.011288192123174667,\n",
       " -0.004385270178318024,\n",
       " 0.013511442579329014,\n",
       " 0.09434686601161957,\n",
       " -0.008081000298261642,\n",
       " 0.0015094242990016937,\n",
       " -0.006642279215157032,\n",
       " 0.008296692743897438,\n",
       " -0.0022244686260819435,\n",
       " 0.0017183776944875717,\n",
       " -0.008396538905799389,\n",
       " 0.02021198533475399,\n",
       " -0.021362874656915665,\n",
       " -0.007207450456917286,\n",
       " -0.006317181512713432,\n",
       " -0.019855959340929985,\n",
       " -0.005659207701683044,\n",
       " -0.028780585154891014,\n",
       " 0.01342690084129572,\n",
       " -0.010304588824510574,\n",
       " -0.005046779289841652,\n",
       " -0.02494427002966404,\n",
       " 0.011358115822076797,\n",
       " 0.005693472921848297,\n",
       " -0.009426373988389969,\n",
       " -0.009474735707044601,\n",
       " -0.008692452684044838,\n",
       " -0.0014817197807133198,\n",
       " 0.009714403189718723,\n",
       " -0.01541480328887701,\n",
       " -0.027447544038295746,\n",
       " 0.010364538058638573,\n",
       " 0.00866154208779335,\n",
       " -0.008708076551556587,\n",
       " 0.021119635552167892,\n",
       " -0.002641957253217697,\n",
       " 0.014659963548183441,\n",
       " -0.0022976105101406574,\n",
       " 0.0010731338988989592,\n",
       " -0.016082370653748512,\n",
       " -0.013176923617720604,\n",
       " 0.006617782637476921,\n",
       " 0.005114874802529812,\n",
       " -0.007393346168100834,\n",
       " 0.008037937805056572,\n",
       " -0.0018506217747926712,\n",
       " 0.014713456854224205,\n",
       " -0.004822665825486183,\n",
       " 0.00234430143609643,\n",
       " 0.006604108959436417,\n",
       " 0.0062242550775408745,\n",
       " -0.016071602702140808,\n",
       " 0.0064832172356545925,\n",
       " -0.004687083885073662,\n",
       " 0.005444843787699938,\n",
       " -0.008554522879421711,\n",
       " -0.00682545080780983,\n",
       " 0.006894261110574007,\n",
       " 0.00443559605628252,\n",
       " 0.01191990077495575,\n",
       " 0.008141443133354187,\n",
       " 0.0216253362596035,\n",
       " -0.0045138075947761536,\n",
       " 0.0039267148822546005,\n",
       " 0.0027694255113601685]"
      ]
     },
     "execution_count": 110,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "comment_embs[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "69ef27cb",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1.401454210281372e-05"
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.max(np.array(comment_embs[12])-np.array(comment_embs[42]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "a83768da",
   "metadata": {},
   "outputs": [],
   "source": [
    "emb_dict = {'comment':list(clean_df['clean_comment']), 'target':list(clean_df['target']), 'emb':comment_embs}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 112,
   "id": "dda28a20",
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('siamese_embeddings.json', 'w') as fileobj:\n",
    "    json.dump(emb_dict, fileobj)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d4d79e99",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "74c5de6f",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(emb_dict['emb'], emb_dict['target'], test_size = 0.3, random_state = 123)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "a6019b93",
   "metadata": {},
   "outputs": [],
   "source": [
    "scaler = StandardScaler()\n",
    "scaler.fit(X_train)\n",
    "X_train = scaler.transform(X_train)\n",
    "X_test = scaler.transform(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "fdc383f5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Lasso(alpha=0.05)"
      ]
     },
     "execution_count": 48,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lasso = linear_model.Lasso(alpha = 5e-2)  # higher alpha means more weights are \"dropped\"\n",
    "lasso.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "ec05e381",
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred = lasso.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "id": "4a5c0435",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.4235634209638861"
      ]
     },
     "execution_count": 54,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.sqrt(mean_squared_error(y_test, y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 167,
   "id": "9c207d25",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.41869282195222374"
      ]
     },
     "execution_count": 167,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_train_pred = lasso.predict(X_train)\n",
    "np.sqrt(mean_squared_error(y_train, y_train_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "id": "d180d37f",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.0 \t -0.04548822066086966\n",
      "-0.25 \t -0.0359112027299842\n",
      "0.0 \t -0.00532681584862299\n",
      "-0.5 \t -0.028270260054304018\n",
      "0.0 \t -0.032379178709008874\n",
      "-0.25 \t -0.04656136130430148\n",
      "0.0 \t -0.03558803371950367\n",
      "-0.75 \t -0.029733217690268588\n",
      "0.0 \t -0.033708707988475674\n",
      "0.5 \t -0.0320100689719609\n",
      "0.5 \t -0.02225944588708992\n",
      "-0.5 \t -0.04005450688541198\n",
      "0.25 \t -0.03797039727213578\n",
      "0.25 \t -0.028691739443123636\n",
      "-0.25 \t -0.04474594205405832\n",
      "0.0 \t -0.03849435172769572\n",
      "0.25 \t -0.04673972022162538\n",
      "0.0 \t -0.034663402131313144\n",
      "0.0 \t -0.03211737553491658\n",
      "0.75 \t -0.03706870015794359\n",
      "1.0 \t -0.03283176007051036\n",
      "0.0 \t -0.02979045819627723\n",
      "0.5 \t -0.035084908435629274\n",
      "-1.0 \t -0.04032253270157407\n",
      "0.5 \t -0.02235932903986454\n",
      "0.0 \t -0.03715020558825839\n",
      "1.0 \t -0.011350482968024479\n",
      "0.0 \t -0.03294775399287494\n",
      "0.5 \t -0.030029015282177735\n",
      "-1.0 \t -0.031140215509237044\n",
      "0.25 \t 0.004092768390478459\n",
      "0.75 \t -0.03176326733131531\n",
      "0.5 \t -0.0346188360383773\n",
      "0.5 \t -0.03796319726414357\n",
      "-0.25 \t -0.032847854931774015\n",
      "-0.5 \t -0.032733369546643215\n",
      "0.5 \t -0.03621940481559145\n",
      "1.0 \t -0.026160797014206847\n",
      "-0.5 \t -0.0322498563816821\n",
      "0.0 \t -0.03761840372097087\n",
      "-0.5 \t -0.03479800562113762\n",
      "0.0 \t -0.02718199663804017\n",
      "-0.25 \t -0.03109291749271922\n",
      "0.25 \t -0.032414271656279525\n",
      "0.0 \t -0.03306043913168364\n",
      "-0.5 \t -0.03268792221749327\n",
      "-0.25 \t -0.03300771066584716\n",
      "0.0 \t -0.041217090576239554\n",
      "0.0 \t -0.02315038079964712\n",
      "0.0 \t -0.031155927505779064\n",
      "0.0 \t -0.028459488161368583\n",
      "0.0 \t -0.03777164640981863\n",
      "0.25 \t -0.03488927771496046\n",
      "0.0 \t -0.039856480886242655\n",
      "0.0 \t -0.03396636193030441\n",
      "-0.5 \t -0.037491046910967406\n",
      "-1.0 \t -0.034813482303943315\n",
      "0.0 \t -0.03775815258508239\n",
      "0.0 \t -0.03290767227194537\n",
      "0.5 \t -0.031707384042338166\n",
      "0.25 \t -0.039066726855738025\n",
      "0.0 \t -0.03944612145703769\n",
      "0.5 \t -0.037318126585292655\n",
      "-1.0 \t -0.03251632118324824\n",
      "-0.5 \t -0.03913361030029941\n",
      "0.0 \t -0.030109263697802126\n",
      "0.0 \t -0.03960263591115187\n",
      "0.0 \t -0.04581018897909287\n",
      "0.0 \t -0.03820531978486126\n",
      "0.5 \t -0.015809297109534673\n",
      "0.25 \t -0.03461275046816519\n",
      "0.0 \t -0.03558141954233917\n",
      "0.25 \t -0.03837720913531231\n",
      "0.0 \t -0.011167650385383764\n",
      "-0.5 \t -0.03647923176567097\n",
      "-0.5 \t -0.030235972624865368\n",
      "0.0 \t -0.033920487704816954\n",
      "-0.25 \t -0.039809125718768414\n",
      "0.0 \t -0.03288641281104003\n",
      "0.0 \t -0.04025218100798897\n",
      "0.0 \t -0.03090901457976824\n",
      "0.25 \t -0.05159444454016836\n",
      "0.5 \t -0.028952837279903484\n",
      "-0.5 \t -0.03953755768992263\n",
      "1.0 \t -0.03295859973585533\n",
      "0.0 \t -0.029969216490545604\n",
      "-0.5 \t -0.03629382808148202\n",
      "0.25 \t -0.041926508504222734\n",
      "-0.75 \t -0.03520721133039481\n",
      "0.0 \t -0.03781298273278753\n",
      "-0.5 \t -0.039947859063793896\n",
      "-0.75 \t -0.03869465907978741\n",
      "-0.25 \t -0.03087482413038273\n",
      "-0.75 \t -0.04054113204969095\n",
      "-0.75 \t -0.03611857204091425\n",
      "0.0 \t -0.03893177933117096\n",
      "0.0 \t -0.0403293741230633\n",
      "-0.5 \t -0.03618422176877266\n",
      "0.0 \t -0.030415320218697688\n",
      "0.0 \t -0.042302473762331684\n",
      "0.25 \t -0.037220075195012\n",
      "-0.5 \t -0.039185242421771335\n",
      "-0.75 \t -0.031169011550297165\n",
      "-0.5 \t -0.014566016544593427\n",
      "0.75 \t -0.03743335138533168\n",
      "0.0 \t -0.03778009921109563\n",
      "-1.0 \t -0.03900596502238203\n",
      "-0.5 \t -0.029375540583113893\n",
      "0.0 \t -0.04693430745162649\n",
      "0.25 \t -0.02587190508392373\n",
      "-0.25 \t -0.04378264130123654\n",
      "-0.25 \t -0.04521070466171202\n",
      "0.0 \t -0.04106769892528319\n",
      "0.0 \t -0.036600049041920414\n",
      "-0.5 \t -0.03194525614822\n",
      "0.25 \t -0.03628358807736952\n",
      "0.0 \t -0.03430307769507198\n",
      "0.25 \t -0.037156048458008115\n",
      "0.75 \t -0.043474124360261435\n",
      "-1.0 \t -0.03370640122539555\n",
      "0.0 \t -0.0008684442842147588\n",
      "0.0 \t -0.034394266174630525\n",
      "0.0 \t -0.04788077634092747\n",
      "-0.25 \t -0.03683216476009159\n",
      "-0.25 \t -0.035695607261140384\n",
      "-0.5 \t -0.03237091183650758\n",
      "-1.0 \t -0.0457515797966939\n",
      "0.25 \t -0.03232593973257058\n",
      "0.5 \t -0.00791967903541544\n",
      "0.25 \t -0.03369392706529701\n",
      "-0.25 \t -0.04036050233442625\n",
      "-0.5 \t -0.034810688932145346\n",
      "0.0 \t -0.02675541213733241\n",
      "0.5 \t -0.029950043407079144\n",
      "0.0 \t -0.023076341227001505\n",
      "-0.5 \t -0.04196595342523623\n",
      "-0.25 \t -0.041266716617508546\n",
      "-0.75 \t -0.029155190146073685\n",
      "0.0 \t -0.0389769361560906\n",
      "-0.5 \t -0.030276360682497595\n",
      "-0.5 \t -0.02722162454713572\n",
      "-1.0 \t -0.041111013884915934\n",
      "0.0 \t -0.03305810975036657\n",
      "-0.25 \t -0.04093293702607605\n",
      "0.5 \t -0.03995793462836358\n",
      "0.0 \t -0.02784143039044001\n",
      "-0.5 \t -0.04271826635398712\n",
      "0.0 \t -0.03965323185576326\n",
      "0.25 \t -0.029712082257734335\n",
      "0.5 \t -0.035400563487127015\n",
      "0.0 \t -0.03506863081384541\n",
      "-0.25 \t -0.04291643025353746\n",
      "0.25 \t -0.03906521055250844\n",
      "0.0 \t -0.0378424998677785\n",
      "0.0 \t -0.042730754914138164\n",
      "-0.5 \t -0.047302755130308516\n",
      "0.0 \t -0.009278499331617503\n",
      "-0.5 \t -0.032154107909410645\n",
      "0.25 \t -0.04495342257449966\n",
      "0.0 \t -0.034800448248282365\n",
      "-0.5 \t -0.0330208173286022\n",
      "0.0 \t -0.029869801097468864\n",
      "0.0 \t -0.022989106099845762\n",
      "-0.25 \t -0.02074009437569245\n",
      "-0.25 \t -0.038575490125761246\n",
      "0.0 \t -0.032193267379057824\n",
      "0.0 \t -0.03810336804758255\n",
      "0.0 \t -0.03475845408835314\n",
      "0.5 \t -0.04381224936429898\n",
      "1.0 \t -0.03861558195241881\n",
      "0.0 \t -0.03951103267436514\n",
      "0.25 \t -0.03903354498796606\n",
      "0.0 \t -0.03311542618049765\n",
      "0.5 \t -0.037829169050165236\n",
      "0.0 \t -0.03146716777581702\n",
      "0.0 \t -0.039168183914887286\n",
      "0.5 \t -0.024390905314495635\n",
      "-0.5 \t -0.03464107279228617\n",
      "0.0 \t -0.04136652859560893\n",
      "0.0 \t -0.02990528784371246\n",
      "0.0 \t -0.03692688105228134\n",
      "0.0 \t -0.03176542397905116\n",
      "0.0 \t -0.04141114829491099\n",
      "0.0 \t -0.03891569788972859\n",
      "0.5 \t -0.027421602416245222\n",
      "0.0 \t -0.035886037720443964\n",
      "0.0 \t -0.04580395366987117\n",
      "-0.5 \t -0.03437276951538037\n",
      "0.5 \t -0.035324540828850094\n",
      "0.0 \t -0.037188799808998425\n",
      "-0.25 \t -0.04349402901678637\n",
      "0.0 \t -0.038571980409480636\n",
      "-0.25 \t -0.0452063504999449\n",
      "0.0 \t -0.03147924949644358\n",
      "0.0 \t -0.03676249767019048\n",
      "-0.5 \t -0.0334048791382823\n",
      "-0.25 \t -0.037973511911666556\n",
      "0.0 \t -0.03856338676712896\n",
      "0.0 \t -0.037714075892785213\n",
      "0.5 \t -0.03580270580512599\n",
      "-1.0 \t -0.03288688321095083\n",
      "0.0 \t -0.04037897211689665\n",
      "-0.5 \t -0.03351480558678535\n",
      "0.0 \t -0.032492178779039364\n",
      "-0.5 \t -0.028437251935502304\n",
      "0.25 \t -0.032778584126415815\n",
      "1.0 \t -0.031756614475879665\n",
      "0.75 \t -0.026422837538351847\n",
      "0.0 \t -0.04382228036921019\n",
      "0.5 \t -0.03218284958850011\n",
      "-0.25 \t -0.03221414751689668\n",
      "0.0 \t -0.04028181078491108\n",
      "0.0 \t -0.030601828841770335\n",
      "0.0 \t -0.03928549230337943\n",
      "-1.0 \t -0.03306707396662265\n",
      "-0.25 \t -0.013412312851861109\n",
      "-0.5 \t -0.03850200291024408\n",
      "0.0 \t -0.029063150362345146\n",
      "0.25 \t -0.03294104572231852\n",
      "-0.5 \t -0.03808404447243713\n",
      "-0.25 \t -0.04065499269816105\n",
      "0.0 \t -0.03660094113653189\n",
      "-0.75 \t -0.03932521370490542\n",
      "0.0 \t -0.030042304857160883\n",
      "-0.5 \t -0.03656631466824716\n",
      "0.0 \t -0.03673066902267118\n",
      "-0.5 \t -0.030654550370134336\n",
      "0.5 \t -0.039551062749390915\n",
      "0.25 \t -0.04097366429608377\n",
      "-0.5 \t -0.04162396720466042\n",
      "0.5 \t -0.035350665338459056\n",
      "-0.5 \t -0.04881160101547836\n",
      "0.5 \t -0.028822378197040414\n",
      "0.25 \t -0.009297624990585784\n",
      "0.0 \t -0.041222777749738426\n",
      "0.0 \t -0.028927157687128675\n",
      "0.25 \t -0.0378004328761284\n",
      "0.0 \t -0.03843142585694276\n",
      "0.0 \t -0.035646163679910865\n",
      "0.0 \t -0.026990043617784995\n",
      "0.0 \t -0.04612103062779079\n",
      "0.0 \t -0.038034369725958014\n",
      "-0.5 \t -0.03276898439095562\n",
      "0.5 \t -0.031215866158254644\n",
      "0.0 \t -0.0348760896988843\n",
      "0.0 \t -0.042832231426203925\n",
      "-0.5 \t -0.03142018190153523\n",
      "-0.25 \t -0.033043668865151664\n",
      "-0.5 \t -0.03950432606085537\n",
      "0.75 \t -0.027091048297520095\n",
      "-0.75 \t -0.045150908583211705\n",
      "-0.25 \t -0.036308503749455615\n",
      "0.0 \t -0.0410865025638493\n",
      "-0.25 \t -0.04161222378909702\n",
      "-0.75 \t -0.043715661651112896\n",
      "0.0 \t -0.029352970652859807\n",
      "0.25 \t -0.04264452527619442\n",
      "0.75 \t -0.036348297381741\n",
      "0.0 \t -0.01954640381102691\n",
      "-1.0 \t -0.03795994721273682\n",
      "0.25 \t -0.02877787468425968\n",
      "0.0 \t -0.0346043006834358\n",
      "-0.25 \t -0.031852071767105396\n",
      "0.0 \t -0.03336660301701956\n",
      "0.25 \t -0.03522326351660849\n",
      "1.0 \t -0.027514217327047057\n",
      "-0.25 \t -0.045609637642891776\n",
      "0.0 \t -0.04464012570735904\n",
      "0.0 \t -0.03837780499601406\n",
      "-0.25 \t -0.02844795683740804\n",
      "0.75 \t -0.03165455250932089\n",
      "0.0 \t -0.03715148884162989\n",
      "0.0 \t -0.04392472761314167\n",
      "-0.25 \t -0.030217339307229404\n",
      "0.25 \t -0.01981362205121908\n",
      "-0.5 \t -0.035202526705414273\n",
      "-0.25 \t -0.04136249057285666\n",
      "0.25 \t -0.036197635220418994\n",
      "0.75 \t -0.03543651897329972\n",
      "-1.0 \t -0.032722413122194115\n",
      "-0.25 \t -0.041323752797910146\n",
      "-0.5 \t -0.03325036805123924\n",
      "-0.5 \t -0.03612327483516427\n",
      "0.0 \t -0.03296833111397453\n",
      "-0.5 \t -0.030328916866941495\n",
      "-1.0 \t -0.03990170805731321\n",
      "-0.5 \t -0.041662068179690856\n",
      "0.0 \t -0.04692904483766801\n",
      "0.0 \t -0.015552182857682489\n",
      "-0.25 \t -0.03896513031208\n",
      "0.0 \t -0.035087934408031755\n",
      "0.0 \t -0.036285076785352116\n",
      "-0.5 \t -0.03894799829372459\n",
      "-0.75 \t -0.029275025531579305\n",
      "0.0 \t -0.032253624333351785\n",
      "-0.25 \t -0.032788010600252195\n",
      "0.0 \t -0.029305057022243005\n",
      "0.0 \t -0.045045692922516326\n",
      "0.0 \t -0.028726725025953935\n",
      "0.0 \t -0.03409936783943213\n",
      "0.75 \t -0.043782432602515985\n",
      "0.75 \t -0.03890944689974243\n",
      "-0.25 \t -0.03429794898471567\n",
      "0.0 \t -0.025751104696231812\n",
      "0.0 \t -0.03450362473401351\n",
      "-0.5 \t -0.03372154163945447\n",
      "1.0 \t -0.023857990111415858\n",
      "0.0 \t -0.04220118039005588\n",
      "0.0 \t -0.03533663514077461\n",
      "0.0 \t -0.03392713611128514\n",
      "0.0 \t -0.03833311849515127\n",
      "0.0 \t -0.033667384105096836\n",
      "0.25 \t -0.025833220839489496\n",
      "0.0 \t -0.03597371474788625\n",
      "0.0 \t -0.027342506816191336\n",
      "-0.5 \t -0.040439625229246386\n",
      "0.0 \t -0.044205036911178386\n",
      "0.0 \t -0.03243097097276405\n",
      "0.5 \t -0.03229263006721055\n",
      "-1.0 \t -0.01101508144182263\n",
      "0.0 \t -0.04375853621873291\n",
      "-0.5 \t -0.039189323192492465\n",
      "0.75 \t -0.0259946096894958\n",
      "0.0 \t -0.03596672698026973\n",
      "0.0 \t -0.03206031492458844\n",
      "0.5 \t -0.018405766218169993\n",
      "0.0 \t -0.043391923319092446\n",
      "0.0 \t -0.03683653173778346\n",
      "0.0 \t -0.04591197167615339\n",
      "-0.5 \t -0.03178147541259547\n",
      "0.0 \t -0.04163905107165945\n",
      "1.0 \t -0.035459672625146224\n",
      "0.0 \t -0.029258094822283323\n",
      "0.0 \t -0.03655128976095909\n",
      "0.5 \t -0.03644362348249637\n",
      "0.0 \t -0.03769067848145609\n",
      "0.25 \t -0.034068930186059374\n",
      "0.5 \t -0.030323991878295695\n",
      "-0.25 \t -0.04272227278471358\n",
      "0.0 \t -0.029166855525344308\n",
      "0.0 \t -0.03515561622721233\n",
      "-0.25 \t -0.035345327553047506\n",
      "0.0 \t -0.04577198584125891\n",
      "0.0 \t -0.027303710682495336\n",
      "0.0 \t -0.03144511589753376\n",
      "-0.5 \t -0.049314678874854585\n",
      "0.0 \t -0.04434660306187741\n",
      "0.0 \t -0.007888562055849486\n",
      "-0.25 \t -0.033094480445956094\n",
      "0.0 \t -0.041149108978559064\n",
      "-0.5 \t -0.029257001342758472\n",
      "-0.5 \t -0.031260286961148354\n",
      "-0.75 \t -0.03568465279715372\n",
      "0.5 \t -0.025710010621536664\n",
      "-0.5 \t -0.029388116529681266\n",
      "0.0 \t -0.04003217588640331\n",
      "0.0 \t -0.03985682997384924\n",
      "0.5 \t -0.03965791007131389\n",
      "-0.75 \t -0.03058919114650624\n",
      "0.0 \t -0.0288853916788365\n",
      "0.0 \t -0.03788621209218537\n",
      "0.0 \t -0.04658519171798222\n",
      "-0.25 \t -0.04082792373052527\n",
      "0.25 \t -0.043153541078943494\n",
      "-0.25 \t -0.042598373517044354\n",
      "0.0 \t -0.040960572710196645\n",
      "0.0 \t -0.03435699524209904\n",
      "0.25 \t -0.01429869101287979\n",
      "-0.5 \t -0.031061176832577732\n",
      "0.5 \t -0.03658240319593486\n",
      "-0.75 \t -0.045859723564247806\n",
      "0.0 \t -0.03137017857645119\n",
      "0.0 \t -0.02460418942251902\n",
      "-0.5 \t -0.036812548119291945\n",
      "0.75 \t -0.04233673711929202\n",
      "0.0 \t -0.03511634848874752\n",
      "1.0 \t -0.03763224082778032\n",
      "0.5 \t -0.011233597931279649\n",
      "-1.0 \t -0.02976656068055503\n",
      "0.0 \t -0.02915270936870038\n",
      "-0.25 \t -0.03567466642775492\n",
      "-0.5 \t -0.03339964690855657\n",
      "0.0 \t -0.03434078607892255\n",
      "0.5 \t -0.016886032294239527\n",
      "-0.25 \t -0.03946349210615777\n",
      "-0.5 \t -0.03997347818858394\n",
      "-0.5 \t -0.04017859155381434\n",
      "0.0 \t -0.037842210947675946\n",
      "0.5 \t -0.02366295713605729\n",
      "-0.5 \t -0.03293425745500689\n",
      "-0.5 \t -0.030890733891393993\n",
      "0.0 \t -0.016740717720641264\n",
      "0.5 \t -0.038952679449968886\n",
      "0.0 \t -0.039753828412326865\n",
      "-0.5 \t -0.049948187089907774\n",
      "-0.5 \t -0.03193153824447948\n",
      "0.0 \t -0.04156428919728992\n",
      "-0.5 \t -0.03477364924071741\n",
      "0.0 \t -0.01931840596065532\n",
      "0.0 \t -0.03555452131266435\n",
      "-0.5 \t -0.037813359263933206\n",
      "-0.5 \t -0.04320321499689929\n",
      "0.75 \t -0.024987971510512227\n",
      "0.0 \t -0.0295126305070722\n",
      "0.0 \t -0.0343262260694277\n",
      "-1.0 \t -0.032609321747757464\n",
      "0.0 \t -0.024929875175512182\n",
      "0.0 \t -0.039618211363878796\n",
      "0.0 \t -0.030680729014152107\n",
      "1.0 \t -0.04615693846190347\n",
      "0.0 \t -0.03295641828185825\n",
      "0.0 \t -0.044313556153792795\n",
      "0.0 \t -0.03081216878290099\n",
      "0.5 \t -0.039216956691523835\n",
      "0.5 \t -0.03841598347929469\n",
      "0.0 \t -0.039369279766367074\n",
      "-0.5 \t -0.03503341715523202\n",
      "0.5 \t -0.012090518520914854\n",
      "0.5 \t -0.035885653499156435\n",
      "-0.5 \t -0.03771098575903493\n",
      "0.0 \t -0.03983083394157883\n",
      "-0.25 \t -0.027693789603780182\n",
      "0.0 \t -0.033843954007895645\n",
      "0.0 \t -0.04165982052802959\n",
      "1.0 \t -0.0252908579009023\n",
      "0.0 \t -0.03083296176482041\n",
      "-0.5 \t -0.03845244645952158\n",
      "0.0 \t -0.02478477035671964\n",
      "-0.25 \t -0.034458758261616276\n",
      "0.0 \t -0.03634823163626545\n",
      "0.0 \t -0.042276692458941986\n",
      "0.0 \t -0.041589890152810484\n",
      "-0.25 \t -0.045266910195718144\n",
      "-0.25 \t -0.034767422377241994\n",
      "-0.25 \t -0.03341832659460554\n",
      "-0.5 \t -0.042364309094253455\n",
      "0.0 \t -0.040170562784035135\n",
      "-0.5 \t -0.037746890200265316\n",
      "0.5 \t -0.04013046930033093\n",
      "-0.5 \t -0.037224006153804653\n",
      "0.5 \t -0.030999922657889416\n",
      "-0.25 \t -0.0416397222525871\n",
      "-0.75 \t -0.03192481851162916\n",
      "-0.5 \t -0.03122291537408715\n",
      "-0.25 \t -0.04182033975288853\n",
      "-0.5 \t -0.041201852824679266\n",
      "0.0 \t -0.035646232441934024\n",
      "0.75 \t -0.04051773984293372\n",
      "-1.0 \t -0.040607542605836516\n",
      "0.0 \t -0.039999378091146044\n",
      "-1.0 \t -0.04397642910053329\n",
      "-0.25 \t -0.044054790714877626\n",
      "0.75 \t -0.02691893562073415\n",
      "-0.5 \t -0.031771839636141996\n",
      "0.0 \t -0.030564950424564776\n",
      "0.25 \t -0.036214789328968766\n",
      "0.5 \t -0.028576011670916772\n",
      "0.0 \t -0.044133213850356845\n",
      "0.0 \t -0.03084543592491895\n",
      "-0.5 \t -0.03561656006581589\n",
      "-1.0 \t -0.02979976094515832\n",
      "-0.25 \t -0.05073247357695035\n",
      "-0.5 \t -0.04107606027044615\n",
      "0.5 \t -0.04836636012670906\n",
      "-0.5 \t -0.020904074611621866\n",
      "0.25 \t -0.028729268080066546\n",
      "0.0 \t -0.03755020249325357\n",
      "0.0 \t -0.019559865515694743\n",
      "0.0 \t -0.049241015681646745\n",
      "-1.0 \t -0.0379376545156646\n",
      "0.0 \t -0.04029676391362839\n",
      "-0.25 \t -0.03919773384676208\n",
      "-1.0 \t -0.03450149688638266\n",
      "-0.25 \t -0.030979510807791034\n",
      "0.5 \t -0.02247776943737985\n",
      "0.25 \t -0.03769442946871429\n",
      "-0.25 \t -0.0381509462379759\n",
      "1.0 \t -0.040380237801960144\n",
      "-0.75 \t -0.03735234477869799\n",
      "0.75 \t -0.030334357343199142\n",
      "0.25 \t -0.038622977388083124\n",
      "-0.5 \t -0.030061184872038064\n",
      "-0.25 \t -0.026020811631500995\n",
      "0.25 \t -0.034865548259225235\n",
      "-0.75 \t -0.03587615494626854\n",
      "0.0 \t -0.03868728942768048\n",
      "0.0 \t -0.025304429233888728\n",
      "-0.75 \t -0.03114814784589215\n",
      "-0.5 \t -0.03556542254661947\n",
      "-0.25 \t -0.03712031441062677\n",
      "0.0 \t -0.041773229701462807\n",
      "0.5 \t -0.03375809411826804\n",
      "0.0 \t -0.04512432732107507\n",
      "0.0 \t -0.03171946086180863\n",
      "0.0 \t -0.03128206703544843\n",
      "-0.5 \t -0.0315677365883608\n",
      "-0.25 \t -0.03200732392903838\n",
      "0.0 \t -0.04062115706606155\n",
      "-0.5 \t -0.041240178482610516\n",
      "0.25 \t -0.02872482759090331\n",
      "-0.5 \t -0.03798834206809794\n",
      "0.5 \t -0.03272973633003409\n",
      "-0.75 \t -0.03558974839109903\n",
      "-0.5 \t -0.032133046892725024\n",
      "0.0 \t -0.025482201261364704\n",
      "-0.25 \t -0.04003689964184363\n",
      "-0.25 \t -0.0339766378237023\n",
      "1.0 \t -0.03357871395217868\n",
      "0.5 \t -0.03833971306769138\n",
      "0.0 \t -0.025304569698628706\n",
      "0.0 \t -0.03245618800747782\n",
      "0.0 \t -0.023723825732892168\n",
      "-0.75 \t -0.030141090460712932\n",
      "0.0 \t -0.02836096109368634\n",
      "0.5 \t -0.039495445158382846\n",
      "-0.5 \t -0.03669849347556958\n",
      "-0.75 \t -0.02824541623370758\n",
      "0.5 \t -0.03436683790558347\n",
      "0.0 \t -0.036838321504977935\n",
      "-0.5 \t -0.0410598112241405\n",
      "0.0 \t -0.03930639596676755\n",
      "-0.25 \t -0.03389974674807107\n",
      "0.0 \t -0.0412190226927825\n",
      "0.0 \t -0.03370226948558605\n",
      "0.0 \t -0.04804866733006367\n",
      "0.0 \t -0.043071074415659376\n",
      "0.25 \t -0.021207371310272657\n",
      "0.25 \t -0.01996854480602383\n",
      "0.25 \t -0.037525338919259896\n",
      "0.25 \t -0.008713188047022057\n",
      "0.5 \t -0.03568853097810347\n",
      "0.0 \t -0.030106324507919443\n",
      "0.0 \t -0.03767912996845728\n",
      "-0.25 \t -0.035523774081414536\n",
      "0.5 \t -0.027295934643052563\n",
      "-0.75 \t -0.03421535316727758\n",
      "-0.25 \t -0.03494492652165967\n",
      "0.0 \t -0.026545517716932435\n",
      "0.0 \t -0.033353146890323246\n",
      "0.25 \t -0.011854255230461831\n",
      "0.5 \t -0.03526701057421558\n",
      "0.25 \t -0.03333493285473688\n",
      "-0.5 \t -0.021221563310222062\n",
      "-1.0 \t -0.02961994943376399\n",
      "0.5 \t -0.031252004935925184\n",
      "0.0 \t -0.03664660824742655\n",
      "0.25 \t -0.03681848561047617\n",
      "-0.25 \t -0.03342400472139663\n",
      "0.0 \t -0.03697340911795029\n",
      "0.0 \t -0.03347074955226268\n",
      "-0.25 \t -0.037091488437522524\n",
      "0.5 \t -0.026851123063271844\n",
      "0.75 \t -0.033058203166943065\n",
      "0.5 \t -0.03256761251115197\n",
      "0.0 \t -0.03620062100627653\n",
      "-0.5 \t -0.045279321551034785\n",
      "-1.0 \t -0.03484026917239895\n",
      "0.0 \t -0.04002753107163304\n",
      "0.0 \t -0.02947685107150907\n",
      "-0.5 \t -0.03401031813882069\n",
      "0.5 \t -0.035599323547859836\n",
      "0.0 \t -0.030936916037711863\n",
      "0.0 \t -0.02474701160767724\n",
      "0.0 \t -0.038591121900921274\n",
      "-0.5 \t -0.02646863666824019\n",
      "0.0 \t -0.03558340624547956\n",
      "0.25 \t -0.028598455764045225\n",
      "-0.5 \t -0.035888018014154456\n",
      "1.0 \t -0.038450452970616604\n",
      "-0.5 \t -0.029662769338932603\n",
      "0.25 \t -0.0386792567369764\n",
      "0.0 \t -0.03850623734089969\n",
      "0.0 \t -0.035120606593725234\n",
      "0.5 \t -0.030313342922488374\n",
      "0.0 \t -0.03818358102611019\n",
      "-0.25 \t -0.04543909819272999\n",
      "0.0 \t -0.041034043340572084\n",
      "0.0 \t -0.036711249241963506\n",
      "0.75 \t -0.0325704104836253\n",
      "0.0 \t -0.03518048613478195\n",
      "-1.0 \t -0.04421635637109793\n",
      "0.0 \t -0.0355420894512811\n",
      "0.25 \t -0.03569252029271055\n",
      "0.0 \t -0.038359306638065443\n",
      "0.0 \t -0.03629112518556689\n",
      "-0.25 \t -0.043134140147255785\n",
      "0.0 \t -0.03432248880540657\n",
      "0.0 \t -0.03900663288628133\n",
      "0.5 \t -0.03727452217751477\n",
      "0.0 \t -0.03205861721740455\n",
      "0.0 \t -0.03163224005885144\n",
      "-1.0 \t -0.03651049855716542\n",
      "0.0 \t -0.0361327511461499\n",
      "0.0 \t -0.03753100633936153\n",
      "0.25 \t -0.029069824103117148\n",
      "0.75 \t -0.02802977258769622\n",
      "0.5 \t -0.023387696102368093\n",
      "-0.25 \t -0.031596789805789754\n",
      "0.0 \t -0.025588613996808313\n",
      "-0.5 \t -0.027810515551391864\n",
      "0.5 \t -0.032963480541177356\n",
      "0.0 \t -0.03336683621858555\n",
      "0.0 \t -0.020731624986338657\n",
      "0.0 \t -0.042142936051881894\n",
      "-0.25 \t -0.02553721409667116\n",
      "0.0 \t -0.03410348321872669\n",
      "0.5 \t -0.022724725639402123\n",
      "0.0 \t -0.03735043377505325\n",
      "-0.75 \t -0.03747275672369676\n",
      "0.25 \t -0.03858735945430422\n",
      "0.0 \t -0.037185910984307576\n",
      "0.75 \t -0.026355729259181754\n",
      "0.0 \t -0.03804192311881637\n",
      "-0.5 \t -0.043463753542013255\n"
     ]
    }
   ],
   "source": [
    "for i in range(len(y_test)):\n",
    "    print(y_test[i], '\\t', y_pred[i])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "06b93b88",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.43908993782073796"
      ]
     },
     "execution_count": 51,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ridge = linear_model.Ridge(alpha=10)\n",
    "ridge.fit(X_train, y_train)\n",
    "y_pred = ridge.predict(X_test)\n",
    "np.sqrt(mean_squared_error(y_test, y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 178,
   "id": "52c45e40",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-1.0 \t -0.07622657016206058\n",
      "0.5 \t 0.23385754537397396\n",
      "0.25 \t -0.3259443551562532\n",
      "0.25 \t 0.005254937110673999\n",
      "0.0 \t 0.011024963905050943\n",
      "0.0 \t -0.1265029689677056\n",
      "0.0 \t -0.12341728673240017\n",
      "0.5 \t -0.1578357453837633\n",
      "0.0 \t 0.00899804854313034\n",
      "0.0 \t -0.10571387424092257\n",
      "0.0 \t 0.3612146668205599\n",
      "-1.0 \t -0.15262880367201365\n",
      "-1.0 \t -0.1972827070107659\n",
      "-0.5 \t -0.15774905263726113\n",
      "-1.0 \t -0.31316898675076593\n",
      "0.0 \t -0.1751757723914762\n",
      "-0.5 \t -0.3131587978442374\n",
      "0.0 \t -0.21518862387139748\n",
      "-0.5 \t -0.11115337627521504\n",
      "-1.0 \t 0.046634901561095635\n",
      "-0.25 \t -0.7104028333788888\n",
      "0.5 \t 0.25449757145979385\n",
      "0.0 \t -0.21296936579423847\n",
      "-0.25 \t 0.16283473092382056\n",
      "-0.25 \t -0.1835590942716812\n",
      "-0.25 \t -0.07600585494342786\n",
      "0.25 \t 0.33163753576609484\n",
      "0.25 \t 0.3136609652706106\n",
      "-0.5 \t 0.35449104382498653\n",
      "0.25 \t -0.09740304466096371\n",
      "-0.5 \t -0.055500487369619544\n",
      "0.0 \t -0.28377856524363204\n",
      "0.0 \t -0.023954258342202342\n",
      "0.25 \t -0.914825321050503\n",
      "1.0 \t 0.3387436714857678\n",
      "-0.5 \t 0.30604497764726407\n"
     ]
    }
   ],
   "source": [
    "for i in range(len(y_test)):\n",
    "    print(y_test[i], '\\t', y_pred[i])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "849c9b98",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.45126367384251553"
      ]
     },
     "execution_count": 52,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "reg = linear_model.LinearRegression()\n",
    "reg.fit(X_train, y_train)\n",
    "y_pred = reg.predict(X_test)\n",
    "np.sqrt(mean_squared_error(y_test, y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "86002796",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 212,
   "id": "895f796d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.4763697692583421"
      ]
     },
     "execution_count": 212,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "xgb = xg.XGBRegressor(n_estimators=100, max_depth=4, learning_rate=0.05)\n",
    "xgb.fit(X_train, y_train)\n",
    "y_pred = xgb.predict(X_test)\n",
    "np.sqrt(mean_squared_error(y_test, y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 213,
   "id": "ebb8ff7b",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-1.0 \t -0.15857185\n",
      "0.5 \t 0.63727\n",
      "0.25 \t -0.13212693\n",
      "0.25 \t -0.032253362\n",
      "0.0 \t 0.36850685\n",
      "0.0 \t -0.15306991\n",
      "0.0 \t -0.13987792\n",
      "0.5 \t -0.4351816\n",
      "0.0 \t -0.1494668\n",
      "0.0 \t -0.00982944\n",
      "0.0 \t 0.16662015\n",
      "-1.0 \t -0.26590288\n",
      "-1.0 \t -0.19639434\n",
      "-0.5 \t -0.39096442\n",
      "-1.0 \t -0.16072357\n",
      "0.0 \t -0.3075524\n",
      "-0.5 \t -0.059832126\n",
      "0.0 \t -0.11484269\n",
      "-0.5 \t -0.4233838\n",
      "-1.0 \t 0.13115318\n",
      "-0.25 \t -0.4784529\n",
      "0.5 \t 0.39380956\n",
      "0.0 \t -0.40912884\n",
      "-0.25 \t 0.0021641864\n",
      "-0.25 \t -0.10086639\n",
      "-0.25 \t 0.05441005\n",
      "0.25 \t 0.5123986\n",
      "0.25 \t -0.017556492\n",
      "-0.5 \t 0.028030597\n",
      "0.25 \t -0.1350653\n",
      "-0.5 \t -0.004816406\n",
      "0.0 \t -0.13254924\n",
      "0.0 \t -0.0077196714\n",
      "0.25 \t -0.17632467\n",
      "1.0 \t 0.390759\n",
      "-0.5 \t 0.41259316\n"
     ]
    }
   ],
   "source": [
    "for i in range(len(y_test)):\n",
    "    print(y_test[i], '\\t', y_pred[i])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "id": "be1c40b4",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.007401694259806469"
      ]
     },
     "execution_count": 57,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.std(y_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "id": "e8abdbd8",
   "metadata": {},
   "outputs": [],
   "source": [
    "def convert_to_classifier(targets, preds, threshold=1/3):\n",
    "    new_targets = [x/abs(x) if x!=0 else 0. for x in targets]\n",
    "    new_preds = [x/abs(x) if abs(x)>threshold else 0. for x in preds]\n",
    "    return new_targets, new_preds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "id": "5941f1cc",
   "metadata": {},
   "outputs": [],
   "source": [
    "new_y_test, new_y_pred = convert_to_classifier(y_test, y_pred, threshold=0.004)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "id": "300c84f4",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.3485342019543974"
      ]
     },
     "execution_count": 59,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.mean([int(new_y_test[i]==new_y_pred[i]) for i in range(len(new_y_test))])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4c79871d",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ce60949e",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "32f6674b",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "38337b64",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "c2bfc41a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(array([1.433e+03, 4.580e+02, 1.010e+02, 2.700e+01, 1.400e+01, 7.000e+00,\n",
       "        2.000e+00, 0.000e+00, 1.000e+00, 1.000e+00]),\n",
       " array([  2. ,  74.9, 147.8, 220.7, 293.6, 366.5, 439.4, 512.3, 585.2,\n",
       "        658.1, 731. ]),\n",
       " <BarContainer object of 10 artists>)"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.hist([len(x.split()) for x in clean_df['clean_comment']])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5d4a1ddc",
   "metadata": {},
   "source": [
    "## New model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "ee3facba",
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import AutoModelForSequenceClassification, AutoTokenizer, AutoModel\n",
    "from transformers import BertTokenizer, BertModel, BertForSequenceClassification"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "d6b8eae5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# model_name = 'bert-base-cased'\n",
    "# model_name = \"google/muril-base-cased\"\n",
    "model_name = \"meedan/indian-sbert\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "7c9cfc60",
   "metadata": {},
   "outputs": [],
   "source": [
    "tokenizer = AutoTokenizer.from_pretrained(model_name)\n",
    "# tokenizer = BertTokenizer.from_pretrained(model_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "c25061f8",
   "metadata": {},
   "outputs": [],
   "source": [
    "class NewModel(nn.Module):\n",
    "\n",
    "    def __init__(self, model_name, dropout=0.4):\n",
    "\n",
    "        super(NewModel, self).__init__()\n",
    "\n",
    "        self.bert = AutoModel.from_pretrained(model_name)\n",
    "        self.dropout = nn.Dropout(dropout)\n",
    "        self.l1 = nn.Linear(768, 400)\n",
    "        self.l2 = nn.Linear(400, 200)\n",
    "        self.l3 = nn.Linear(200, 1)\n",
    "        self.relu = nn.ReLU()\n",
    "        self.tanh = nn.Tanh()\n",
    "        \n",
    "        modules = [self.bert.embeddings, *self.bert.encoder.layer[:-3]]  # freeze all but last few\n",
    "#         modules = [self.bert.embeddings, *self.bert.encoder.layer]  # freeze all\n",
    "        for module in modules:\n",
    "            for param in module.parameters():\n",
    "                param.requires_grad = False\n",
    "\n",
    "    def forward(self, input_id, mask):\n",
    "\n",
    "        b = self.bert(input_ids= input_id, attention_mask=mask)\n",
    "        x = b[1]  # pooler output\n",
    "        x = self.dropout(x)\n",
    "        x = self.l1(x)\n",
    "        x = self.relu(x)\n",
    "        x = self.dropout(x)\n",
    "        x = self.l2(x)\n",
    "        x = self.relu(x)\n",
    "        x = self.dropout(x)\n",
    "        x = self.l3(x)\n",
    "        x = self.tanh(x)\n",
    "\n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "81179bf7",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of the model checkpoint at meedan/indian-sbert were not used when initializing XLMRobertaForSequenceClassification: ['pooler.dense.bias', 'pooler.dense.weight']\n",
      "- This IS expected if you are initializing XLMRobertaForSequenceClassification from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing XLMRobertaForSequenceClassification from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
      "Some weights of XLMRobertaForSequenceClassification were not initialized from the model checkpoint at meedan/indian-sbert and are newly initialized: ['classifier.dense.bias', 'classifier.out_proj.bias', 'classifier.out_proj.weight', 'classifier.dense.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    }
   ],
   "source": [
    "model = AutoModelForSequenceClassification.from_pretrained(model_name, num_labels=1).to(device)\n",
    "# model = BertForSequenceClassification.from_pretrained(model_name, num_labels=1).to(device)\n",
    "# model = NewModel(model_name).to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "04db20f0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# modules = [model.embeddings, *model.encoder.layer[:-3]]\n",
    "modules = [*model.roberta.encoder.layer[3:9]]\n",
    "for module in modules:\n",
    "    for param in module.parameters():\n",
    "        param.requires_grad = False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "69fe7f89",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(clean_df['clean_comment'], clean_df['target'], test_size = 0.2, random_state = 123)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "4c42e97e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([ 0.0849, -0.0412,  0.0353,  0.0953, -0.0238], device='cuda:0')\n"
     ]
    }
   ],
   "source": [
    "with torch.no_grad():\n",
    "    temp = tokenizer(list(X_train[:5]), padding='max_length', max_length = 150, truncation=True, return_tensors=\"pt\")\n",
    "    temp_pred = model(temp['input_ids'].to(device), temp['attention_mask'].to(device))\n",
    "    print(temp_pred[0].squeeze(1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "cabadb2a",
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_loop(model, X_train, y_train, num_epochs, batch_size, lr=0.0001, max_length=150):\n",
    "    model.train()\n",
    "    criterion = nn.MSELoss().to(device)\n",
    "    optimizer = torch.optim.Adam(model.parameters(), lr=lr)\n",
    "    losses = []\n",
    "    \n",
    "#     inputs = train_df.copy()\n",
    "    for _ in range(num_epochs):\n",
    "#         inputs = inputs.sample(frac=1).reset_index(drop=True)  # shuffle order\n",
    "        for i in range(int(np.ceil(len(X_train)/batch_size))):\n",
    "            model.zero_grad()\n",
    "            \n",
    "            # getting inputs\n",
    "            batch = list(X_train[i:i+batch_size])\n",
    "            targets = torch.tensor(list(y_train[i:i+batch_size])).to(device)\n",
    "            try:\n",
    "                temp = tokenizer(batch, padding='max_length', max_length = max_length, truncation=True, return_tensors=\"pt\")\n",
    "            except ValueError:\n",
    "                print(\"Error with following batch, skipped:\")\n",
    "                print(len(batch))\n",
    "                print(batch)\n",
    "                print()\n",
    "                continue\n",
    "            input_ids, attention_mask = temp['input_ids'].to(device), temp['attention_mask'].to(device)\n",
    "            \n",
    "            # training model\n",
    "            preds = model(input_ids, attention_mask)[0].squeeze(1)\n",
    "            batch_loss = criterion(preds, targets)\n",
    "            batch_loss.backward()\n",
    "            optimizer.step()\n",
    "            \n",
    "            losses.append(batch_loss.item())\n",
    "            \n",
    "            # excplicitly delete variables in cuda\n",
    "            del batch, targets, temp, input_ids, attention_mask, preds, batch_loss\n",
    "    return model, losses"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "ec931831",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "|===========================================================================|\n",
      "|                  PyTorch CUDA memory summary, device ID 0                 |\n",
      "|---------------------------------------------------------------------------|\n",
      "|            CUDA OOMs: 0            |        cudaMalloc retries: 0         |\n",
      "|===========================================================================|\n",
      "|        Metric         | Cur Usage  | Peak Usage | Tot Alloc  | Tot Freed  |\n",
      "|---------------------------------------------------------------------------|\n",
      "| Allocated memory      |    1060 MB |    1086 MB |    2757 MB |    1696 MB |\n",
      "|       from large pool |    1060 MB |    1086 MB |    2756 MB |    1696 MB |\n",
      "|       from small pool |       0 MB |       0 MB |       0 MB |       0 MB |\n",
      "|---------------------------------------------------------------------------|\n",
      "| Active memory         |    1060 MB |    1086 MB |    2757 MB |    1696 MB |\n",
      "|       from large pool |    1060 MB |    1086 MB |    2756 MB |    1696 MB |\n",
      "|       from small pool |       0 MB |       0 MB |       0 MB |       0 MB |\n",
      "|---------------------------------------------------------------------------|\n",
      "| GPU reserved memory   |    1116 MB |    1136 MB |    1136 MB |   20480 KB |\n",
      "|       from large pool |    1114 MB |    1134 MB |    1134 MB |   20480 KB |\n",
      "|       from small pool |       2 MB |       2 MB |       2 MB |       0 KB |\n",
      "|---------------------------------------------------------------------------|\n",
      "| Non-releasable memory |   56595 KB |   74583 KB |    2484 MB |    2429 MB |\n",
      "|       from large pool |   55040 KB |   73040 KB |    2481 MB |    2428 MB |\n",
      "|       from small pool |    1555 KB |    2045 KB |       2 MB |       0 MB |\n",
      "|---------------------------------------------------------------------------|\n",
      "| Allocations           |     204    |     216    |     850    |     646    |\n",
      "|       from large pool |      75    |      84    |     565    |     490    |\n",
      "|       from small pool |     129    |     136    |     285    |     156    |\n",
      "|---------------------------------------------------------------------------|\n",
      "| Active allocs         |     204    |     216    |     850    |     646    |\n",
      "|       from large pool |      75    |      84    |     565    |     490    |\n",
      "|       from small pool |     129    |     136    |     285    |     156    |\n",
      "|---------------------------------------------------------------------------|\n",
      "| GPU reserved segments |      21    |      22    |      22    |       1    |\n",
      "|       from large pool |      20    |      21    |      21    |       1    |\n",
      "|       from small pool |       1    |       1    |       1    |       0    |\n",
      "|---------------------------------------------------------------------------|\n",
      "| Non-releasable allocs |      21    |      25    |     334    |     313    |\n",
      "|       from large pool |      19    |      23    |     258    |     239    |\n",
      "|       from small pool |       2    |       5    |      76    |      74    |\n",
      "|---------------------------------------------------------------------------|\n",
      "| Oversize allocations  |       0    |       0    |       0    |       0    |\n",
      "|---------------------------------------------------------------------------|\n",
      "| Oversize GPU segments |       0    |       0    |       0    |       0    |\n",
      "|===========================================================================|\n",
      "\n"
     ]
    }
   ],
   "source": [
    "torch.cuda.empty_cache()\n",
    "print(torch.cuda.memory_summary(device=None, abbreviated=False))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "5670a20e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "XLMRobertaForSequenceClassification(\n",
       "  (roberta): RobertaModel(\n",
       "    (embeddings): RobertaEmbeddings(\n",
       "      (word_embeddings): Embedding(250002, 768, padding_idx=1)\n",
       "      (position_embeddings): Embedding(514, 768, padding_idx=1)\n",
       "      (token_type_embeddings): Embedding(1, 768)\n",
       "      (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "      (dropout): Dropout(p=0.1, inplace=False)\n",
       "    )\n",
       "    (encoder): RobertaEncoder(\n",
       "      (layer): ModuleList(\n",
       "        (0): RobertaLayer(\n",
       "          (attention): RobertaAttention(\n",
       "            (self): RobertaSelfAttention(\n",
       "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (output): RobertaSelfOutput(\n",
       "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (intermediate): RobertaIntermediate(\n",
       "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "            (intermediate_act_fn): GELUActivation()\n",
       "          )\n",
       "          (output): RobertaOutput(\n",
       "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (1): RobertaLayer(\n",
       "          (attention): RobertaAttention(\n",
       "            (self): RobertaSelfAttention(\n",
       "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (output): RobertaSelfOutput(\n",
       "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (intermediate): RobertaIntermediate(\n",
       "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "            (intermediate_act_fn): GELUActivation()\n",
       "          )\n",
       "          (output): RobertaOutput(\n",
       "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (2): RobertaLayer(\n",
       "          (attention): RobertaAttention(\n",
       "            (self): RobertaSelfAttention(\n",
       "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (output): RobertaSelfOutput(\n",
       "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (intermediate): RobertaIntermediate(\n",
       "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "            (intermediate_act_fn): GELUActivation()\n",
       "          )\n",
       "          (output): RobertaOutput(\n",
       "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (3): RobertaLayer(\n",
       "          (attention): RobertaAttention(\n",
       "            (self): RobertaSelfAttention(\n",
       "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (output): RobertaSelfOutput(\n",
       "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (intermediate): RobertaIntermediate(\n",
       "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "            (intermediate_act_fn): GELUActivation()\n",
       "          )\n",
       "          (output): RobertaOutput(\n",
       "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (4): RobertaLayer(\n",
       "          (attention): RobertaAttention(\n",
       "            (self): RobertaSelfAttention(\n",
       "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (output): RobertaSelfOutput(\n",
       "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (intermediate): RobertaIntermediate(\n",
       "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "            (intermediate_act_fn): GELUActivation()\n",
       "          )\n",
       "          (output): RobertaOutput(\n",
       "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (5): RobertaLayer(\n",
       "          (attention): RobertaAttention(\n",
       "            (self): RobertaSelfAttention(\n",
       "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (output): RobertaSelfOutput(\n",
       "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (intermediate): RobertaIntermediate(\n",
       "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "            (intermediate_act_fn): GELUActivation()\n",
       "          )\n",
       "          (output): RobertaOutput(\n",
       "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (6): RobertaLayer(\n",
       "          (attention): RobertaAttention(\n",
       "            (self): RobertaSelfAttention(\n",
       "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (output): RobertaSelfOutput(\n",
       "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (intermediate): RobertaIntermediate(\n",
       "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "            (intermediate_act_fn): GELUActivation()\n",
       "          )\n",
       "          (output): RobertaOutput(\n",
       "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (7): RobertaLayer(\n",
       "          (attention): RobertaAttention(\n",
       "            (self): RobertaSelfAttention(\n",
       "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (output): RobertaSelfOutput(\n",
       "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (intermediate): RobertaIntermediate(\n",
       "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "            (intermediate_act_fn): GELUActivation()\n",
       "          )\n",
       "          (output): RobertaOutput(\n",
       "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (8): RobertaLayer(\n",
       "          (attention): RobertaAttention(\n",
       "            (self): RobertaSelfAttention(\n",
       "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (output): RobertaSelfOutput(\n",
       "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (intermediate): RobertaIntermediate(\n",
       "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "            (intermediate_act_fn): GELUActivation()\n",
       "          )\n",
       "          (output): RobertaOutput(\n",
       "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (9): RobertaLayer(\n",
       "          (attention): RobertaAttention(\n",
       "            (self): RobertaSelfAttention(\n",
       "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (output): RobertaSelfOutput(\n",
       "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (intermediate): RobertaIntermediate(\n",
       "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "            (intermediate_act_fn): GELUActivation()\n",
       "          )\n",
       "          (output): RobertaOutput(\n",
       "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (10): RobertaLayer(\n",
       "          (attention): RobertaAttention(\n",
       "            (self): RobertaSelfAttention(\n",
       "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (output): RobertaSelfOutput(\n",
       "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (intermediate): RobertaIntermediate(\n",
       "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "            (intermediate_act_fn): GELUActivation()\n",
       "          )\n",
       "          (output): RobertaOutput(\n",
       "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (11): RobertaLayer(\n",
       "          (attention): RobertaAttention(\n",
       "            (self): RobertaSelfAttention(\n",
       "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (output): RobertaSelfOutput(\n",
       "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (intermediate): RobertaIntermediate(\n",
       "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "            (intermediate_act_fn): GELUActivation()\n",
       "          )\n",
       "          (output): RobertaOutput(\n",
       "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "      )\n",
       "    )\n",
       "  )\n",
       "  (classifier): RobertaClassificationHead(\n",
       "    (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "    (dropout): Dropout(p=0.1, inplace=False)\n",
       "    (out_proj): Linear(in_features=768, out_features=1, bias=True)\n",
       "  )\n",
       ")"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "e5d856a7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Wall time: 7min 19s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "model, losses = train_loop(model, X_train, y_train, num_epochs=5, batch_size=2, lr=1e-5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "ca7f9b46",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[<matplotlib.lines.Line2D at 0x162b7fc8f40>]"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "k = len(losses)//(5*5)\n",
    "moving_avg = [np.mean(losses[max(0, i-k):i]) for i in range(1, len(losses)+1)]\n",
    "plt.plot([i*5/len(moving_avg) for i in range(len(moving_avg))], moving_avg)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "1a336cf7",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.2527851386972469"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.mean(losses[-len(losses)//5:])**0.5  # avg rmse for last epoch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "d28dd23b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.6623370055217841"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "1 - np.mean(losses[-len(losses)//5:])/np.mean(clean_df['target']**2)  # approx r2 for last epoch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "754dab5d",
   "metadata": {},
   "outputs": [],
   "source": [
    "def convert_to_classifier(targets, preds, threshold=1/3):\n",
    "    new_targets = [x/abs(x) if x!=0 else 0. for x in targets]\n",
    "    new_preds = [x/abs(x) if abs(x)>threshold else 0. for x in preds]\n",
    "    return new_targets, new_preds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "8ce0490c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1635, 1635)"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# getting train preds\n",
    "with torch.no_grad():\n",
    "    model.eval()\n",
    "    y_train_pred = []\n",
    "    batch_size = 16\n",
    "    for i in range(0, len(X_train), batch_size):\n",
    "        temp = tokenizer(list(X_train[i:i+batch_size]), padding='max_length', max_length = 150, truncation=True, return_tensors=\"pt\")\n",
    "        y_train_pred.extend(model(temp['input_ids'].to(device), temp['attention_mask'].to(device))[0].squeeze(1).cpu().detach().numpy().tolist())\n",
    "len(y_train), len(y_train_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "4f634a3e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.40264069390569773"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.sqrt(mean_squared_error(y_train, y_train_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "b72b4198",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.15024849740311097"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "r2_score(y_train, y_train_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "2112e39d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.6470948012232416"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "new_y_test, new_y_pred = convert_to_classifier(y_train, y_train_pred, threshold=0.27)\n",
    "np.mean([int(new_y_test[i]==new_y_pred[i]) for i in range(len(new_y_test))])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "18de6403",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.1\n",
      "0.11\n",
      "0.12\n",
      "0.13\n",
      "0.14\n",
      "0.15000000000000002\n",
      "0.16000000000000003\n",
      "0.17000000000000004\n",
      "0.18000000000000005\n",
      "0.19000000000000006\n",
      "0.20000000000000007\n",
      "0.22000000000000008\n",
      "0.2300000000000001\n",
      "0.2400000000000001\n",
      "0.2500000000000001\n",
      "0.27000000000000013\n"
     ]
    }
   ],
   "source": [
    "# optimizing threshold\n",
    "m = 0\n",
    "threshold = 0.1\n",
    "for _ in range(30):\n",
    "    t1, t2 = convert_to_classifier(y_train, y_train_pred, threshold=threshold)\n",
    "    t3 = np.mean([int(t1[i]==t2[i]) for i in range(len(t1))])\n",
    "    if t3>m:\n",
    "        m = t3\n",
    "        print(threshold)\n",
    "    threshold += 0.01"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "49c9d1cf",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(409, 409)"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# getting test preds\n",
    "with torch.no_grad():\n",
    "    model.eval()\n",
    "    y_pred = []\n",
    "    batch_size = 16\n",
    "    for i in range(0, len(X_test), batch_size):\n",
    "        temp = tokenizer(list(X_test[i:i+batch_size]), padding='max_length', max_length = 150, truncation=True, return_tensors=\"pt\")\n",
    "        y_pred.extend(model(temp['input_ids'].to(device), temp['attention_mask'].to(device))[0].squeeze(1).cpu().detach().numpy().tolist())\n",
    "len(y_test), len(y_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "5d0c0ab9",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.5125990937947812"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.sqrt(mean_squared_error(y_test, y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "b94a42e0",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "-0.5001691223246403"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "r2_score(y_test, y_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "4791779e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.36865362207745156"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.std(y_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "6f395d97",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.43031784841075793"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "new_y_test, new_y_pred = convert_to_classifier(y_test, y_pred, threshold=0.27)\n",
    "np.mean([int(new_y_test[i]==new_y_pred[i]) for i in range(len(new_y_test))])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "1f7c1853",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.0 \t -0.05775241181254387\n",
      "-0.25 \t -0.2827375829219818\n",
      "0.0 \t 0.4172804355621338\n",
      "-0.5 \t 0.04910194128751755\n",
      "0.0 \t -0.24904459714889526\n",
      "-0.25 \t 0.03726428374648094\n",
      "0.0 \t 0.078445665538311\n",
      "-0.75 \t -0.37813612818717957\n",
      "0.0 \t -0.03771493211388588\n",
      "0.5 \t 0.175527423620224\n",
      "0.5 \t -1.0917136669158936\n",
      "-0.5 \t -0.9227941036224365\n",
      "0.25 \t -0.2184683084487915\n",
      "0.25 \t 0.08479731529951096\n",
      "-0.25 \t 0.06718819588422775\n",
      "0.0 \t 0.10858087986707687\n",
      "0.25 \t 0.7695704102516174\n",
      "0.0 \t -0.18646325170993805\n",
      "0.0 \t 0.2295352816581726\n",
      "0.75 \t -0.08567924797534943\n",
      "1.0 \t -0.3513842225074768\n",
      "0.0 \t 0.056746114045381546\n",
      "0.5 \t 0.0017267715884372592\n",
      "-1.0 \t -0.5516799688339233\n",
      "0.5 \t 0.26662540435791016\n",
      "0.0 \t 0.16919519007205963\n",
      "1.0 \t 0.1823510229587555\n",
      "0.0 \t 0.5290142893791199\n",
      "0.5 \t -0.37900030612945557\n",
      "-1.0 \t -0.3806743919849396\n",
      "0.25 \t 0.7879431247711182\n",
      "0.75 \t -0.05247288569808006\n",
      "0.5 \t 0.3342251479625702\n",
      "0.5 \t -0.07419543713331223\n",
      "-0.25 \t -0.313406378030777\n",
      "-0.5 \t -0.1692313849925995\n",
      "0.5 \t 0.2744162082672119\n",
      "1.0 \t 0.3490307927131653\n",
      "-0.5 \t 0.13267840445041656\n",
      "0.0 \t -0.40850135684013367\n",
      "-0.5 \t -0.1509884148836136\n",
      "0.0 \t -0.006440667901188135\n",
      "-0.25 \t -0.032433733344078064\n",
      "0.25 \t -0.15220673382282257\n",
      "0.0 \t 0.004021254368126392\n",
      "-0.5 \t -0.43342965841293335\n",
      "-0.25 \t -0.09168586879968643\n",
      "0.0 \t -0.7592763304710388\n",
      "0.0 \t 0.005398882552981377\n",
      "0.0 \t 0.35948386788368225\n",
      "0.0 \t -0.40656912326812744\n",
      "0.0 \t -0.3064633011817932\n",
      "0.25 \t 0.3095172941684723\n",
      "0.0 \t -0.3852584958076477\n",
      "0.0 \t 0.011204450391232967\n",
      "-0.5 \t -0.3270508646965027\n",
      "-1.0 \t 0.003889147425070405\n",
      "0.0 \t -0.5743050575256348\n",
      "0.0 \t -0.5261633992195129\n",
      "0.5 \t 0.1048860251903534\n",
      "0.25 \t 0.14530512690544128\n",
      "0.0 \t -0.05950378254055977\n",
      "0.5 \t -0.4949451982975006\n",
      "-1.0 \t -0.09455215185880661\n",
      "-0.5 \t 0.5981769561767578\n",
      "0.0 \t 0.24739199876785278\n",
      "0.0 \t 0.17395338416099548\n",
      "0.0 \t -0.17575441300868988\n",
      "0.0 \t 0.07230909168720245\n",
      "0.5 \t 0.4913235306739807\n",
      "0.25 \t 0.24381878972053528\n",
      "0.0 \t -0.26929959654808044\n",
      "0.25 \t 0.21235109865665436\n",
      "0.0 \t 0.0347234383225441\n",
      "-0.5 \t 0.22770509123802185\n",
      "-0.5 \t 0.26996874809265137\n",
      "0.0 \t 0.0035697317216545343\n",
      "-0.25 \t -0.6896331310272217\n",
      "0.0 \t -0.2464941293001175\n",
      "0.0 \t 0.47320955991744995\n",
      "0.0 \t 0.31768888235092163\n",
      "0.25 \t 0.23743443191051483\n",
      "0.5 \t 0.029290074482560158\n",
      "-0.5 \t 0.24625322222709656\n",
      "1.0 \t -0.0780186876654625\n",
      "0.0 \t 0.032257866114377975\n",
      "-0.5 \t -0.2424839287996292\n",
      "0.25 \t 0.05200628936290741\n",
      "-0.75 \t 0.14062552154064178\n",
      "0.0 \t -0.4311424791812897\n",
      "-0.5 \t -0.2596239149570465\n",
      "-0.75 \t -0.3793063759803772\n",
      "-0.25 \t -0.24549977481365204\n",
      "-0.75 \t -0.2648278772830963\n",
      "-0.75 \t 0.19521625339984894\n",
      "0.0 \t 0.40827226638793945\n",
      "0.0 \t 0.17644602060317993\n",
      "-0.5 \t 0.011050551198422909\n",
      "0.0 \t -0.8222104907035828\n",
      "0.0 \t 0.022855577990412712\n",
      "0.25 \t -0.6213898062705994\n",
      "-0.5 \t -0.13026010990142822\n",
      "-0.75 \t -0.6055048704147339\n",
      "-0.5 \t 0.043528106063604355\n",
      "0.75 \t 0.36972329020500183\n",
      "0.0 \t 0.08814755827188492\n",
      "-1.0 \t -0.9070355296134949\n",
      "-0.5 \t -0.44171836972236633\n",
      "0.0 \t 0.0389435701072216\n",
      "0.25 \t -1.1884574890136719\n",
      "-0.25 \t -0.5756523013114929\n",
      "-0.25 \t -0.115399569272995\n",
      "0.0 \t 0.07291484624147415\n",
      "0.0 \t -0.06993703544139862\n",
      "-0.5 \t 0.4905617833137512\n",
      "0.25 \t 0.15779650211334229\n",
      "0.0 \t 0.3131696581840515\n",
      "0.25 \t -0.23803308606147766\n",
      "0.75 \t -0.35801783204078674\n",
      "-1.0 \t -0.3939048945903778\n",
      "0.0 \t 0.8366247415542603\n",
      "0.0 \t 0.1315915733575821\n",
      "0.0 \t 0.23925919830799103\n",
      "-0.25 \t -0.131358802318573\n",
      "-0.25 \t 0.10422520339488983\n",
      "-0.5 \t 0.30487319827079773\n",
      "-1.0 \t -0.8025975227355957\n",
      "0.25 \t -0.2559936046600342\n",
      "0.5 \t 0.3003051280975342\n",
      "0.25 \t 0.13570661842823029\n",
      "-0.25 \t -0.3639945685863495\n",
      "-0.5 \t -0.13141347467899323\n",
      "0.0 \t 0.12874330580234528\n",
      "0.5 \t -0.07602644711732864\n",
      "0.0 \t 0.683501660823822\n",
      "-0.5 \t -0.23076872527599335\n",
      "-0.25 \t 0.08951731026172638\n",
      "-0.75 \t 0.3949216604232788\n",
      "0.0 \t 0.568632185459137\n",
      "-0.5 \t 0.35944318771362305\n",
      "-0.5 \t 0.6287962794303894\n",
      "-1.0 \t -0.44303929805755615\n",
      "0.0 \t 0.12857356667518616\n",
      "-0.25 \t -0.5543953776359558\n",
      "0.5 \t 0.26057496666908264\n",
      "0.0 \t -1.0415709018707275\n",
      "-0.5 \t -0.5734177827835083\n",
      "0.0 \t 0.03756929561495781\n",
      "0.25 \t 0.046291887760162354\n",
      "0.5 \t -0.3853452205657959\n",
      "0.0 \t -0.25242677330970764\n",
      "-0.25 \t -0.11318190395832062\n",
      "0.25 \t -0.5154814124107361\n",
      "0.0 \t 0.030255837365984917\n",
      "0.0 \t -0.6816889643669128\n",
      "-0.5 \t 0.10856147110462189\n",
      "0.0 \t 0.6851672530174255\n",
      "-0.5 \t -0.08083603531122208\n",
      "0.25 \t 0.23663297295570374\n",
      "0.0 \t 0.44877728819847107\n",
      "-0.5 \t -0.534834623336792\n",
      "0.0 \t -0.40507304668426514\n",
      "0.0 \t -0.34110426902770996\n",
      "-0.25 \t 0.40317484736442566\n",
      "-0.25 \t -0.6529723405838013\n",
      "0.0 \t -0.5182352662086487\n",
      "0.0 \t -0.49131935834884644\n",
      "0.0 \t 0.17196638882160187\n",
      "0.5 \t 0.17530418932437897\n",
      "1.0 \t 0.5658299326896667\n",
      "0.0 \t -0.5190203189849854\n",
      "0.25 \t -0.13540692627429962\n",
      "0.0 \t -0.4091487526893616\n",
      "0.5 \t -0.06788606941699982\n",
      "0.0 \t -0.11494402587413788\n",
      "0.0 \t 0.15768253803253174\n",
      "0.5 \t 0.13496945798397064\n",
      "-0.5 \t -0.22369743883609772\n",
      "0.0 \t -0.2137136310338974\n",
      "0.0 \t 0.14196868240833282\n",
      "0.0 \t 0.028296390548348427\n",
      "0.0 \t 0.33468514680862427\n",
      "0.0 \t 0.027337323874235153\n",
      "0.0 \t 0.4672061800956726\n",
      "0.5 \t -0.21969307959079742\n",
      "0.0 \t -0.046408552676439285\n",
      "0.0 \t -0.18426993489265442\n",
      "-0.5 \t -0.41695836186408997\n",
      "0.5 \t 0.2158990055322647\n",
      "0.0 \t -0.06623518466949463\n",
      "-0.25 \t -0.21611899137496948\n",
      "0.0 \t 0.03276713564991951\n",
      "-0.25 \t 0.31919151544570923\n",
      "0.0 \t -0.2747791111469269\n",
      "0.0 \t 0.22371108829975128\n",
      "-0.5 \t -0.6180135607719421\n",
      "-0.25 \t 0.09366964548826218\n",
      "0.0 \t -0.09359268844127655\n",
      "0.0 \t -0.22132490575313568\n",
      "0.5 \t -0.10387030243873596\n",
      "-1.0 \t 0.09211378544569016\n",
      "0.0 \t -0.4721047282218933\n",
      "-0.5 \t -0.8378831148147583\n",
      "0.0 \t -0.15506255626678467\n",
      "-0.5 \t 0.5381554365158081\n",
      "0.25 \t 0.36418431997299194\n",
      "1.0 \t -0.7205945253372192\n",
      "0.75 \t -0.1303318291902542\n",
      "0.0 \t -0.23610897362232208\n",
      "0.5 \t -0.4245118796825409\n",
      "-0.25 \t -1.0407814979553223\n",
      "0.0 \t -0.036367934197187424\n",
      "0.0 \t -0.19227279722690582\n",
      "0.0 \t -0.4031602442264557\n",
      "-1.0 \t -0.5820144414901733\n",
      "-0.25 \t 0.6245758533477783\n",
      "-0.5 \t 0.16041480004787445\n",
      "0.0 \t 0.3985459506511688\n",
      "0.25 \t -0.2762770354747772\n",
      "-0.5 \t -0.5162815451622009\n",
      "-0.25 \t 0.2398313283920288\n",
      "0.0 \t -0.38043588399887085\n",
      "-0.75 \t -0.77909916639328\n",
      "0.0 \t -0.03866995871067047\n",
      "-0.5 \t -0.08798707276582718\n",
      "0.0 \t -0.0037042072508484125\n",
      "-0.5 \t -0.6034451127052307\n",
      "0.5 \t -0.14384205639362335\n",
      "0.25 \t -0.37842580676078796\n",
      "-0.5 \t 0.1086837574839592\n",
      "0.5 \t 0.5445201396942139\n",
      "-0.5 \t -0.10110137611627579\n",
      "0.5 \t -0.13668471574783325\n",
      "0.25 \t 0.7001561522483826\n",
      "0.0 \t -0.08109606802463531\n",
      "0.0 \t -0.3684314489364624\n",
      "0.25 \t 0.32802361249923706\n",
      "0.0 \t -0.48545411229133606\n",
      "0.0 \t -0.4030838906764984\n",
      "0.0 \t 0.11871329694986343\n",
      "0.0 \t -0.2761152684688568\n",
      "0.0 \t -0.4879807233810425\n",
      "-0.5 \t -0.4897777736186981\n",
      "0.5 \t 0.3327035903930664\n",
      "0.0 \t -0.40549561381340027\n",
      "0.0 \t 0.0159783735871315\n",
      "-0.5 \t -0.06676807999610901\n",
      "-0.25 \t 0.777870774269104\n",
      "-0.5 \t -0.8086745738983154\n",
      "0.75 \t 0.3910822868347168\n",
      "-0.75 \t -0.3913089632987976\n",
      "-0.25 \t -0.44039714336395264\n",
      "0.0 \t 0.09402547031641006\n",
      "-0.25 \t 0.20162631571292877\n",
      "-0.75 \t -0.5637823939323425\n",
      "0.0 \t 0.10036266595125198\n",
      "0.25 \t -0.38299790024757385\n",
      "0.75 \t -0.3100951313972473\n",
      "0.0 \t 0.08603277802467346\n",
      "-1.0 \t 0.024037832394242287\n",
      "0.25 \t -0.13047342002391815\n",
      "0.0 \t -0.3464144170284271\n",
      "-0.25 \t -0.10328878462314606\n",
      "0.0 \t 0.13348117470741272\n",
      "0.25 \t 0.7125159502029419\n",
      "1.0 \t 0.17653526365756989\n",
      "-0.25 \t -0.23154959082603455\n",
      "0.0 \t 0.10856857150793076\n",
      "0.0 \t 0.27196767926216125\n",
      "-0.25 \t -0.36732017993927\n",
      "0.75 \t 0.07521123439073563\n",
      "0.0 \t 0.06961902230978012\n",
      "0.0 \t 0.15972726047039032\n",
      "-0.25 \t -0.25743773579597473\n",
      "0.25 \t 0.9632518887519836\n",
      "-0.5 \t -0.12649790942668915\n",
      "-0.25 \t 0.39150965213775635\n",
      "0.25 \t 0.18789342045783997\n",
      "0.75 \t -0.7359806299209595\n",
      "-1.0 \t 0.055482156574726105\n",
      "-0.25 \t -0.06553942710161209\n",
      "-0.5 \t -0.17781485617160797\n",
      "-0.5 \t 0.13785086572170258\n",
      "0.0 \t -0.06723323464393616\n",
      "-0.5 \t 0.05137290805578232\n",
      "-1.0 \t 0.07828252762556076\n",
      "-0.5 \t -0.7469217777252197\n",
      "0.0 \t -0.260323703289032\n",
      "0.0 \t 0.1468328833580017\n",
      "-0.25 \t 0.08717227727174759\n",
      "0.0 \t -0.39503416419029236\n",
      "0.0 \t -0.05888201296329498\n",
      "-0.5 \t 0.06431259214878082\n",
      "-0.75 \t -0.4720170497894287\n",
      "0.0 \t 0.08590139448642731\n",
      "-0.25 \t 0.5833649635314941\n",
      "0.0 \t 0.4933245778083801\n",
      "0.0 \t -0.34021875262260437\n",
      "0.0 \t 0.4554641544818878\n",
      "0.0 \t 0.05798930302262306\n",
      "0.75 \t -0.5813946723937988\n",
      "0.75 \t -0.22621729969978333\n",
      "-0.25 \t 0.2615948021411896\n",
      "0.0 \t 0.07033563405275345\n",
      "0.0 \t -0.11137397587299347\n",
      "-0.5 \t -0.08362285792827606\n",
      "1.0 \t 0.6779376864433289\n",
      "0.0 \t 0.5847848653793335\n",
      "0.0 \t 0.043444085866212845\n",
      "0.0 \t 0.2757141888141632\n",
      "0.0 \t -0.17411263287067413\n",
      "0.0 \t -0.11986242979764938\n",
      "0.25 \t 0.18331079185009003\n",
      "0.0 \t -0.15170328319072723\n",
      "0.0 \t 0.018279796466231346\n",
      "-0.5 \t -0.5057275891304016\n",
      "0.0 \t -0.40285730361938477\n",
      "0.0 \t -0.07230410724878311\n",
      "0.5 \t 0.3328372836112976\n",
      "-1.0 \t 0.0648530051112175\n",
      "0.0 \t -0.21533343195915222\n",
      "-0.5 \t -0.15917466580867767\n",
      "0.75 \t -0.2847853899002075\n",
      "0.0 \t 0.05409974977374077\n",
      "0.0 \t 0.1698119342327118\n",
      "0.5 \t -0.07695061713457108\n",
      "0.0 \t 0.055322594940662384\n",
      "0.0 \t -0.298406183719635\n",
      "0.0 \t -0.2960081994533539\n",
      "-0.5 \t 0.3124716281890869\n",
      "0.0 \t 0.14559976756572723\n",
      "1.0 \t -0.00027617361047305167\n",
      "0.0 \t -0.07269660383462906\n",
      "0.0 \t 0.04328421503305435\n",
      "0.5 \t -0.6918027400970459\n",
      "0.0 \t -0.5377962589263916\n",
      "0.25 \t -0.06902928650379181\n",
      "0.5 \t -0.1558583825826645\n",
      "-0.25 \t -0.22942481935024261\n",
      "0.0 \t -0.3539455831050873\n",
      "0.0 \t -0.3006773889064789\n",
      "-0.25 \t 0.00026031475863419473\n",
      "0.0 \t -0.12670587003231049\n",
      "0.0 \t 0.6051076054573059\n",
      "0.0 \t -0.7555041909217834\n",
      "-0.5 \t 0.19830511510372162\n",
      "0.0 \t -0.0611710250377655\n",
      "0.0 \t 0.6095427870750427\n",
      "-0.25 \t -0.08270782232284546\n",
      "0.0 \t -0.011811879463493824\n",
      "-0.5 \t 0.19146163761615753\n",
      "-0.5 \t 0.14268939197063446\n",
      "-0.75 \t -0.5175405144691467\n",
      "0.5 \t -0.012470334768295288\n",
      "-0.5 \t 0.3042820692062378\n",
      "0.0 \t -0.18524761497974396\n",
      "0.0 \t -0.011113074608147144\n",
      "0.5 \t -0.5028209090232849\n",
      "-0.75 \t -0.589767336845398\n",
      "0.0 \t 0.08117303997278214\n",
      "0.0 \t 0.17172378301620483\n",
      "0.0 \t -0.11910130828619003\n",
      "-0.25 \t -0.29986196756362915\n",
      "0.25 \t -0.6390218734741211\n",
      "-0.25 \t 0.23028267920017242\n",
      "0.0 \t -0.11596651375293732\n",
      "0.0 \t -0.19317330420017242\n",
      "0.25 \t 0.16997328400611877\n",
      "-0.5 \t 0.07538106292486191\n",
      "0.5 \t -0.9888209700584412\n",
      "-0.75 \t -0.22252629697322845\n",
      "0.0 \t -0.10841754823923111\n",
      "0.0 \t 0.6615373492240906\n",
      "-0.5 \t 0.5016396641731262\n",
      "0.75 \t -0.6798275113105774\n",
      "0.0 \t -0.14455126225948334\n",
      "1.0 \t -0.4273970127105713\n",
      "0.5 \t 0.2870534360408783\n",
      "-1.0 \t -0.9978803992271423\n",
      "0.0 \t -0.15596026182174683\n",
      "-0.25 \t 0.2867612838745117\n",
      "-0.5 \t 0.019262224435806274\n",
      "0.0 \t 0.1234828382730484\n",
      "0.5 \t 0.728648841381073\n",
      "-0.25 \t 0.07765305787324905\n",
      "-0.5 \t -1.0078530311584473\n",
      "-0.5 \t 0.2509329617023468\n",
      "0.0 \t 0.22109945118427277\n",
      "0.5 \t 0.05537639558315277\n",
      "-0.5 \t -0.15544357895851135\n",
      "-0.5 \t -0.6769499182701111\n",
      "0.0 \t 0.5187605023384094\n",
      "0.5 \t -0.11622888594865799\n",
      "0.0 \t -0.16979758441448212\n",
      "-0.5 \t -0.3642891049385071\n",
      "-0.5 \t -0.25458306074142456\n",
      "0.0 \t -0.24101632833480835\n",
      "-0.5 \t -0.09771542251110077\n",
      "0.0 \t 0.3703874349594116\n",
      "0.0 \t 0.2715037763118744\n",
      "-0.5 \t -0.5947732925415039\n",
      "-0.5 \t 0.14226461946964264\n",
      "0.75 \t -0.07580328732728958\n",
      "0.0 \t 0.3970094323158264\n",
      "0.0 \t -0.14462941884994507\n",
      "-1.0 \t -0.529699444770813\n",
      "0.0 \t -0.6951354146003723\n",
      "0.0 \t -0.04306076094508171\n",
      "0.0 \t -0.40770938992500305\n"
     ]
    }
   ],
   "source": [
    "for i in range(len(y_test)):\n",
    "    print(y_test.iloc[i], '\\t', y_pred[i])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "84576a47",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e281728e",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "5341f7a4",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2044"
      ]
     },
     "execution_count": 47,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# getting full preds\n",
    "with torch.no_grad():\n",
    "    model.eval()\n",
    "    preds = []\n",
    "    batch_size = 16\n",
    "    for i in range(0, len(clean_df), batch_size):\n",
    "        temp = tokenizer(list(clean_df['clean_comment'][i:i+batch_size]), padding='max_length', max_length = 256, truncation=True, return_tensors=\"pt\")\n",
    "        preds.extend(model(temp['input_ids'].to(device), temp['attention_mask'].to(device))[0].squeeze(1).cpu().detach().numpy().tolist())\n",
    "len(preds)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "12636757",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[0.3273819088935852,\n",
       " -0.2997356653213501,\n",
       " -1.4223204851150513,\n",
       " -0.1749923825263977,\n",
       " -0.6475207209587097,\n",
       " -0.7731558680534363,\n",
       " -0.1400814801454544,\n",
       " -0.05199674889445305,\n",
       " -1.2246460914611816,\n",
       " -5.1540362619562075e-05,\n",
       " 0.07392391562461853,\n",
       " -0.08611341565847397,\n",
       " 0.046839188784360886,\n",
       " -0.9809575080871582,\n",
       " -1.1814957857131958,\n",
       " 0.2730066776275635,\n",
       " -0.04323574900627136,\n",
       " -0.25614526867866516,\n",
       " -0.07295921444892883,\n",
       " 0.05834890529513359,\n",
       " 0.09305237978696823,\n",
       " -0.3950732946395874,\n",
       " 0.060769032686948776,\n",
       " -0.2828540503978729,\n",
       " -0.09373804181814194,\n",
       " -0.08411163091659546,\n",
       " 0.2403462678194046,\n",
       " -0.17623849213123322,\n",
       " -0.33056628704071045,\n",
       " -0.2461470067501068,\n",
       " -0.38819995522499084,\n",
       " -0.21865923702716827,\n",
       " -0.344584584236145,\n",
       " -0.1754022240638733,\n",
       " -0.12433488667011261,\n",
       " -0.3208404779434204,\n",
       " 0.25746381282806396,\n",
       " 0.1234079897403717,\n",
       " -0.19573822617530823,\n",
       " -0.24602611362934113,\n",
       " 0.29530224204063416,\n",
       " 0.5264720916748047,\n",
       " -0.08382809162139893,\n",
       " -0.3590361773967743,\n",
       " -0.2321571260690689,\n",
       " 0.18399566411972046,\n",
       " 0.4197656512260437,\n",
       " 0.1732199639081955,\n",
       " 0.05157721787691116,\n",
       " 0.11399436742067337,\n",
       " -0.3176068663597107,\n",
       " -0.15011553466320038,\n",
       " -0.43455561995506287,\n",
       " -0.43932926654815674,\n",
       " -0.100972019135952,\n",
       " 0.03661873936653137,\n",
       " -0.27936747670173645,\n",
       " -0.3233955204486847,\n",
       " 0.4707578718662262,\n",
       " -0.3068403899669647,\n",
       " -0.03884751349687576,\n",
       " -0.05816496163606644,\n",
       " 0.6893238425254822,\n",
       " -0.0743878036737442,\n",
       " 0.08666572719812393,\n",
       " -0.3518766462802887,\n",
       " -0.7160929441452026,\n",
       " 0.26917925477027893,\n",
       " -0.7860443592071533,\n",
       " -0.010435951873660088,\n",
       " -0.11637751013040543,\n",
       " 0.4697301983833313,\n",
       " -1.0477710962295532,\n",
       " -0.09567108005285263,\n",
       " -0.9979361295700073,\n",
       " -0.28291836380958557,\n",
       " -0.48678940534591675,\n",
       " -0.5677849650382996,\n",
       " -0.6640245914459229,\n",
       " -0.36499544978141785,\n",
       " -0.8722817897796631,\n",
       " -0.3804018199443817,\n",
       " -0.02761038765311241,\n",
       " -0.326153963804245,\n",
       " -0.3488825261592865,\n",
       " -0.5511562824249268,\n",
       " -0.004824755247682333,\n",
       " -0.5567095279693604,\n",
       " -0.660174548625946,\n",
       " -0.46498921513557434,\n",
       " -0.1499437391757965,\n",
       " 0.03058478608727455,\n",
       " -0.3647845685482025,\n",
       " -0.7836192846298218,\n",
       " -0.7021599411964417,\n",
       " 0.17135116457939148,\n",
       " 0.7698516249656677,\n",
       " -0.342797189950943,\n",
       " -0.17012861371040344,\n",
       " -0.3370639979839325,\n",
       " -0.07858924567699432,\n",
       " -0.021986762061715126,\n",
       " -0.022703342139720917,\n",
       " -0.56859290599823,\n",
       " 0.09730228036642075,\n",
       " -0.008039146661758423,\n",
       " 0.31162747740745544,\n",
       " 0.19707641005516052,\n",
       " 0.4212816655635834,\n",
       " -0.1025259867310524,\n",
       " -0.06800777465105057,\n",
       " -0.06717567890882492,\n",
       " 0.010287856683135033,\n",
       " 0.09015437960624695,\n",
       " 0.3173407316207886,\n",
       " -0.8737343549728394,\n",
       " 0.1588604748249054,\n",
       " -0.1032782644033432,\n",
       " -0.17383575439453125,\n",
       " -0.2247154861688614,\n",
       " -0.1174938753247261,\n",
       " 0.275187224149704,\n",
       " -0.3923434019088745,\n",
       " -0.09538280218839645,\n",
       " -0.24365192651748657,\n",
       " 0.48908892273902893,\n",
       " 0.12372897565364838,\n",
       " 0.2465154379606247,\n",
       " 0.05996769666671753,\n",
       " -0.24217352271080017,\n",
       " 0.27544501423835754,\n",
       " -0.25267815589904785,\n",
       " 0.04280513897538185,\n",
       " -0.45921653509140015,\n",
       " -0.5431104898452759,\n",
       " -0.519738495349884,\n",
       " -0.560427188873291,\n",
       " -0.20921480655670166,\n",
       " -0.30192866921424866,\n",
       " -0.11422248929738998,\n",
       " 0.6318315267562866,\n",
       " -1.0093129873275757,\n",
       " -0.014815675094723701,\n",
       " -0.16351492702960968,\n",
       " -0.14085544645786285,\n",
       " -0.6115591526031494,\n",
       " -0.9009385704994202,\n",
       " -0.45340290665626526,\n",
       " -0.08185936510562897,\n",
       " -0.048198968172073364,\n",
       " 0.1466224491596222,\n",
       " -0.1377706080675125,\n",
       " -0.7182302474975586,\n",
       " -0.23245616257190704,\n",
       " -0.49791404604911804,\n",
       " -0.05696776136755943,\n",
       " -0.5659574270248413,\n",
       " 0.429563045501709,\n",
       " -1.0721055269241333,\n",
       " -0.8557721972465515,\n",
       " -0.7795602679252625,\n",
       " -0.49703988432884216,\n",
       " 0.02877926267683506,\n",
       " 0.10457802563905716,\n",
       " -0.561625599861145,\n",
       " 0.21520628035068512,\n",
       " 0.014506048522889614,\n",
       " -0.2695716917514801,\n",
       " -0.5685757994651794,\n",
       " -0.5174627304077148,\n",
       " -0.6191132068634033,\n",
       " -0.23752231895923615,\n",
       " -0.38888734579086304,\n",
       " -0.008009325712919235,\n",
       " -0.10544128715991974,\n",
       " -0.11505677551031113,\n",
       " -0.7705816626548767,\n",
       " -0.2503258287906647,\n",
       " -0.6469608545303345,\n",
       " -0.2909879684448242,\n",
       " -0.2715568542480469,\n",
       " 0.09829816222190857,\n",
       " -0.1282784789800644,\n",
       " 0.06903137266635895,\n",
       " -0.25443023443222046,\n",
       " 0.7541359066963196,\n",
       " -0.5373238921165466,\n",
       " -0.5152913331985474,\n",
       " -0.8774654865264893,\n",
       " -0.852504551410675,\n",
       " -0.7032707333564758,\n",
       " -0.27477502822875977,\n",
       " -0.10310493409633636,\n",
       " -0.6122605800628662,\n",
       " -0.3431631624698639,\n",
       " 0.1668432056903839,\n",
       " -0.7294602394104004,\n",
       " -0.31215280294418335,\n",
       " -0.22236502170562744,\n",
       " -0.02949938364326954,\n",
       " -0.07679775357246399,\n",
       " 0.13565920293331146,\n",
       " 0.21888433396816254,\n",
       " 0.04627988114953041,\n",
       " -0.3425053060054779,\n",
       " 0.21145100891590118,\n",
       " -0.4804737865924835,\n",
       " -0.38403284549713135,\n",
       " 0.14599503576755524,\n",
       " -0.26716238260269165,\n",
       " -0.48347368836402893,\n",
       " -0.19972741603851318,\n",
       " 0.07295705378055573,\n",
       " -0.3989357054233551,\n",
       " -0.002540873596444726,\n",
       " -0.9621607661247253,\n",
       " -0.2043028622865677,\n",
       " -0.9944847822189331,\n",
       " -0.2774527966976166,\n",
       " 0.0016645628493279219,\n",
       " -0.8413294553756714,\n",
       " 0.14311914145946503,\n",
       " -0.3850207030773163,\n",
       " -0.44006919860839844,\n",
       " 4.852582424064167e-05,\n",
       " 0.9475891590118408,\n",
       " -0.060487374663352966,\n",
       " -0.6640971302986145,\n",
       " -0.011115841567516327,\n",
       " -0.34631940722465515,\n",
       " -0.10932565480470657,\n",
       " 0.5484135746955872,\n",
       " -0.23210574686527252,\n",
       " 0.040654730051755905,\n",
       " -0.18015329539775848,\n",
       " 0.5227182507514954,\n",
       " 0.03131679818034172,\n",
       " 0.07002504914999008,\n",
       " 0.06365635246038437,\n",
       " -0.24641944468021393,\n",
       " -0.5396513938903809,\n",
       " -0.26416465640068054,\n",
       " -0.1519821733236313,\n",
       " 0.02718030847609043,\n",
       " 0.27348315715789795,\n",
       " 0.1550390124320984,\n",
       " -0.19485333561897278,\n",
       " 0.25448939204216003,\n",
       " 0.06191897392272949,\n",
       " -0.061735086143016815,\n",
       " -0.4018581211566925,\n",
       " -0.6078940629959106,\n",
       " -0.4120347201824188,\n",
       " -0.013616006821393967,\n",
       " 0.17320258915424347,\n",
       " 0.4111006557941437,\n",
       " 0.12711578607559204,\n",
       " -0.5310158133506775,\n",
       " 0.09558029472827911,\n",
       " -0.06148787587881088,\n",
       " -0.0718325823545456,\n",
       " -0.3593837320804596,\n",
       " -0.5634822845458984,\n",
       " 0.06475931406021118,\n",
       " 0.0621345229446888,\n",
       " -0.15699169039726257,\n",
       " -0.24480409920215607,\n",
       " -0.12176045030355453,\n",
       " 0.6788216233253479,\n",
       " -0.3687022924423218,\n",
       " -0.11434498429298401,\n",
       " -1.200810432434082,\n",
       " 0.07845524698495865,\n",
       " -0.5207518339157104,\n",
       " -0.7938451170921326,\n",
       " -0.33633726835250854,\n",
       " -0.21523132920265198,\n",
       " 0.0026525266002863646,\n",
       " 0.21811965107917786,\n",
       " -0.5333388447761536,\n",
       " 0.46183615922927856,\n",
       " 0.25929608941078186,\n",
       " 0.5048479437828064,\n",
       " -0.1616635024547577,\n",
       " -0.5489262938499451,\n",
       " 0.23117268085479736,\n",
       " -0.2874334752559662,\n",
       " 0.08655571192502975,\n",
       " -0.4110729396343231,\n",
       " 0.25164297223091125,\n",
       " -0.12490858882665634,\n",
       " 0.27611082792282104,\n",
       " -0.15940937399864197,\n",
       " -0.14973974227905273,\n",
       " -0.8525988459587097,\n",
       " -0.5088724493980408,\n",
       " -0.07866375148296356,\n",
       " -0.45592498779296875,\n",
       " -0.543509304523468,\n",
       " 0.5260298252105713,\n",
       " -0.07544391602277756,\n",
       " -0.18183369934558868,\n",
       " 0.3627154529094696,\n",
       " -0.2658235728740692,\n",
       " -0.23281867802143097,\n",
       " 0.015076380223035812,\n",
       " 0.4290110766887665,\n",
       " 0.09515088051557541,\n",
       " -0.2019602209329605,\n",
       " -0.20565278828144073,\n",
       " -0.36470282077789307,\n",
       " -0.05859998241066933,\n",
       " -0.09792783111333847,\n",
       " 0.4281093180179596,\n",
       " 0.10527139157056808,\n",
       " -0.16638457775115967,\n",
       " -0.025519751012325287,\n",
       " 0.029846297577023506,\n",
       " 0.1342591643333435,\n",
       " -0.37542569637298584,\n",
       " 0.0294090136885643,\n",
       " 0.16467711329460144,\n",
       " 0.5631462335586548,\n",
       " 0.6928418874740601,\n",
       " -0.9612276554107666,\n",
       " -0.14769522845745087,\n",
       " 0.27808618545532227,\n",
       " -0.1998451054096222,\n",
       " -0.2837749421596527,\n",
       " -0.07399725914001465,\n",
       " 0.21243655681610107,\n",
       " 0.13062222301959991,\n",
       " -0.5825863480567932,\n",
       " -0.644615888595581,\n",
       " -0.5979717969894409,\n",
       " 0.37967512011528015,\n",
       " -0.07785499840974808,\n",
       " -0.8958066701889038,\n",
       " 0.08416083455085754,\n",
       " 0.08395411819219589,\n",
       " 0.6232277154922485,\n",
       " -0.20245344936847687,\n",
       " -0.0680660679936409,\n",
       " -0.911467432975769,\n",
       " 0.41238436102867126,\n",
       " 0.3644951581954956,\n",
       " 0.9299387335777283,\n",
       " -0.47696319222450256,\n",
       " 0.5899866819381714,\n",
       " -0.3551565408706665,\n",
       " -0.5091607570648193,\n",
       " -0.5909463167190552,\n",
       " 0.905103862285614,\n",
       " -0.05012945830821991,\n",
       " -0.25075745582580566,\n",
       " 0.6451930403709412,\n",
       " -0.16945944726467133,\n",
       " 0.13766533136367798,\n",
       " 0.18700234591960907,\n",
       " -0.014452215284109116,\n",
       " 0.09875013679265976,\n",
       " -0.49239593744277954,\n",
       " 1.0354117155075073,\n",
       " 0.4770762622356415,\n",
       " 0.03343265503644943,\n",
       " 0.6111986637115479,\n",
       " 0.28069403767585754,\n",
       " -0.12588009238243103,\n",
       " -1.1233750581741333,\n",
       " -0.2929877042770386,\n",
       " -0.2433861494064331,\n",
       " 0.202505424618721,\n",
       " -0.021410902962088585,\n",
       " -0.07355251163244247,\n",
       " -0.5952414870262146,\n",
       " 0.42077258229255676,\n",
       " -0.03717947006225586,\n",
       " -0.8127453923225403,\n",
       " -0.30047667026519775,\n",
       " -0.2921445369720459,\n",
       " -0.3921950161457062,\n",
       " 0.05284607410430908,\n",
       " -0.6282622814178467,\n",
       " 0.3953950107097626,\n",
       " -0.06298283487558365,\n",
       " 0.23166576027870178,\n",
       " -0.16973882913589478,\n",
       " 0.0476372204720974,\n",
       " -0.17487411201000214,\n",
       " -0.49221986532211304,\n",
       " 0.7778334021568298,\n",
       " 0.4179321229457855,\n",
       " 0.12155898660421371,\n",
       " -0.32411256432533264,\n",
       " 0.039034560322761536,\n",
       " -0.4156326353549957,\n",
       " 0.3225219249725342,\n",
       " 0.19697275757789612,\n",
       " -0.149379163980484,\n",
       " -0.25891315937042236,\n",
       " 0.8099027276039124,\n",
       " 0.891883909702301,\n",
       " -0.22949440777301788,\n",
       " -0.12264993041753769,\n",
       " 0.692314624786377,\n",
       " -0.4342973232269287,\n",
       " -0.13696105778217316,\n",
       " -0.17910736799240112,\n",
       " 0.6985601782798767,\n",
       " 0.3693450689315796,\n",
       " -0.29201963543891907,\n",
       " -0.1790563017129898,\n",
       " -0.15596801042556763,\n",
       " -0.544222891330719,\n",
       " -0.3148138225078583,\n",
       " -0.6442952156066895,\n",
       " 0.2994198501110077,\n",
       " -0.41452038288116455,\n",
       " 0.202672079205513,\n",
       " 0.007906249724328518,\n",
       " -0.18642236292362213,\n",
       " -0.17286913096904755,\n",
       " 0.516732394695282,\n",
       " -0.007856136187911034,\n",
       " -0.10188939422369003,\n",
       " -0.0929480493068695,\n",
       " 0.01701892726123333,\n",
       " 0.03205814212560654,\n",
       " -0.15738166868686676,\n",
       " -0.3445681035518646,\n",
       " 0.03558529540896416,\n",
       " -0.358564168214798,\n",
       " -0.19055907428264618,\n",
       " -0.557373583316803,\n",
       " -0.6363278031349182,\n",
       " 0.03931416943669319,\n",
       " 0.8027728199958801,\n",
       " -0.3842059373855591,\n",
       " 0.21964390575885773,\n",
       " 0.5404946804046631,\n",
       " 0.05509590357542038,\n",
       " -0.0851745530962944,\n",
       " 0.3826557397842407,\n",
       " 0.4388442933559418,\n",
       " -0.2941162884235382,\n",
       " 0.13522084057331085,\n",
       " 0.19817158579826355,\n",
       " 0.2658652365207672,\n",
       " -0.36631426215171814,\n",
       " -0.018244368955492973,\n",
       " -0.048618946224451065,\n",
       " -0.0043664476834237576,\n",
       " -0.4323287606239319,\n",
       " -0.6325337886810303,\n",
       " 0.005685766693204641,\n",
       " -0.027229132130742073,\n",
       " 0.09909027069807053,\n",
       " -0.3844625651836395,\n",
       " 0.26689210534095764,\n",
       " -0.5919211506843567,\n",
       " 0.15836812555789948,\n",
       " -0.4638126790523529,\n",
       " -0.01100127212703228,\n",
       " -0.08315110951662064,\n",
       " -0.318417489528656,\n",
       " -0.4500811696052551,\n",
       " 0.10858146101236343,\n",
       " -0.0028114947490394115,\n",
       " -0.7322000861167908,\n",
       " 0.1366594135761261,\n",
       " -0.11007008701562881,\n",
       " 0.04968953877687454,\n",
       " -0.16100458800792694,\n",
       " -0.7077585458755493,\n",
       " 0.44256314635276794,\n",
       " 0.6821059584617615,\n",
       " -0.6021488904953003,\n",
       " 0.1505526900291443,\n",
       " -0.37474265694618225,\n",
       " -0.5880888104438782,\n",
       " 0.43170562386512756,\n",
       " -0.5581055283546448,\n",
       " 0.4684019684791565,\n",
       " -0.017818862572312355,\n",
       " 0.3235955238342285,\n",
       " 0.0978790894150734,\n",
       " 0.1541593223810196,\n",
       " -0.12139488756656647,\n",
       " -0.15099851787090302,\n",
       " -0.06825863569974899,\n",
       " 0.21759288012981415,\n",
       " -0.010844630189239979,\n",
       " -0.015378686599433422,\n",
       " 0.35028544068336487,\n",
       " -1.109186053276062,\n",
       " -0.18728917837142944,\n",
       " 0.564822256565094,\n",
       " -0.5715846419334412,\n",
       " 0.007576601579785347,\n",
       " 0.21546941995620728,\n",
       " -0.299719899892807,\n",
       " 0.11599835008382797,\n",
       " -0.06356298923492432,\n",
       " -0.07942665368318558,\n",
       " 0.36130577325820923,\n",
       " -0.40537190437316895,\n",
       " 0.18782086670398712,\n",
       " -0.8826179504394531,\n",
       " -0.21091508865356445,\n",
       " 0.5873227715492249,\n",
       " 0.07827776670455933,\n",
       " -0.04206543043255806,\n",
       " -0.14619141817092896,\n",
       " 0.4025263786315918,\n",
       " 0.27432623505592346,\n",
       " 0.43144306540489197,\n",
       " 0.03064676932990551,\n",
       " 0.3397356867790222,\n",
       " -0.26841652393341064,\n",
       " 0.2555929124355316,\n",
       " -0.2318924218416214,\n",
       " -1.1226952075958252,\n",
       " -0.4407097101211548,\n",
       " -0.23756733536720276,\n",
       " 0.16423837840557098,\n",
       " 0.24504612386226654,\n",
       " -0.21339263021945953,\n",
       " 0.14756016433238983,\n",
       " -0.2645488679409027,\n",
       " -0.5629845857620239,\n",
       " 0.32214808464050293,\n",
       " -0.06791212409734726,\n",
       " -0.038315776735544205,\n",
       " 0.046796832233667374,\n",
       " -0.1240963265299797,\n",
       " 0.18102124333381653,\n",
       " -0.5811827778816223,\n",
       " 0.4794866144657135,\n",
       " -0.13456623256206512,\n",
       " -0.1799917072057724,\n",
       " -0.25530561804771423,\n",
       " 0.08402403444051743,\n",
       " 0.07951909303665161,\n",
       " 0.09621190279722214,\n",
       " 0.7483341097831726,\n",
       " -0.7626848816871643,\n",
       " -0.6888957619667053,\n",
       " -0.37741437554359436,\n",
       " -0.36576056480407715,\n",
       " 0.11070097237825394,\n",
       " -0.14248135685920715,\n",
       " 0.1539454311132431,\n",
       " -0.5678054690361023,\n",
       " -0.1587790697813034,\n",
       " -0.14670930802822113,\n",
       " -0.537834644317627,\n",
       " -0.8521766662597656,\n",
       " -0.4786054790019989,\n",
       " -0.20898780226707458,\n",
       " 0.8957183957099915,\n",
       " 0.08759979158639908,\n",
       " -0.09761732816696167,\n",
       " -0.008100738748908043,\n",
       " 0.22139903903007507,\n",
       " -0.30246415734291077,\n",
       " -0.027843045070767403,\n",
       " -0.2652486264705658,\n",
       " -0.05512961745262146,\n",
       " -0.05888773500919342,\n",
       " -0.3854313790798187,\n",
       " -0.39699286222457886,\n",
       " 0.36871442198753357,\n",
       " -0.35585981607437134,\n",
       " -0.5448203086853027,\n",
       " -0.6173707842826843,\n",
       " -0.06155315786600113,\n",
       " 0.026889866217970848,\n",
       " 0.02630981244146824,\n",
       " -0.07945907115936279,\n",
       " -0.39921337366104126,\n",
       " -0.7496877908706665,\n",
       " -0.15628592669963837,\n",
       " -0.06765282154083252,\n",
       " 0.08093973249197006,\n",
       " -0.1270505040884018,\n",
       " 0.7863856554031372,\n",
       " 0.32106563448905945,\n",
       " 0.2266269475221634,\n",
       " -0.1298082023859024,\n",
       " -0.2939346730709076,\n",
       " -0.12034248560667038,\n",
       " 0.0874711200594902,\n",
       " -0.165754497051239,\n",
       " -0.10189462453126907,\n",
       " -0.39509138464927673,\n",
       " -0.17588312923908234,\n",
       " -0.21830831468105316,\n",
       " 0.04929793253540993,\n",
       " 0.17314723134040833,\n",
       " 0.47404584288597107,\n",
       " -0.43841731548309326,\n",
       " -0.6106420755386353,\n",
       " -0.4113348722457886,\n",
       " -0.02815261296927929,\n",
       " -0.2265496551990509,\n",
       " -0.21261876821517944,\n",
       " -0.7607575058937073,\n",
       " -0.22945712506771088,\n",
       " -0.44797763228416443,\n",
       " -0.13451357185840607,\n",
       " 0.3380602300167084,\n",
       " -0.18257848918437958,\n",
       " -0.4268014430999756,\n",
       " -0.04303712397813797,\n",
       " 0.34064820408821106,\n",
       " -0.6654999256134033,\n",
       " 0.17778965830802917,\n",
       " -0.25424718856811523,\n",
       " -0.423644095659256,\n",
       " 0.6471021175384521,\n",
       " -0.24153001606464386,\n",
       " 0.31292724609375,\n",
       " -0.16674719750881195,\n",
       " -0.8364825248718262,\n",
       " 0.6741237044334412,\n",
       " -0.44576069712638855,\n",
       " 0.02712208591401577,\n",
       " -0.022530553862452507,\n",
       " -0.029167430475354195,\n",
       " -0.49768930673599243,\n",
       " -0.045527685433626175,\n",
       " -0.740965723991394,\n",
       " -0.19544123113155365,\n",
       " -0.17779763042926788,\n",
       " 1.1975563764572144,\n",
       " -0.6278859376907349,\n",
       " -0.9220861792564392,\n",
       " -0.8689239025115967,\n",
       " 0.09885100275278091,\n",
       " 0.012699390761554241,\n",
       " -0.03142990544438362,\n",
       " -0.007213911507278681,\n",
       " -0.34929776191711426,\n",
       " -0.07470818608999252,\n",
       " 0.10534809529781342,\n",
       " -0.10123961418867111,\n",
       " -0.22053399682044983,\n",
       " -0.26329275965690613,\n",
       " -0.154715433716774,\n",
       " 0.3389343321323395,\n",
       " -0.7366902232170105,\n",
       " -0.8367988467216492,\n",
       " -0.74676114320755,\n",
       " -0.3013007938861847,\n",
       " -0.09322012215852737,\n",
       " -0.15451613068580627,\n",
       " 0.08085625618696213,\n",
       " 0.04151936620473862,\n",
       " 0.005696802865713835,\n",
       " -0.06194435432553291,\n",
       " 0.3931378722190857,\n",
       " -0.004544964525848627,\n",
       " 0.01935729756951332,\n",
       " -0.20226837694644928,\n",
       " -0.44468259811401367,\n",
       " 0.12668423354625702,\n",
       " -0.13961900770664215,\n",
       " 0.5812436938285828,\n",
       " -0.8511444330215454,\n",
       " -0.20823119580745697,\n",
       " -0.0731632187962532,\n",
       " 0.9820218086242676,\n",
       " -0.39182472229003906,\n",
       " -0.7020261883735657,\n",
       " 0.2715862989425659,\n",
       " -0.5650491118431091,\n",
       " -0.6471317410469055,\n",
       " 0.30093589425086975,\n",
       " -0.20410439372062683,\n",
       " 0.07434550672769547,\n",
       " 0.015378209762275219,\n",
       " -0.5083582997322083,\n",
       " -0.03993066027760506,\n",
       " -0.061981264501810074,\n",
       " 0.2651638984680176,\n",
       " 0.18944399058818817,\n",
       " -0.14914122223854065,\n",
       " -0.27676331996917725,\n",
       " -0.026358701288700104,\n",
       " -0.27672821283340454,\n",
       " -0.2032259702682495,\n",
       " 0.0567488893866539,\n",
       " -0.8515293598175049,\n",
       " -0.15527892112731934,\n",
       " 0.08054608851671219,\n",
       " 0.47101378440856934,\n",
       " -0.9461467266082764,\n",
       " 0.18015417456626892,\n",
       " -0.5543227791786194,\n",
       " -0.20981280505657196,\n",
       " -0.10864142328500748,\n",
       " -0.04780685156583786,\n",
       " -0.17370085418224335,\n",
       " 0.059466179460287094,\n",
       " -0.4508885145187378,\n",
       " 0.025616422295570374,\n",
       " -0.6592774391174316,\n",
       " -0.7128445506095886,\n",
       " -0.21594657003879547,\n",
       " -0.44495368003845215,\n",
       " -0.37046724557876587,\n",
       " -0.5974637866020203,\n",
       " 0.050513941794633865,\n",
       " -0.018410803750157356,\n",
       " -0.4647623300552368,\n",
       " 0.21347784996032715,\n",
       " 0.18984124064445496,\n",
       " 0.2005060464143753,\n",
       " -0.5147850513458252,\n",
       " -0.7139354348182678,\n",
       " -0.6015380620956421,\n",
       " -0.40626463294029236,\n",
       " -0.04567164182662964,\n",
       " -0.012906942516565323,\n",
       " -0.1838371306657791,\n",
       " -0.8492097854614258,\n",
       " 0.4063308835029602,\n",
       " -0.649861216545105,\n",
       " -0.26281464099884033,\n",
       " 0.44126465916633606,\n",
       " -0.09624820202589035,\n",
       " 0.6870548725128174,\n",
       " 0.18056823313236237,\n",
       " 0.040706198662519455,\n",
       " 0.061131060123443604,\n",
       " 0.02619604766368866,\n",
       " -0.21822455525398254,\n",
       " 0.7398039102554321,\n",
       " -0.18844757974147797,\n",
       " -0.891446590423584,\n",
       " 0.4540990889072418,\n",
       " 0.12327305227518082,\n",
       " 0.018724286928772926,\n",
       " 0.25998684763908386,\n",
       " 0.007259873207658529,\n",
       " -0.08902791142463684,\n",
       " 0.4754551947116852,\n",
       " 0.20114992558956146,\n",
       " -0.09178768843412399,\n",
       " -0.012825815007090569,\n",
       " -0.5010669827461243,\n",
       " -0.2248305082321167,\n",
       " 0.18611806631088257,\n",
       " -0.10301917791366577,\n",
       " 0.16944369673728943,\n",
       " 0.16523003578186035,\n",
       " 0.10675348341464996,\n",
       " -0.5101069211959839,\n",
       " -0.27539846301078796,\n",
       " -0.39714527130126953,\n",
       " -0.6479853987693787,\n",
       " -0.20289358496665955,\n",
       " 0.23511669039726257,\n",
       " 0.37509509921073914,\n",
       " 0.06013185903429985,\n",
       " 0.606497049331665,\n",
       " -0.06283536553382874,\n",
       " 0.3077946901321411,\n",
       " -0.4714956283569336,\n",
       " -0.15448735654354095,\n",
       " -0.005897219758480787,\n",
       " 0.40125712752342224,\n",
       " -0.22185327112674713,\n",
       " -0.5592946410179138,\n",
       " -0.7232625484466553,\n",
       " -0.7041274905204773,\n",
       " 0.03299888223409653,\n",
       " 0.11443564295768738,\n",
       " 0.17866110801696777,\n",
       " -0.44251495599746704,\n",
       " -0.4185509979724884,\n",
       " -0.27677544951438904,\n",
       " -0.059643182903528214,\n",
       " 0.1482006162405014,\n",
       " 0.24433694779872894,\n",
       " -0.5078964829444885,\n",
       " -0.516979455947876,\n",
       " 0.07442615926265717,\n",
       " 0.019078465178608894,\n",
       " -0.21716651320457458,\n",
       " 0.06199498847126961,\n",
       " 0.31666749715805054,\n",
       " -0.2624490261077881,\n",
       " -0.20569047331809998,\n",
       " 0.007296469062566757,\n",
       " -0.2343786358833313,\n",
       " -0.32216429710388184,\n",
       " -0.11591948568820953,\n",
       " 0.40972375869750977,\n",
       " 0.22389128804206848,\n",
       " 0.0012331120669841766,\n",
       " -0.06930886209011078,\n",
       " 0.7090196013450623,\n",
       " 0.5049266815185547,\n",
       " 0.054877638816833496,\n",
       " 0.19790677726268768,\n",
       " -0.12221072614192963,\n",
       " -0.0656597763299942,\n",
       " -0.018487747758626938,\n",
       " -0.16922490298748016,\n",
       " 0.159210205078125,\n",
       " -0.68895423412323,\n",
       " -0.05905624106526375,\n",
       " -0.40693363547325134,\n",
       " 0.14585073292255402,\n",
       " -0.09452884644269943,\n",
       " -0.3877161145210266,\n",
       " 0.0004679588309954852,\n",
       " -0.3401012122631073,\n",
       " -0.08929362148046494,\n",
       " 0.46088674664497375,\n",
       " -0.22256670892238617,\n",
       " 0.012546980753540993,\n",
       " -0.06140555813908577,\n",
       " 0.20408324897289276,\n",
       " 0.0657704770565033,\n",
       " -0.062027864158153534,\n",
       " -0.43580541014671326,\n",
       " -0.1446348875761032,\n",
       " 0.26090648770332336,\n",
       " -0.30450788140296936,\n",
       " -0.6906976103782654,\n",
       " -0.20367902517318726,\n",
       " 0.15572980046272278,\n",
       " -0.09790239483118057,\n",
       " -0.12339391559362411,\n",
       " 0.19468644261360168,\n",
       " -0.1882074475288391,\n",
       " -0.1685349941253662,\n",
       " 0.05398919805884361,\n",
       " -0.09588999301195145,\n",
       " 0.3289472162723541,\n",
       " 0.12983207404613495,\n",
       " -0.6381430625915527,\n",
       " -0.09761732816696167,\n",
       " -0.3821410536766052,\n",
       " -0.8610018491744995,\n",
       " 0.11122649163007736,\n",
       " 1.4155941009521484,\n",
       " -0.5776181221008301,\n",
       " 0.4371458888053894,\n",
       " -0.027537832036614418,\n",
       " 0.20516593754291534,\n",
       " 0.2189994901418686,\n",
       " -0.07830655574798584,\n",
       " -0.48669856786727905,\n",
       " 0.2891603112220764,\n",
       " -0.2578851878643036,\n",
       " -0.1385546773672104,\n",
       " -0.5124943256378174,\n",
       " -0.7106447219848633,\n",
       " -0.17528952658176422,\n",
       " -0.16512177884578705,\n",
       " 0.0020145021844655275,\n",
       " 0.03304030001163483,\n",
       " -0.140167698264122,\n",
       " -0.028994545340538025,\n",
       " -0.5329877138137817,\n",
       " -0.15976333618164062,\n",
       " -0.15439675748348236,\n",
       " -0.4661104679107666,\n",
       " -0.3679148852825165,\n",
       " -0.6110891699790955,\n",
       " -0.09537806361913681,\n",
       " -0.5583661198616028,\n",
       " -0.5400208234786987,\n",
       " -0.10612475872039795,\n",
       " -0.34152185916900635,\n",
       " -0.16784967482089996,\n",
       " -0.028980735689401627,\n",
       " -0.18499824404716492,\n",
       " -0.9925046563148499,\n",
       " -0.7016357779502869,\n",
       " -0.08146696537733078,\n",
       " -0.018223339691758156,\n",
       " -0.13065245747566223,\n",
       " 0.2723993957042694,\n",
       " -0.07375957071781158,\n",
       " 0.11958148330450058,\n",
       " -0.14929935336112976,\n",
       " -0.2148500233888626,\n",
       " -0.17350365221500397,\n",
       " -0.17227846384048462,\n",
       " -0.09502799063920975,\n",
       " -0.41901150345802307,\n",
       " 0.2695748805999756,\n",
       " -0.08137191087007523,\n",
       " 0.09118045121431351,\n",
       " 0.5105440616607666,\n",
       " -0.6035571694374084,\n",
       " -0.17821839451789856,\n",
       " 0.3023814857006073,\n",
       " -0.069142647087574,\n",
       " -0.1490844339132309,\n",
       " -0.7435461282730103,\n",
       " 0.7219911813735962,\n",
       " -0.7041332125663757,\n",
       " -0.15624888241291046,\n",
       " 0.8090510964393616,\n",
       " -0.13097041845321655,\n",
       " -0.09425131976604462,\n",
       " -0.27805784344673157,\n",
       " 0.05296441167593002,\n",
       " -0.5590803623199463,\n",
       " -0.16107405722141266,\n",
       " -0.16039536893367767,\n",
       " 0.1671956330537796,\n",
       " -0.2095785140991211,\n",
       " -0.0888553038239479,\n",
       " 0.045020751655101776,\n",
       " 0.9380998015403748,\n",
       " 1.035121202468872,\n",
       " -0.00172548764385283,\n",
       " 0.1035250574350357,\n",
       " -0.09773747622966766,\n",
       " -0.743418276309967,\n",
       " 0.09632518142461777,\n",
       " -0.10207162797451019,\n",
       " 0.07790446281433105,\n",
       " 0.059486422687768936,\n",
       " 0.2407579869031906,\n",
       " 0.032951392233371735,\n",
       " -0.08472130447626114,\n",
       " -0.6933023929595947,\n",
       " -0.2697302997112274,\n",
       " 0.022454746067523956,\n",
       " 0.23961317539215088,\n",
       " 0.4087503254413605,\n",
       " -1.0477710962295532,\n",
       " -0.013269986025989056,\n",
       " -0.31636831164360046,\n",
       " -0.5169418454170227,\n",
       " 0.11588159948587418,\n",
       " -0.11078950017690659,\n",
       " -0.15823806822299957,\n",
       " -0.25855669379234314,\n",
       " -0.13699859380722046,\n",
       " -0.5423202514648438,\n",
       " 0.4723935127258301,\n",
       " -0.2121609002351761,\n",
       " 0.38116738200187683,\n",
       " -0.012630456127226353,\n",
       " 0.844404935836792,\n",
       " -0.7698560357093811,\n",
       " -0.02276959829032421,\n",
       " -0.15434333682060242,\n",
       " -0.10194309055805206,\n",
       " 0.3966686725616455,\n",
       " 0.38915762305259705,\n",
       " -0.421186238527298,\n",
       " -0.6173189282417297,\n",
       " -0.11256319284439087,\n",
       " 0.0902569591999054,\n",
       " -0.0770053043961525,\n",
       " -0.6168257594108582,\n",
       " -0.021285880357027054,\n",
       " -0.29292377829551697,\n",
       " -0.6007188558578491,\n",
       " -0.6330140233039856,\n",
       " 0.7187038660049438,\n",
       " 0.6390941739082336,\n",
       " 0.5631065964698792,\n",
       " -0.3004966974258423,\n",
       " -0.3070574998855591,\n",
       " -0.04623130336403847,\n",
       " -0.00911498349159956,\n",
       " 0.1571023017168045,\n",
       " -0.2512362003326416,\n",
       " 0.05209505558013916,\n",
       " -0.538535475730896,\n",
       " -0.8570570945739746,\n",
       " -0.37254178524017334,\n",
       " -0.2523275315761566,\n",
       " 0.09221523255109787,\n",
       " -0.11227863281965256,\n",
       " -0.05644300580024719,\n",
       " -0.0757267028093338,\n",
       " -0.04776011034846306,\n",
       " 0.13530094921588898,\n",
       " -0.4727369248867035,\n",
       " 0.5865077376365662,\n",
       " -0.05655983090400696,\n",
       " -0.5218269228935242,\n",
       " -0.3661307394504547,\n",
       " 0.023806694895029068,\n",
       " -0.7345853447914124,\n",
       " -0.004163539502769709,\n",
       " -0.405740886926651,\n",
       " -0.31768304109573364,\n",
       " -0.02486066333949566,\n",
       " ...]"
      ]
     },
     "execution_count": 48,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "preds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "02b40425",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(array([  6.,  39., 171., 378., 776., 449., 153.,  54.,  11.,   7.]),\n",
       " array([-1.48909509, -1.18797395, -0.88685281, -0.58573167, -0.28461053,\n",
       "         0.01651061,  0.31763175,  0.61875288,  0.91987402,  1.22099516,\n",
       "         1.5221163 ]),\n",
       " <BarContainer object of 10 artists>)"
      ]
     },
     "execution_count": 49,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.hist(preds)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "98a2f8b2",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>clean_title</th>\n",
       "      <th>clean_comment</th>\n",
       "      <th>url</th>\n",
       "      <th>avg_score</th>\n",
       "      <th>target</th>\n",
       "      <th>preds</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Shashi Tharoor Set To Run For Congress Preside...</td>\n",
       "      <td>Extremely valid points but I believe he has th...</td>\n",
       "      <td>/r/india/comments/xif8wm/shashi_tharoor_set_to...</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-0.50</td>\n",
       "      <td>0.327382</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Yogi government puts Kolkata's image as part o...</td>\n",
       "      <td>Even if the ad was designed by the newspaper t...</td>\n",
       "      <td>/r/india/comments/pmn9o3/yogi_government_puts_...</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-0.50</td>\n",
       "      <td>-0.299736</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>An attempt to address the list of \"simplified\"...</td>\n",
       "      <td>Diverse population including Muslims. Welcomin...</td>\n",
       "      <td>/r/india/comments/ebdeup/an_attempt_to_address...</td>\n",
       "      <td>-1.5</td>\n",
       "      <td>-0.75</td>\n",
       "      <td>-1.422320</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>You guys noticing what's happening in Sri Lanka?</td>\n",
       "      <td>What a joke. They didn't create any propaganda...</td>\n",
       "      <td>/r/india/comments/tt1ryh/you_guys_noticing_wha...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.00</td>\n",
       "      <td>-0.174992</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Just got abused on the train by a hyper nation...</td>\n",
       "      <td>Ohoo bahut bura laga ye sunke ki aap Undergarm...</td>\n",
       "      <td>/r/india/comments/rh2kcs/just_got_abused_on_th...</td>\n",
       "      <td>-2.0</td>\n",
       "      <td>-1.00</td>\n",
       "      <td>-0.647521</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                         clean_title  \\\n",
       "0  Shashi Tharoor Set To Run For Congress Preside...   \n",
       "1  Yogi government puts Kolkata's image as part o...   \n",
       "2  An attempt to address the list of \"simplified\"...   \n",
       "3   You guys noticing what's happening in Sri Lanka?   \n",
       "4  Just got abused on the train by a hyper nation...   \n",
       "\n",
       "                                       clean_comment  \\\n",
       "0  Extremely valid points but I believe he has th...   \n",
       "1  Even if the ad was designed by the newspaper t...   \n",
       "2  Diverse population including Muslims. Welcomin...   \n",
       "3  What a joke. They didn't create any propaganda...   \n",
       "4  Ohoo bahut bura laga ye sunke ki aap Undergarm...   \n",
       "\n",
       "                                                 url  avg_score  target  \\\n",
       "0  /r/india/comments/xif8wm/shashi_tharoor_set_to...       -1.0   -0.50   \n",
       "1  /r/india/comments/pmn9o3/yogi_government_puts_...       -1.0   -0.50   \n",
       "2  /r/india/comments/ebdeup/an_attempt_to_address...       -1.5   -0.75   \n",
       "3  /r/india/comments/tt1ryh/you_guys_noticing_wha...        0.0    0.00   \n",
       "4  /r/india/comments/rh2kcs/just_got_abused_on_th...       -2.0   -1.00   \n",
       "\n",
       "      preds  \n",
       "0  0.327382  \n",
       "1 -0.299736  \n",
       "2 -1.422320  \n",
       "3 -0.174992  \n",
       "4 -0.647521  "
      ]
     },
     "execution_count": 50,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pred_df = clean_df.copy()\n",
    "pred_df['preds'] = preds\n",
    "pred_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "e09235de",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.28823150672944636"
      ]
     },
     "execution_count": 51,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.sqrt(mean_squared_error(pred_df['target'], pred_df['preds']))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "41ffef10",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.37984472691565396"
      ]
     },
     "execution_count": 52,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.std(pred_df['preds'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "3a9ed9d3",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.6893346379647749"
      ]
     },
     "execution_count": 53,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "new_y_test, new_y_pred = convert_to_classifier(pred_df['target'], pred_df['preds'], threshold=0.21)\n",
    "np.mean([int(new_y_test[i]==new_y_pred[i]) for i in range(len(new_y_test))])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "30410ed3",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "bd811e4d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>clean_title</th>\n",
       "      <th>clean_comment</th>\n",
       "      <th>url</th>\n",
       "      <th>avg_score</th>\n",
       "      <th>target</th>\n",
       "      <th>preds</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Shashi Tharoor Set To Run For Congress Preside...</td>\n",
       "      <td>Extremely valid points but I believe he has th...</td>\n",
       "      <td>/r/india/comments/xif8wm/shashi_tharoor_set_to...</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-0.50</td>\n",
       "      <td>-0.174241</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Yogi government puts Kolkata's image as part o...</td>\n",
       "      <td>Even if the ad was designed by the newspaper t...</td>\n",
       "      <td>/r/india/comments/pmn9o3/yogi_government_puts_...</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-0.50</td>\n",
       "      <td>-0.042562</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>An attempt to address the list of \"simplified\"...</td>\n",
       "      <td>Diverse population including Muslims. Welcomin...</td>\n",
       "      <td>/r/india/comments/ebdeup/an_attempt_to_address...</td>\n",
       "      <td>-1.5</td>\n",
       "      <td>-0.75</td>\n",
       "      <td>-0.422888</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>You guys noticing what's happening in Sri Lanka?</td>\n",
       "      <td>What a joke. They didn't create any propaganda...</td>\n",
       "      <td>/r/india/comments/tt1ryh/you_guys_noticing_wha...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.002135</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Just got abused on the train by a hyper nation...</td>\n",
       "      <td>Ohoo bahut bura laga ye sunke ki aap Undergarm...</td>\n",
       "      <td>/r/india/comments/rh2kcs/just_got_abused_on_th...</td>\n",
       "      <td>-2.0</td>\n",
       "      <td>-1.00</td>\n",
       "      <td>-0.613895</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>Defeat BJP Mission Uttar Pradesh,' Farmers to ...</td>\n",
       "      <td>Not really. As the country has seen for the la...</td>\n",
       "      <td>/r/india/comments/nmyqu4/defeat_bjp_mission_ut...</td>\n",
       "      <td>-2.0</td>\n",
       "      <td>-1.00</td>\n",
       "      <td>-0.601553</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>Spurned by Congress for years, Dalits in Delhi...</td>\n",
       "      <td>If they focused on campaigning in urban areas ...</td>\n",
       "      <td>/r/india/comments/euipuz/spurned_by_congress_f...</td>\n",
       "      <td>-0.5</td>\n",
       "      <td>-0.25</td>\n",
       "      <td>-0.188489</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>Government spent nearly 3,723 Crore on ads in ...</td>\n",
       "      <td>This ads are for various awareness programmes,...</td>\n",
       "      <td>/r/IndiaSpeaks/comments/zpnhnr/government_spen...</td>\n",
       "      <td>0.5</td>\n",
       "      <td>0.25</td>\n",
       "      <td>0.225526</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>The standard of prime time debates on our nati...</td>\n",
       "      <td>What else can you expect from Godi Media. All ...</td>\n",
       "      <td>/r/india/comments/118s00j/the_standard_of_prim...</td>\n",
       "      <td>-2.0</td>\n",
       "      <td>-1.00</td>\n",
       "      <td>-0.724807</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>West Bengal government has put total ban on ma...</td>\n",
       "      <td>To fine people for spitting government will ha...</td>\n",
       "      <td>/r/india/comments/dpz5rs/west_bengal_governmen...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.00</td>\n",
       "      <td>-0.064062</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>I clicked a picture from the sky in Delhi and ...</td>\n",
       "      <td>Be me , asthmatic and nearly always sneezing a...</td>\n",
       "      <td>/r/india/comments/vl882u/i_clicked_a_picture_f...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.041457</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>An attempt to address the list of \"simplified\"...</td>\n",
       "      <td>But is Art. 14 also supposed to determine the ...</td>\n",
       "      <td>/r/india/comments/ebdeup/an_attempt_to_address...</td>\n",
       "      <td>0.5</td>\n",
       "      <td>0.25</td>\n",
       "      <td>0.173021</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>\"Educated\" MP of india</td>\n",
       "      <td>Bhai tu reddit pe muhje mere feminist opinions...</td>\n",
       "      <td>/r/IndiaSpeaks/comments/10zcnhx/educated_mp_of...</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.50</td>\n",
       "      <td>0.538129</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>Tejasvi Surya barged into the south bbmp war r...</td>\n",
       "      <td>When elections were happening my mum said even...</td>\n",
       "      <td>/r/india/comments/n5dxga/tejasvi_surya_barged_...</td>\n",
       "      <td>-2.0</td>\n",
       "      <td>-1.00</td>\n",
       "      <td>-0.897721</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>Put 'The Kashmir Files' on YouTube, everyone w...</td>\n",
       "      <td>Attempt at more elaborate translation, for tho...</td>\n",
       "      <td>/r/india/comments/tmcun4/put_the_kashmir_files...</td>\n",
       "      <td>-2.0</td>\n",
       "      <td>-1.00</td>\n",
       "      <td>-1.066948</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>Kejriwal says The Kashmir Files is a jhoothi f...</td>\n",
       "      <td>I ve not seen the movie but it s all over redd...</td>\n",
       "      <td>/r/IndiaSpeaks/comments/tmhqqg/kejriwal_says_t...</td>\n",
       "      <td>-0.5</td>\n",
       "      <td>-0.25</td>\n",
       "      <td>0.274200</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>Smriti Irani's son recently graduated from a f...</td>\n",
       "      <td>Well, the thing about the future is that it's ...</td>\n",
       "      <td>/r/india/comments/w7co36/smriti_iranis_son_rec...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.00</td>\n",
       "      <td>-0.058332</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>An attempt to address the list of \"simplified\"...</td>\n",
       "      <td>You do realise that everything you are saying ...</td>\n",
       "      <td>/r/india/comments/ebdeup/an_attempt_to_address...</td>\n",
       "      <td>-0.5</td>\n",
       "      <td>-0.25</td>\n",
       "      <td>0.026099</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>Rajasthan BJP MLA Sanjay Sharma posted this on...</td>\n",
       "      <td>Hello u meetyourneed, Your comment breaks r In...</td>\n",
       "      <td>/r/IndiaSpeaks/comments/r9df3s/rajasthan_bjp_m...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.161631</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>Suzanna Arundhati Roy blames Indian government...</td>\n",
       "      <td>If halal organization is using money to find t...</td>\n",
       "      <td>/r/IndiaSpeaks/comments/tepze6/suzanna_arundha...</td>\n",
       "      <td>0.5</td>\n",
       "      <td>0.25</td>\n",
       "      <td>-0.041047</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>Smriti Irani's son recently graduated from a f...</td>\n",
       "      <td>Well well looky looky at this hypocritical fak...</td>\n",
       "      <td>/r/india/comments/w7co36/smriti_iranis_son_rec...</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.50</td>\n",
       "      <td>0.367701</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>The picture pretty much sums up the ideology o...</td>\n",
       "      <td>I think a lot of countries have in recent year...</td>\n",
       "      <td>/r/india/comments/ee11sp/the_picture_pretty_mu...</td>\n",
       "      <td>1.5</td>\n",
       "      <td>0.75</td>\n",
       "      <td>0.479003</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>BBC grilling BJP spokesperson on censoring twe...</td>\n",
       "      <td>I'll say it again those tweets were deleted be...</td>\n",
       "      <td>/r/india/comments/n07ph4/bbc_grilling_bjp_spok...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.072943</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>Congress with some innovative banners for the ...</td>\n",
       "      <td>Her entire family line was involved with RSS. ...</td>\n",
       "      <td>/r/india/comments/u0iytk/congress_with_some_in...</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-0.50</td>\n",
       "      <td>0.069261</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24</th>\n",
       "      <td>You guys noticing what's happening in Sri Lanka?</td>\n",
       "      <td>Not to disagree or agree with you but just a l...</td>\n",
       "      <td>/r/india/comments/tt1ryh/you_guys_noticing_wha...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.00</td>\n",
       "      <td>-0.029494</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25</th>\n",
       "      <td>It's aaolutely hilarious to see some right win...</td>\n",
       "      <td>This is pure BS. Most Defined Benefit pensions...</td>\n",
       "      <td>/r/india/comments/m62khd/its_aaolutely_hilario...</td>\n",
       "      <td>0.5</td>\n",
       "      <td>0.25</td>\n",
       "      <td>-0.000010</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26</th>\n",
       "      <td>When Indira Gandhi cracked down on BBC</td>\n",
       "      <td>You've bought into their narrative. A sikh sep...</td>\n",
       "      <td>/r/IndiaSpeaks/comments/113k1jh/when_indira_ga...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.00</td>\n",
       "      <td>-0.100529</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27</th>\n",
       "      <td>Rajasthan BJP MLA Sanjay Sharma posted this on...</td>\n",
       "      <td>Its sarcasm you poor soul. I know there isnt a...</td>\n",
       "      <td>/r/IndiaSpeaks/comments/r9df3s/rajasthan_bjp_m...</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-0.50</td>\n",
       "      <td>-0.332813</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28</th>\n",
       "      <td>I've collected all available records of UPA ce...</td>\n",
       "      <td>india is not binary, if someone who is critici...</td>\n",
       "      <td>/r/IndiaSpeaks/comments/nn035c/ive_collected_a...</td>\n",
       "      <td>-0.5</td>\n",
       "      <td>-0.25</td>\n",
       "      <td>-0.288821</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29</th>\n",
       "      <td>Priorities of respective governments</td>\n",
       "      <td>Mamta Banerjee was just showcasing how she dis...</td>\n",
       "      <td>/r/india/comments/l6t78h/priorities_of_respect...</td>\n",
       "      <td>-0.5</td>\n",
       "      <td>-0.25</td>\n",
       "      <td>-0.100080</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                          clean_title  \\\n",
       "0   Shashi Tharoor Set To Run For Congress Preside...   \n",
       "1   Yogi government puts Kolkata's image as part o...   \n",
       "2   An attempt to address the list of \"simplified\"...   \n",
       "3    You guys noticing what's happening in Sri Lanka?   \n",
       "4   Just got abused on the train by a hyper nation...   \n",
       "5   Defeat BJP Mission Uttar Pradesh,' Farmers to ...   \n",
       "6   Spurned by Congress for years, Dalits in Delhi...   \n",
       "7   Government spent nearly 3,723 Crore on ads in ...   \n",
       "8   The standard of prime time debates on our nati...   \n",
       "9   West Bengal government has put total ban on ma...   \n",
       "10  I clicked a picture from the sky in Delhi and ...   \n",
       "11  An attempt to address the list of \"simplified\"...   \n",
       "12                             \"Educated\" MP of india   \n",
       "13  Tejasvi Surya barged into the south bbmp war r...   \n",
       "14  Put 'The Kashmir Files' on YouTube, everyone w...   \n",
       "15  Kejriwal says The Kashmir Files is a jhoothi f...   \n",
       "16  Smriti Irani's son recently graduated from a f...   \n",
       "17  An attempt to address the list of \"simplified\"...   \n",
       "18  Rajasthan BJP MLA Sanjay Sharma posted this on...   \n",
       "19  Suzanna Arundhati Roy blames Indian government...   \n",
       "20  Smriti Irani's son recently graduated from a f...   \n",
       "21  The picture pretty much sums up the ideology o...   \n",
       "22  BBC grilling BJP spokesperson on censoring twe...   \n",
       "23  Congress with some innovative banners for the ...   \n",
       "24   You guys noticing what's happening in Sri Lanka?   \n",
       "25  It's aaolutely hilarious to see some right win...   \n",
       "26             When Indira Gandhi cracked down on BBC   \n",
       "27  Rajasthan BJP MLA Sanjay Sharma posted this on...   \n",
       "28  I've collected all available records of UPA ce...   \n",
       "29               Priorities of respective governments   \n",
       "\n",
       "                                        clean_comment  \\\n",
       "0   Extremely valid points but I believe he has th...   \n",
       "1   Even if the ad was designed by the newspaper t...   \n",
       "2   Diverse population including Muslims. Welcomin...   \n",
       "3   What a joke. They didn't create any propaganda...   \n",
       "4   Ohoo bahut bura laga ye sunke ki aap Undergarm...   \n",
       "5   Not really. As the country has seen for the la...   \n",
       "6   If they focused on campaigning in urban areas ...   \n",
       "7   This ads are for various awareness programmes,...   \n",
       "8   What else can you expect from Godi Media. All ...   \n",
       "9   To fine people for spitting government will ha...   \n",
       "10  Be me , asthmatic and nearly always sneezing a...   \n",
       "11  But is Art. 14 also supposed to determine the ...   \n",
       "12  Bhai tu reddit pe muhje mere feminist opinions...   \n",
       "13  When elections were happening my mum said even...   \n",
       "14  Attempt at more elaborate translation, for tho...   \n",
       "15  I ve not seen the movie but it s all over redd...   \n",
       "16  Well, the thing about the future is that it's ...   \n",
       "17  You do realise that everything you are saying ...   \n",
       "18  Hello u meetyourneed, Your comment breaks r In...   \n",
       "19  If halal organization is using money to find t...   \n",
       "20  Well well looky looky at this hypocritical fak...   \n",
       "21  I think a lot of countries have in recent year...   \n",
       "22  I'll say it again those tweets were deleted be...   \n",
       "23  Her entire family line was involved with RSS. ...   \n",
       "24  Not to disagree or agree with you but just a l...   \n",
       "25  This is pure BS. Most Defined Benefit pensions...   \n",
       "26  You've bought into their narrative. A sikh sep...   \n",
       "27  Its sarcasm you poor soul. I know there isnt a...   \n",
       "28  india is not binary, if someone who is critici...   \n",
       "29  Mamta Banerjee was just showcasing how she dis...   \n",
       "\n",
       "                                                  url  avg_score  target  \\\n",
       "0   /r/india/comments/xif8wm/shashi_tharoor_set_to...       -1.0   -0.50   \n",
       "1   /r/india/comments/pmn9o3/yogi_government_puts_...       -1.0   -0.50   \n",
       "2   /r/india/comments/ebdeup/an_attempt_to_address...       -1.5   -0.75   \n",
       "3   /r/india/comments/tt1ryh/you_guys_noticing_wha...        0.0    0.00   \n",
       "4   /r/india/comments/rh2kcs/just_got_abused_on_th...       -2.0   -1.00   \n",
       "5   /r/india/comments/nmyqu4/defeat_bjp_mission_ut...       -2.0   -1.00   \n",
       "6   /r/india/comments/euipuz/spurned_by_congress_f...       -0.5   -0.25   \n",
       "7   /r/IndiaSpeaks/comments/zpnhnr/government_spen...        0.5    0.25   \n",
       "8   /r/india/comments/118s00j/the_standard_of_prim...       -2.0   -1.00   \n",
       "9   /r/india/comments/dpz5rs/west_bengal_governmen...        0.0    0.00   \n",
       "10  /r/india/comments/vl882u/i_clicked_a_picture_f...        0.0    0.00   \n",
       "11  /r/india/comments/ebdeup/an_attempt_to_address...        0.5    0.25   \n",
       "12  /r/IndiaSpeaks/comments/10zcnhx/educated_mp_of...        1.0    0.50   \n",
       "13  /r/india/comments/n5dxga/tejasvi_surya_barged_...       -2.0   -1.00   \n",
       "14  /r/india/comments/tmcun4/put_the_kashmir_files...       -2.0   -1.00   \n",
       "15  /r/IndiaSpeaks/comments/tmhqqg/kejriwal_says_t...       -0.5   -0.25   \n",
       "16  /r/india/comments/w7co36/smriti_iranis_son_rec...        0.0    0.00   \n",
       "17  /r/india/comments/ebdeup/an_attempt_to_address...       -0.5   -0.25   \n",
       "18  /r/IndiaSpeaks/comments/r9df3s/rajasthan_bjp_m...        0.0    0.00   \n",
       "19  /r/IndiaSpeaks/comments/tepze6/suzanna_arundha...        0.5    0.25   \n",
       "20  /r/india/comments/w7co36/smriti_iranis_son_rec...        1.0    0.50   \n",
       "21  /r/india/comments/ee11sp/the_picture_pretty_mu...        1.5    0.75   \n",
       "22  /r/india/comments/n07ph4/bbc_grilling_bjp_spok...        0.0    0.00   \n",
       "23  /r/india/comments/u0iytk/congress_with_some_in...       -1.0   -0.50   \n",
       "24  /r/india/comments/tt1ryh/you_guys_noticing_wha...        0.0    0.00   \n",
       "25  /r/india/comments/m62khd/its_aaolutely_hilario...        0.5    0.25   \n",
       "26  /r/IndiaSpeaks/comments/113k1jh/when_indira_ga...        0.0    0.00   \n",
       "27  /r/IndiaSpeaks/comments/r9df3s/rajasthan_bjp_m...       -1.0   -0.50   \n",
       "28  /r/IndiaSpeaks/comments/nn035c/ive_collected_a...       -0.5   -0.25   \n",
       "29  /r/india/comments/l6t78h/priorities_of_respect...       -0.5   -0.25   \n",
       "\n",
       "       preds  \n",
       "0  -0.174241  \n",
       "1  -0.042562  \n",
       "2  -0.422888  \n",
       "3   0.002135  \n",
       "4  -0.613895  \n",
       "5  -0.601553  \n",
       "6  -0.188489  \n",
       "7   0.225526  \n",
       "8  -0.724807  \n",
       "9  -0.064062  \n",
       "10  0.041457  \n",
       "11  0.173021  \n",
       "12  0.538129  \n",
       "13 -0.897721  \n",
       "14 -1.066948  \n",
       "15  0.274200  \n",
       "16 -0.058332  \n",
       "17  0.026099  \n",
       "18  0.161631  \n",
       "19 -0.041047  \n",
       "20  0.367701  \n",
       "21  0.479003  \n",
       "22  0.072943  \n",
       "23  0.069261  \n",
       "24 -0.029494  \n",
       "25 -0.000010  \n",
       "26 -0.100529  \n",
       "27 -0.332813  \n",
       "28 -0.288821  \n",
       "29 -0.100080  "
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pred_df[:30]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "e5f3155f",
   "metadata": {},
   "outputs": [],
   "source": [
    "pred_df.to_csv('indian_sbert_preds.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "6d5ab363",
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.save(model, 'models/indian_sbert.pkl')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "043ec751",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
